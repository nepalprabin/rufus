{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prabinnepal/miniforge3/envs/rufus/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from client import RufusClient\n",
    "import os \n",
    "\n",
    "key = os.getenv('RUFUS_API_KEY')\n",
    "client = RufusClient(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Extract information from the website Extract all the blog contents based on this prompt: </span>                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">\"https://nepalprabin.github.io\"</span>                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        </span>                                                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        Follow these steps:</span>                                                                                     <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        1. Crawl the website starting from the given URL</span>                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        2. Extract clean, readable content from the HTML</span>                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        3. Evaluate the relevance of each page to the prompt</span>                                                    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        4. Synthesize the relevant content into a structured document in json format  </span>                          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        </span>                                                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">        Return the final document.</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - gpt-4o ────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mExtract information from the website Extract all the blog contents based on this prompt: \u001b[0m                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m\"https://nepalprabin.github.io\"\u001b[0m                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        \u001b[0m                                                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        Follow these steps:\u001b[0m                                                                                     \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        1. Crawl the website starting from the given URL\u001b[0m                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        2. Extract clean, readable content from the HTML\u001b[0m                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        3. Evaluate the relevance of each page to the prompt\u001b[0m                                                    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        4. Synthesize the relevant content into a structured document in json format  \u001b[0m                          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        \u001b[0m                                                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m        Return the final document.\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - gpt-4o \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">start_url </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"https://nepalprabin.github.io\"</span><span style=\"background-color: #272822\">                                                                    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_pages </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"background-color: #272822\">                                                                                               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_depth </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">True</span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Begin crawling the website from the given URL</span><span style=\"background-color: #272822\">                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">crawled_pages </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_crawler_tool(start_url</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">start_url, max_pages</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_pages, max_depth</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_depth, </span><span style=\"background-color: #272822\">               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots)</span><span style=\"background-color: #272822\">                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(crawled_pages)</span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mhttps://nepalprabin.github.io\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mTrue\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Begin crawling the website from the given URL\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mcrawled_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_crawler_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcrawled_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code execution failed at line </span><span style=\"color: #008000; text-decoration-color: #008000\">'crawled_pages = web_crawler_tool(start_url=start_url, max_pages=max_pages, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">max_depth=max_depth, respect_robots=respect_robots)'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> due to: TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> not supported between instances of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'int'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> and </span><span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mCode execution failed at line \u001b[0m\u001b[32m'crawled_pages = web_crawler_tool\u001b[0m\u001b[32m(\u001b[0m\u001b[32mstart_url\u001b[0m\u001b[32m=\u001b[0m\u001b[32mstart_url\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmax_pages\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmax_pages\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mmax_depth\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmax_depth\u001b[0m\u001b[32m, \u001b[0m\u001b[32mrespect_robots\u001b[0m\u001b[32m=\u001b[0m\u001b[32mrespect_robots\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1;31m due to: TypeError: \u001b[0m\u001b[32m'<'\u001b[0m\u001b[1;31m not supported between instances of \u001b[0m\n",
       "\u001b[32m'int'\u001b[0m\u001b[1;31m and \u001b[0m\u001b[32m'NoneType'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 4.75 seconds| Input tokens: 2,445 | Output tokens: 174]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 4.75 seconds| Input tokens: 2,445 | Output tokens: 174]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">start_url </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"https://nepalprabin.github.io\"</span><span style=\"background-color: #272822\">                                                                    </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_pages </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">100</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Set to a large number</span><span style=\"background-color: #272822\">                                                                       </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_depth </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">True</span><span style=\"background-color: #272822\">                                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Retry crawling the website with corrected parameters</span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">crawled_pages </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_crawler_tool(start_url</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">start_url, max_pages</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_pages, max_depth</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">max_depth, </span><span style=\"background-color: #272822\">               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">respect_robots)</span><span style=\"background-color: #272822\">                                                                                 </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(crawled_pages)</span><span style=\"background-color: #272822\">                                                                                           </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mhttps://nepalprabin.github.io\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m100\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Set to a large number\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mTrue\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Retry crawling the website with corrected parameters\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mcrawled_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_crawler_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstart_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_depth\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrespect_robots\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcrawled_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "{'pages': {'https://nepalprabin.github.io': {'title': 'Prabin Nepal', 'html': '&lt;!DOCTYPE html&gt;\\n&lt;html \n",
       "xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;&lt;head&gt;\\n\\n&lt;meta charset=\"utf-8\"&gt;\\n&lt;meta \n",
       "name=\"generator\" content=\"quarto-1.6.42\"&gt;\\n\\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes\"&gt;\\n\\n\\n&lt;title&gt;Prabin Nepal&lt;/title&gt;\\n&lt;style&gt;\\ncode{white-space: \n",
       "pre-wrap;}\\nspan.smallcaps{font-variant: small-caps;}\\ndiv.columns{display: flex; gap: min(4vw, \n",
       "1.5em);}\\ndiv.column{flex: auto; overflow-x: auto;}\\ndiv.hanging-indent{margin-left: 1.5em; text-indent: \n",
       "-1.5em;}\\nul.task-list{list-style: none;}\\nul.task-list li input[type=\"checkbox\"] {\\n  width: 0.8em;\\n  margin: 0 \n",
       "0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ \\n  \n",
       "vertical-align: middle;\\n}\\n&lt;/style&gt;\\n\\n\\n&lt;script src=\"site_libs/quarto-nav/quarto-nav.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-nav/headroom.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/clipboard/clipboard.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-search/autocomplete.umd.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-search/fuse.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-search/quarto-search.js\"&gt;&lt;/script&gt;\\n&lt;meta name=\"quarto:offset\" content=\"./\"&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-listing/list.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-listing/quarto-listing.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-html/quarto.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-html/popper.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-html/tippy.umd.min.js\"&gt;&lt;/script&gt;\\n&lt;script \n",
       "src=\"site_libs/quarto-html/anchor.min.js\"&gt;&lt;/script&gt;\\n&lt;link href=\"site_libs/quarto-html/tippy.css\" \n",
       "rel=\"stylesheet\"&gt;\\n&lt;link \n",
       "href=\"site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css\" rel=\"stylesheet\" \n",
       "class=\"quarto-color-scheme\" id=\"quarto-text-highlighting-styles\"&gt;\\n&lt;link \n",
       "href=\"site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css\" rel=\"stylesheet\" \n",
       "class=\"quarto-color-scheme quarto-color-alternate\" id=\"quarto-text-highlighting-styles\"&gt;\\n&lt;script \n",
       "src=\"site_libs/bootstrap/bootstrap.min.js\"&gt;&lt;/script&gt;\\n&lt;link href=\"site_libs/bootstrap/bootstrap-icons.css\" \n",
       "rel=\"stylesheet\"&gt;\\n&lt;link href=\"site_libs/bootstrap/bootstrap-d75320580429fd03ccc14abf5aea7e44.min.css\" \n",
       "rel=\"stylesheet\" append-hash=\"true\" class=\"quarto-color-scheme\" id=\"quarto-bootstrap\" data-mode=\"light\"&gt;\\n&lt;link \n",
       "href=\"site_libs/bootstrap/bootstrap-dark-03cff2e87a80ce85282700c0d3d2a4d3.min.css\" rel=\"stylesheet\" \n",
       "append-hash=\"true\" class=\"quarto-color-scheme quarto-color-alternate\" id=\"quarto-bootstrap\" \n",
       "data-mode=\"dark\"&gt;\\n&lt;script id=\"quarto-search-options\" type=\"application/json\"&gt;{\\n  \"location\": \"navbar\",\\n  \n",
       "\"copy-button\": false,\\n  \"collapse-after\": 3,\\n  \"panel-placement\": \"end\",\\n  \"type\": \"overlay\",\\n  \"limit\": 50,\\n \n",
       "\"keyboard-shortcut\": [\\n    \"f\",\\n    \"/\",\\n    \"s\"\\n  ],\\n  \"show-item-context\": false,\\n  \"language\": {\\n    \n",
       "\"search-no-results-text\": \"No results\",\\n    \"search-matching-documents-text\": \"matching documents\",\\n    \n",
       "\"search-copy-link-title\": \"Copy link to search\",\\n    \"search-hide-matches-text\": \"Hide additional matches\",\\n    \n",
       "\"search-more-match-text\": \"more match in this document\",\\n    \"search-more-matches-text\": \"more matches in this \n",
       "document\",\\n    \"search-clear-button-title\": \"Clear\",\\n    \"search-text-placeholder\": \"\",\\n    \n",
       "\"search-detached-cancel-button-title\": \"Cancel\",\\n    \"search-submit-button-title\": \"Submit\",\\n    \"search-label\": \n",
       "\"Search\"\\n  }\\n}&lt;/script&gt;\\n&lt;script&gt;\\n\\n  window.document.addEventListener(\"DOMContentLoaded\", function (_event) {\\n\n",
       "const listingTargetEl = window.document.querySelector(\\'#listing-listing .list\\');\\n    if (!listingTargetEl) {\\n  \n",
       "// No listing discovered, do not attach.\\n      return; \\n    }\\n\\n    const options = {\\n      valueNames: \n",
       "[\\'listing-date\\',\\'listing-title\\',\\'listing-author\\',\\'listing-image\\',\\'listing-description\\',\\'listing-categori\n",
       "es\\',{ data: [\\'index\\'] },{ data: [\\'categories\\'] },{ data: [\\'listing-date-sort\\'] },{ data: \n",
       "[\\'listing-file-modified-sort\\'] }],\\n      \\n      searchColumns: \n",
       "[\"listing-date\",\"listing-title\",\"listing-author\",\"listing-image\",\"listing-description\",\"listing-categories\"],\\n    \n",
       "};\\n\\n    window[\\'quarto-listings\\'] = window[\\'quarto-listings\\'] || {};\\n    \n",
       "window[\\'quarto-listings\\'][\\'listing-listing\\'] = new List(\\'listing-listing\\', options);\\n\\n    if \n",
       "(window[\\'quarto-listing-loaded\\']) {\\n      window[\\'quarto-listing-loaded\\']();\\n    }\\n  });\\n\\n  \n",
       "window.addEventListener(\\'hashchange\\',() =&gt; {\\n    if (window[\\'quarto-listing-loaded\\']) {\\n      \n",
       "window[\\'quarto-listing-loaded\\']();\\n    }\\n  })\\n  &lt;/script&gt;\\n&lt;script async=\"\" \n",
       "src=\"https://www.googletagmanager.com/gtag/js?id=G-5HCLVN4PVB\"&gt;&lt;/script&gt;\\n\\n&lt;script \n",
       "type=\"text/javascript\"&gt;\\n\\nwindow.dataLayer = window.dataLayer || [];\\nfunction \n",
       "gtag(){dataLayer.push(arguments);}\\ngtag(\\'js\\', new Date());\\ngtag(\\'config\\', \\'G-5HCLVN4PVB\\', { \n",
       "\\'anonymize_ip\\': true});\\n&lt;/script&gt;\\n\\n  &lt;script \n",
       "src=\"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6\"&gt;&lt;/script&gt;\\n  &lt;script \n",
       "src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js\" type=\"text/javascript\"&gt;&lt;/script&gt;\\n\\n&lt;script \n",
       "type=\"text/javascript\"&gt;\\nconst typesetMath = (el) =&gt; {\\n  if (window.MathJax) {\\n    // MathJax Typeset\\n    \n",
       "window.MathJax.typeset([el]);\\n  } else if (window.katex) {\\n    // KaTeX Render\\n    var mathElements = \n",
       "el.getElementsByClassName(\"math\");\\n    var macros = [];\\n    for (var i = 0; i &lt; mathElements.length; i++) {\\n    \n",
       "var texText = mathElements[i].firstChild;\\n      if (mathElements[i].tagName == \"SPAN\") {\\n        \n",
       "window.katex.render(texText.data, mathElements[i], {\\n          displayMode: \n",
       "mathElements[i].classList.contains(\\'display\\'),\\n          throwOnError: false,\\n          macros: macros,\\n      \n",
       "fleqn: false\\n        });\\n      }\\n    }\\n  }\\n}\\nwindow.Quarto = {\\n  typesetMath\\n};\\n&lt;/script&gt;\\n\\n&lt;link \n",
       "rel=\"stylesheet\" href=\"styles.css\"&gt;\\n&lt;meta property=\"og:title\" content=\"Prabin Nepal\"&gt;\\n&lt;meta property=\"og:image\" \n",
       "content=\"https://nepalprabin.github.io/images/ai_agents.png\"&gt;\\n&lt;meta property=\"og:site_name\" content=\"Prabin \n",
       "Nepal\"&gt;\\n&lt;meta property=\"og:image:height\" content=\"768\"&gt;\\n&lt;meta property=\"og:image:width\" \n",
       "content=\"1024\"&gt;\\n&lt;/head&gt;\\n\\n&lt;body class=\"nav-fixed\"&gt;\\n\\n&lt;div id=\"quarto-search-results\"&gt;&lt;/div&gt;\\n  &lt;header \n",
       "id=\"quarto-header\" class=\"headroom fixed-top quarto-banner\"&gt;\\n    &lt;nav class=\"navbar navbar-expand-lg \" \n",
       "data-bs-theme=\"dark\"&gt;\\n      &lt;div class=\"navbar-container container-fluid\"&gt;\\n      &lt;div \n",
       "class=\"navbar-brand-container mx-auto\"&gt;\\n    &lt;a class=\"navbar-brand\" href=\"./index.html\"&gt;\\n    &lt;span \n",
       "class=\"navbar-title\"&gt;Prabin Nepal&lt;/span&gt;\\n    &lt;/a&gt;\\n  &lt;/div&gt;\\n            &lt;div id=\"quarto-search\" class=\"\" \n",
       "title=\"Search\"&gt;&lt;/div&gt;\\n          &lt;button class=\"navbar-toggler\" type=\"button\" data-bs-toggle=\"collapse\" \n",
       "data-bs-target=\"#navbarCollapse\" aria-controls=\"navbarCollapse\" role=\"menu\" aria-expanded=\"false\" \n",
       "aria-label=\"Toggle navigation\" onclick=\"if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }\"&gt;\\n  \n",
       "&lt;span class=\"navbar-toggler-icon\"&gt;&lt;/span&gt;\\n&lt;/button&gt;\\n          &lt;div class=\"collapse navbar-collapse\" \n",
       "id=\"navbarCollapse\"&gt;\\n            &lt;ul class=\"navbar-nav navbar-nav-scroll ms-auto\"&gt;\\n  &lt;li class=\"nav-item\"&gt;\\n    \n",
       "&lt;a class=\"nav-link\" href=\"./projects.html\"&gt; \\n&lt;span class=\"menu-text\"&gt;Projects&lt;/span&gt;&lt;/a&gt;\\n  &lt;/li&gt;  \\n  &lt;li \n",
       "class=\"nav-item compact\"&gt;\\n    &lt;a class=\"nav-link\" href=\"https://github.com/nepalprabin\"&gt; &lt;i class=\"bi bi-github\" \n",
       "role=\"img\"&gt;\\n&lt;/i&gt; \\n&lt;span class=\"menu-text\"&gt;&lt;/span&gt;&lt;/a&gt;\\n  &lt;/li&gt;  \\n  &lt;li class=\"nav-item compact\"&gt;\\n    &lt;a \n",
       "class=\"nav-link\" href=\"https://linkedin.com/in/prabin-nepal\"&gt; &lt;i class=\"bi bi-linkedin\" role=\"img\"&gt;\\n&lt;/i&gt; \\n&lt;span \n",
       "class=\"menu-text\"&gt;&lt;/span&gt;&lt;/a&gt;\\n  &lt;/li&gt;  \\n&lt;/ul&gt;\\n          &lt;/div&gt; &lt;!-- /navcollapse --&gt;\\n            &lt;div \n",
       "class=\"quarto-navbar-tools\"&gt;\\n  &lt;a href=\"\" class=\"quarto-color-scheme-toggle quarto-navigation-tool  px-1\" \n",
       "onclick=\"window.quartoToggleColorScheme(); return false;\" title=\"Toggle dark mode\"&gt;&lt;i class=\"bi\"&gt;&lt;/i&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n\n",
       "&lt;/div&gt; &lt;!-- /container-fluid --&gt;\\n    &lt;/nav&gt;\\n&lt;/header&gt;\\n&lt;!-- content --&gt;\\n&lt;header id=\"title-block-header\" \n",
       "class=\"quarto-title-block\"&gt;&lt;/header&gt;&lt;div id=\"quarto-content\" class=\"quarto-container page-columns \n",
       "page-rows-contents page-layout-full page-navbar\"&gt;\\n&lt;!-- sidebar --&gt;\\n&lt;!-- margin-sidebar --&gt;\\n    &lt;div \n",
       "id=\"quarto-margin-sidebar\" class=\"sidebar margin-sidebar\"&gt;\\n        \\n    &lt;h5 \n",
       "class=\"quarto-listing-category-title\"&gt;Categories&lt;/h5&gt;&lt;div class=\"quarto-listing-category category-default\"&gt;&lt;div \n",
       "class=\"category\" data-category=\"\"&gt;All &lt;span class=\"quarto-category-count\"&gt;(16)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" \n",
       "data-category=\"TExN\"&gt;LLM &lt;span class=\"quarto-category-count\"&gt;(1)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" \n",
       "data-category=\"TkxQ\"&gt;NLP &lt;span class=\"quarto-category-count\"&gt;(4)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" \n",
       "data-category=\"YWdlbnRz\"&gt;agents &lt;span class=\"quarto-category-count\"&gt;(1)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" \n",
       "data-category=\"Y29tcHV0ZXItdmlzaW9u\"&gt;computer-vision &lt;span class=\"quarto-category-count\"&gt;(6)&lt;/span&gt;&lt;/div&gt;&lt;div \n",
       "class=\"category\" data-category=\"ZGVlcC1sZWFybmluZw==\"&gt;deep-learning &lt;span \n",
       "class=\"quarto-category-count\"&gt;(12)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" data-category=\"bGxtcw==\"&gt;llms &lt;span \n",
       "class=\"quarto-category-count\"&gt;(1)&lt;/span&gt;&lt;/div&gt;&lt;div class=\"category\" \n",
       "data-category=\"bWFjaGluZS1sZWFybmluZw==\"&gt;machine-learning &lt;span class=\"quarto-category-count\"&gt;(2)&lt;/span&gt;&lt;/div&gt;&lt;div \n",
       "class=\"category\" data-category=\"c2VsZi1zdXBlcnZpc2VkLWxlYXJuaW5n\"&gt;self-supervised-learning &lt;span \n",
       "class=\"quarto-category-count\"&gt;(1)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\\n&lt;!-- main --&gt;\\n&lt;main class=\"content \n",
       "quarto-banner-title-block column-page-left\" id=\"quarto-document-content\"&gt;\\n\\n\\n\\n\\n\\n\\n\\n\\n&lt;div \n",
       "class=\"quarto-listing quarto-listing-container-default\" id=\"listing-listing\"&gt;\\n&lt;div class=\"list \n",
       "quarto-listing-default\"&gt;\\n&lt;div class=\"quarto-post image-right\" data-index=\"0\" \n",
       "data-categories=\"bGxtcyUyQ2FnZW50cw==\" data-listing-date-sort=\"1740873600000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"799\"&gt;\\n&lt;div class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" \n",
       "src=\"./images/ai_agents.png\" class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;Huggingface AI Agents Quiz \n",
       "Solutions&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div class=\"listing-subtitle\"&gt;\\n&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'bGxtcw==\\'); \n",
       "return false;\"&gt;\\nllms\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'YWdlbnRz\\'); \n",
       "return false;\"&gt;\\nagents\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;I have been diving into AI \n",
       "agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of how to build and\n",
       "deploy AI agents using the &lt;code&gt;smol…&lt;/code&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"&gt;\\n&lt;div \n",
       "class=\"listing-date\"&gt;\\nMar 2, 2025\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"quarto-post image-right\" \n",
       "data-index=\"1\" data-categories=\"bWFjaGluZS1sZWFybmluZyUyQ05MUCUyQ2RlZXAtbGVhcm5pbmclMkNMTE0=\" \n",
       "data-listing-date-sort=\"1688428800000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"9\" data-listing-word-count-sort=\"1630\"&gt;\\n&lt;div\n",
       "class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" \n",
       "src=\"./images/augmenting llms.png\" class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a href=\"./posts/2023-07-04-augmented-language-models.html\" \n",
       "class=\"no-external\"&gt;Augmenting Large Language Models: Expanding Context and Enhancing Relevance&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div \n",
       "class=\"listing-subtitle\"&gt;\\n&lt;a href=\"./posts/2023-07-04-augmented-language-models.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'bWFjaGluZS1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\nmachine-learning\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); \n",
       "return false;\"&gt;\\nNLP\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return false;\"&gt;\\ndeep-learning\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TExN\\'); return \n",
       "false;\"&gt;\\nLLM\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"&gt;With the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"&gt;\\n&lt;div class=\"listing-date\"&gt;\\nJul 4, \n",
       "2023\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"quarto-post image-right\" data-index=\"2\" \n",
       "data-categories=\"bWFjaGluZS1sZWFybmluZyUyQ05MUCUyQ2RlZXAtbGVhcm5pbmc=\" data-listing-date-sort=\"1678838400000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"918\"&gt;\\n&lt;div class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" src=\"./images/gpt-4.jpeg\" \n",
       "class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a href=\"./posts/2023-05-15-gpt4-summary.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"&gt;Brief overview of GPT-4&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div \n",
       "class=\"listing-subtitle\"&gt;\\n&lt;a href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'bWFjaGluZS1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\nmachine-learning\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); \n",
       "return false;\"&gt;\\nNLP\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\ndeep-learning\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"&gt;Since the release of ChatGPT, there has been \n",
       "significant interest and discussion within the broader AI and natural language processing communities regarding \n",
       "its…&lt;code&gt;&lt;/code&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a href=\"./posts/2023-05-15-gpt4-summary.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;div class=\"listing-date\"&gt;\\nMar 15, 2023\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"quarto-post image-right\" data-index=\"3\" data-categories=\"TkxQJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1666137600000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"10\" \n",
       "data-listing-word-count-sort=\"1880\"&gt;\\n&lt;div class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" \n",
       "src=\"./images/text-summarization.jpg\" class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3\n",
       "class=\"no-anchor listing-title\"&gt;\\n&lt;a href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;Text\n",
       "Summarization NLP&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div class=\"listing-subtitle\"&gt;\\n&lt;a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); return \n",
       "false;\"&gt;\\nNLP\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\ndeep-learning\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"&gt;Text summarization is one of the Natural \n",
       "Language Processing (NLP) tasks where documents/texts are shortened automatically while holding the same semantic \n",
       "meaning.…&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a href=\"./posts/2022-10-19-text-summarization-nlp.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;div class=\"listing-date\"&gt;\\nOct 19, 2022\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"quarto-post image-right\" data-index=\"4\" data-categories=\"TkxQJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1635120000000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"742\"&gt;\\n&lt;div \n",
       "class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" src=\"./images/autocorrect_example.png\" \n",
       "class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\"&gt;Autocorrect and Minimum \n",
       "Edit Distance&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div class=\"listing-subtitle\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); return \n",
       "false;\"&gt;\\nNLP\\n&lt;/div&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\ndeep-learning\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\"&gt;This is my brief note from\n",
       "&lt;em&gt;DeepLearning.AI’s&lt;/em&gt; NLP Specialization Course.&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\"&gt;\\n&lt;div \n",
       "class=\"listing-date\"&gt;\\nOct 25, 2021\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"quarto-post image-right\" \n",
       "data-index=\"5\" data-categories=\"Y29tcHV0ZXItdmlzaW9uJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1627344000000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"919\"&gt;\\n&lt;div \n",
       "class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" src=\"./images/vision_transformer.gif\" \n",
       "class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\"&gt;Illustrated Vision \n",
       "Transformers&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div class=\"listing-subtitle\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-categories\"&gt;\\n&lt;div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'Y29tcHV0ZXItdmlzaW9u\\'); return false;\"&gt;\\ncomputer-vision\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\"&gt;\\ndeep-learning\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\"&gt;Ever since Transformer was \n",
       "introduced in 2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP\n",
       "tasks use Transformers and…&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\"&gt;\\n&lt;div \n",
       "class=\"listing-date\"&gt;\\nJul 27, 2021\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"quarto-post image-right\" \n",
       "data-index=\"6\" data-listing-date-sort=\"1616716800000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"901\"&gt;\\n&lt;div \n",
       "class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" \n",
       "src=\"./images/contrastive-puzzle.gif\" class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3 \n",
       "class=\"no-anchor listing-title\"&gt;\\n&lt;a href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"&gt;Paper \n",
       "Explanation: A Simple Framework for Contrastive Learning of Visual Representations (simCLR)&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div \n",
       "class=\"listing-subtitle\"&gt;\\n&lt;a href=\"./posts/2021-03-26-simclr-explained.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"&gt;Various self-supervised learning methods have \n",
       "been proposed in recent years for learning image representations. Though a lot of methods have been proposed, the \n",
       "performance…&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div class=\"metadata\"&gt;\\n&lt;a href=\"./posts/2021-03-26-simclr-explained.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;div class=\"listing-date\"&gt;\\nMar 26, 2021\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"quarto-post image-right\" data-index=\"7\" data-listing-date-sort=\"1609459200000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"728\"&gt;\\n&lt;div class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;p&gt;&lt;img loading=\"lazy\" src=\"./images/residual-block.png\" \n",
       "class=\"thumbnail-image\"&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;Deep Residual Learning for Image Recognition (ResNet paper explained)&lt;/a&gt;\\n&lt;/h3&gt;\\n&lt;div \n",
       "class=\"listing-subtitle\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;div class=\"listing-description\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;Deep Neural Networks tend to provide more accuracy as the number of layers increases. But, as \n",
       "we go more deeper in the network, the accuracy of the network decreases instead…&lt;i&gt;&lt;/i&gt;&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"metadata\"&gt;\\n&lt;a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"&gt;\\n&lt;div class=\"listing-date\"&gt;\\nJan 1, 2021\\n&lt;/div&gt;\\n&lt;/a&gt;\\n&lt;/div&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"quarto-post image-right\" data-index=\"8\" \n",
       "data-categories=\"ZGVlcC1sZWFybmluZyUyQ3NlbGYtc3VwZXJ2aXNlZC1sZWFybmluZw==\" data-listing-date-sort=\"1607385600000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"6\" data-listing-word-count-sort=\"1181\"&gt;\\n&lt;div class=\"thumbnail\"&gt;\\n&lt;p&gt;&lt;a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\"&gt;\\n&lt;p class=\"card-img-top\"&gt;&lt;img \n",
       "src=\"images/self-supervised-learning.png\"  class=\"thumbnail-image card-img\"/&gt;&lt;/p&gt;\\n&lt;/a&gt;&lt;p&gt;&lt;a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\"&gt;&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;\\n&lt;div \n",
       "class=\"body\"&gt;\\n&lt;h3 class=\"no-anchor listing-title\"&gt;\\n&lt;a\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       "idden\"&gt;&lt;div class=\"react-directory-filename-cell\"&gt;&lt;div class=\"react-directory-truncate\"&gt;&lt;a title=\"README.md\" \n",
       "aria-label=\"README.md, (File)\" class=\"Link--primary\" \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/blob/master/README.md\"&gt;README.md&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/\n",
       "td&gt;&lt;td class=\"react-directory-row-commit-cell\"&gt;&lt;div class=\"Skeleton Skeleton--text\"&gt;\\xa0&lt;/div&gt;&lt;/td&gt;&lt;td&gt;&lt;div \n",
       "class=\"Skeleton Skeleton--text\"&gt;\\xa0&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=\"Box-sc-g0xbh4-0 eNCcrz d-none\" \n",
       "data-testid=\"view-all-files-row\"&gt;&lt;td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 bHTcCe\"&gt;&lt;div&gt;&lt;button \n",
       "class=\"prc-Link-Link-85e08\"&gt;View all files&lt;/button&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div \n",
       "class=\"Box-sc-g0xbh4-0 csrIcr\"&gt;&lt;div class=\"Box-sc-g0xbh4-0 bUQNHB\"&gt;&lt;div itemscope=\"\" \n",
       "itemType=\"https://schema.org/abstract\" class=\"Box-sc-g0xbh4-0 jPdcfu\"&gt;&lt;h2 \n",
       "class=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 brGdpi\"&gt;Repository files navigation&lt;/h2&gt;&lt;nav \n",
       "class=\"UnderlineTabbedInterface__StyledComponentUnderlineWrapper-sc-4ilrg0-0 eBevHz\" aria-label=\"Repository \n",
       "files\"&gt;&lt;ul role=\"list\" class=\"UnderlineTabbedInterface__StyledComponentUnderlineItemList-sc-4ilrg0-1 ehEdWC\"&gt;&lt;li \n",
       "class=\"Box-sc-g0xbh4-0 hUCRAk\"&gt;&lt;a href=\"#\" aria-current=\"page\" \n",
       "class=\"UnderlineTabbedInterface__StyledUnderlineItem-sc-4ilrg0-2 beOdPj\"&gt;&lt;span data-component=\"icon\"&gt;&lt;svg \n",
       "aria-hidden=\"true\" focusable=\"false\" class=\"octicon octicon-book\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" \n",
       "fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"&gt;&lt;path\n",
       "d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 \n",
       ".75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25\n",
       "0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 \n",
       "2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 \n",
       "2.25 0 0 0-2.25 2.25Z\"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;&lt;span data-component=\"text\" \n",
       "data-content=\"README\"&gt;README&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/nav&gt;&lt;/div&gt;&lt;div class=\"Box-sc-g0xbh4-0 QkQOb \n",
       "js-snippet-clipboard-copy-unpositioned undefined\" data-hpc=\"true\"&gt;&lt;article class=\"markdown-body entry-content \n",
       "container-lg\" itemprop=\"text\"&gt;&lt;div class=\"markdown-heading\" dir=\"auto\"&gt;&lt;h1 tabindex=\"-1\" class=\"heading-element\" \n",
       "dir=\"auto\"&gt;deeplearning-architecture&lt;/h1&gt;&lt;a id=\"user-content-deeplearning-architecture\" class=\"anchor\" \n",
       "aria-label=\"Permalink: deeplearning-architecture\" href=\"#deeplearning-architecture\"&gt;&lt;svg class=\"octicon \n",
       "octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"&gt;&lt;path d=\"m7.775 3.275 \n",
       "1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 \n",
       "1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 \n",
       "1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25\n",
       "1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 \n",
       "1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;/div&gt;\\n&lt;p dir=\"auto\"&gt;I am trying to keep \n",
       "record of research papers that I have read or trying to read so \n",
       "far.&lt;/p&gt;\\n&lt;markdown-accessiblity-table&gt;&lt;table&gt;\\n&lt;thead&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Research \n",
       "Papers&lt;/th&gt;\\n&lt;th&gt;Link&lt;/th&gt;\\n&lt;/tr&gt;\\n&lt;/thead&gt;\\n&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;td&gt;ImageNet Classification with Deep Convolutional \n",
       "Neural Networks (AlexNet)&lt;/td&gt;\\n&lt;td&gt;&lt;a \n",
       "href=\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" \n",
       "rel=\"nofollow\"&gt;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pd\n",
       "f&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Very Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/pdf/1409.1556.pdf\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/pdf/1409.1556.pdf&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Going Deeper with Convolutions \n",
       "(GoogLeNet)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1409.4842\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1409.4842&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Rich feature hierarchies for accurate \n",
       "object detection and semantic segmentation (R-CNN)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1311.2524\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1311.2524&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;U-Net: Convolutional Networks for \n",
       "Biomedical Image Segmentation&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1505.04597\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1505.04597&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;A Neural Algorithm of Artistic \n",
       "Style&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1508.06576\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1508.06576&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Generative Adversarial \n",
       "Networks&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1406.2661\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1406.2661&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Conditional Generative Adversarial \n",
       "Nets&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1411.1784\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1411.1784&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Unsupervised Representation Learning with\n",
       "Deep Convolutional Generative Adversarial Networks (DCGAN)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1511.06434\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1511.06434&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Image-to-Image Translation with \n",
       "Conditional Adversarial Networks (pix2pix)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1611.07004\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1611.07004&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;Unpaired Image-to-Image Translation \n",
       "using Cycle-Consistent Adversarial Networks (CycleGAN)&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1703.10593\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1703.10593&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr&gt;\\n&lt;td&gt;MobileNets: Efficient Convolutional \n",
       "Neural Networks for Mobile Vision Applications&lt;/td&gt;\\n&lt;td&gt;&lt;a href=\"https://arxiv.org/abs/1704.04861\" \n",
       "rel=\"nofollow\"&gt;https://arxiv.org/abs/1704.04861&lt;/a&gt;&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;/tbody&gt;\\n&lt;/table&gt;&lt;/markdown-accessiblity-table&gt;\\n\n",
       "&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; &lt;!-- --&gt; &lt;!-- --&gt; &lt;script type=\"application/json\" \n",
       "id=\"__PRIMER_DATA_:R0:__\"&gt;{\"resolvedServerColorMode\":\"day\"}&lt;/script&gt;&lt;/div&gt;\\n&lt;/react-partial&gt;\\n\\n      &lt;input \n",
       "type=\"hidden\" data-csrf=\"true\" \n",
       "value=\"0hdd7oDMutqK5cyvH4iWIGeWUV6nVYJ0WCQ45/cYztnZiQTRHuVx9r2SZJrUye/cGPbcMVxBu09skaixg4uNcg==\" /&gt;\\n&lt;/div&gt;\\n  &lt;div\n",
       "data-view-component=\"true\" class=\"Layout-sidebar\"&gt;      \\n\\n      &lt;div class=\"BorderGrid about-margin\" data-pjax&gt;\\n\n",
       "&lt;div class=\"BorderGrid-row\"&gt;\\n          &lt;div class=\"BorderGrid-cell\"&gt;\\n            &lt;div class=\"hide-sm hide-md\"&gt;\\n \n",
       "&lt;h2 class=\"mb-3 h4\"&gt;About&lt;/h2&gt;\\n\\n      &lt;div class=\"f4 my-3 color-fg-muted text-italic\"&gt;\\n        No description, \n",
       "website, or topics provided.\\n      &lt;/div&gt;\\n\\n\\n    &lt;h3 class=\"sr-only\"&gt;Resources&lt;/h3&gt;\\n    &lt;div class=\"mt-2\"&gt;\\n   \n",
       "&lt;a class=\"Link--muted\" data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Repository \n",
       "Overview&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;click&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;location:sidebar;file:readme&amp;quot;}\" \n",
       "href=\"#readme-ov-file\"&gt;\\n        &lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-book mr-2\"&gt;\\n    &lt;path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 \n",
       "0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0\n",
       "0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 \n",
       "10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 \n",
       "7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n        Readme\\n&lt;/a&gt;\n",
       "&lt;/div&gt;\\n\\n  \\n\\n\\n\\n  &lt;include-fragment  \n",
       "src=\"/nepalprabin/deeplearning-paper-implementation/hovercards/citation/sidebar_partial?tree_name=master\"&gt;\\n  \n",
       "&lt;/include-fragment&gt;\\n\\n  &lt;div class=\"mt-2\"&gt;\\n    &lt;a href=\"/nepalprabin/deeplearning-paper-implementation/activity\" \n",
       "data-view-component=\"true\" class=\"Link Link--muted\"&gt;&lt;svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16\n",
       "16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-2\"&gt;\\n    &lt;path d=\"M6 2c.306\n",
       "0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 \n",
       "0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 \n",
       "2Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;span class=\"color-fg-muted\"&gt;Activity&lt;/span&gt;&lt;/a&gt;  &lt;/div&gt;\\n\\n\\n  &lt;h3 \n",
       "class=\"sr-only\"&gt;Stars&lt;/h3&gt;\\n  &lt;div class=\"mt-2\"&gt;\\n    &lt;a \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/stargazers\" data-view-component=\"true\" class=\"Link \n",
       "Link--muted\"&gt;&lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-star mr-2\"&gt;\\n    &lt;path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 \n",
       "3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0\n",
       "0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 \n",
       "5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 \n",
       "0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 \n",
       "2.694Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;strong&gt;3&lt;/strong&gt;\\n      stars&lt;/a&gt;  &lt;/div&gt;\\n\\n  &lt;h3 class=\"sr-only\"&gt;Watchers&lt;/h3&gt;\\n\n",
       "&lt;div class=\"mt-2\"&gt;\\n    &lt;a href=\"/nepalprabin/deeplearning-paper-implementation/watchers\" \n",
       "data-view-component=\"true\" class=\"Link Link--muted\"&gt;&lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" \n",
       "version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-eye mr-2\"&gt;\\n    &lt;path d=\"M8 2c1.981 0 \n",
       "3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 \n",
       "3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 \n",
       "0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 \n",
       "1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 \n",
       "2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 \n",
       "0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 \n",
       "10Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;strong&gt;2&lt;/strong&gt;\\n      watching&lt;/a&gt;  &lt;/div&gt;\\n\\n  &lt;h3 class=\"sr-only\"&gt;Forks&lt;/h3&gt;\\n  \n",
       "&lt;div class=\"mt-2\"&gt;\\n    &lt;a href=\"/nepalprabin/deeplearning-paper-implementation/forks\" data-view-component=\"true\" \n",
       "class=\"Link Link--muted\"&gt;&lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\"&gt;\\n    &lt;path d=\"M5 5.372v.878c0 \n",
       ".414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 \n",
       "2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 \n",
       "3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 \n",
       "0 .75.75 0 0 0 1.5 0Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;strong&gt;1&lt;/strong&gt;\\n      fork&lt;/a&gt;  &lt;/div&gt;\\n\\n    &lt;div \n",
       "class=\"mt-2\"&gt;\\n      &lt;a class=\"Link--muted\" \n",
       "href=\"/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fnepalprabin%2Fdeeplearning-paper-implementatio\n",
       "n&amp;amp;report=nepalprabin+%28user%29\"&gt;\\n          Report repository\\n&lt;/a&gt;    &lt;/div&gt;\\n&lt;/div&gt;\\n\\n          &lt;/div&gt;\\n   \n",
       "&lt;/div&gt;\\n\\n        \\n            &lt;div class=\"BorderGrid-row\"&gt;\\n              &lt;div class=\"BorderGrid-cell\"&gt;\\n        \n",
       "&lt;h2 class=\"h4 mb-3\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\"&gt;\\n  &lt;a \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/releases\" data-view-component=\"true\" class=\"Link--primary \n",
       "no-underline Link\"&gt;Releases&lt;/a&gt;&lt;/h2&gt;\\n\\n    &lt;div class=\"text-small color-fg-muted\"&gt;No releases published&lt;/div&gt;\\n\\n \n",
       "&lt;/div&gt;\\n            &lt;/div&gt;\\n\\n        \\n        \\n            &lt;div class=\"BorderGrid-row\"&gt;\\n              &lt;div \n",
       "class=\"BorderGrid-cell\"&gt;\\n                \\n  &lt;h2 class=\"h4 mb-3\"&gt;\\n  &lt;a \n",
       "href=\"/users/nepalprabin/packages?repo_name=deeplearning-paper-implementation\" data-view-component=\"true\" \n",
       "class=\"Link--primary no-underline Link d-flex flex-items-center\"&gt;Packages\\n      &lt;span title=\"0\" hidden=\"hidden\" \n",
       "data-view-component=\"true\" class=\"Counter ml-1\"&gt;0&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;\\n\\n\\n      &lt;div class=\"text-small color-fg-muted\"\n",
       "&gt;\\n        No packages published &lt;br&gt;\\n      &lt;/div&gt;\\n\\n\\n\\n              &lt;/div&gt;\\n            &lt;/div&gt;\\n\\n        \\n  \n",
       "&lt;div class=\"BorderGrid-row\" hidden&gt;\\n              &lt;div class=\"BorderGrid-cell\"&gt;\\n                &lt;include-fragment\n",
       "src=\"/nepalprabin/deeplearning-paper-implementation/used_by_list\" \n",
       "accept=\"text/fragment+html\"&gt;\\n&lt;/include-fragment&gt;\\n              &lt;/div&gt;\\n            &lt;/div&gt;\\n\\n        \\n        \\n\n",
       "\\n            &lt;div class=\"BorderGrid-row\"&gt;\\n              &lt;div class=\"BorderGrid-cell\"&gt;\\n                &lt;h2 \n",
       "class=\"h4 mb-3\"&gt;Languages&lt;/h2&gt;\\n&lt;div class=\"mb-2\"&gt;\\n  &lt;span data-view-component=\"true\" class=\"Progress\"&gt;\\n    &lt;span\n",
       "style=\"background-color:#DA5B0B !important;;width: 100.0%;\" itemprop=\"keywords\" data-view-component=\"true\" \n",
       "class=\"Progress-item color-bg-success-emphasis\"&gt;&lt;/span&gt;\\n&lt;/span&gt;&lt;/div&gt;\\n&lt;ul class=\"list-style-none\"&gt;\\n    &lt;li \n",
       "class=\"d-inline\"&gt;\\n        &lt;a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline \n",
       "text-small mr-3\" href=\"/nepalprabin/deeplearning-paper-implementation/search?l=jupyter-notebook\"  \n",
       "data-ga-click=\"Repository, language stats search click, location:repo overview\"&gt;\\n          &lt;svg \n",
       "style=\"color:#DA5B0B;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\"&gt;\\n    &lt;path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 \n",
       "0-8Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n          &lt;span class=\"color-fg-default text-bold mr-1\"&gt;Jupyter Notebook&lt;/span&gt;\\n          \n",
       "&lt;span&gt;100.0%&lt;/span&gt;\\n        &lt;/a&gt;\\n    &lt;/li&gt;\\n&lt;/ul&gt;\\n\\n              &lt;/div&gt;\\n            &lt;/div&gt;\\n\\n              \n",
       "&lt;/div&gt;\\n&lt;/div&gt;\\n  \\n&lt;/div&gt;&lt;/div&gt;\\n\\n  &lt;/div&gt;\\n\\n\\n  &lt;/div&gt;\\n\\n&lt;/turbo-frame&gt;\\n\\n\\n    &lt;/main&gt;\\n  &lt;/div&gt;\\n\\n  \n",
       "&lt;/div&gt;\\n\\n          &lt;footer class=\"footer pt-8 pb-6 f6 color-fg-muted p-responsive\" role=\"contentinfo\" &gt;\\n  &lt;h2 \n",
       "class=\\'sr-only\\'&gt;Footer&lt;/h2&gt;\\n\\n  \\n\\n\\n  &lt;div class=\"d-flex flex-justify-center flex-items-center \n",
       "flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap\"&gt;\\n    &lt;div class=\"d-flex flex-items-center flex-shrink-0 \n",
       "mx-2\"&gt;\\n      &lt;a aria-label=\"Homepage\" title=\"GitHub\" class=\"footer-octicon mr-2\" href=\"https://github.com\"&gt;\\n     \n",
       "&lt;svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-mark-github\"&gt;\\n    &lt;path d=\"M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 \n",
       "10.91.575.101.79-.244.79-.546 \n",
       "0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014\n",
       "-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 \n",
       "3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 \n",
       "1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 \n",
       "2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 \n",
       "4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 \n",
       "21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n&lt;/a&gt;\\n      &lt;span&gt;\\n        &amp;copy; 2025 \n",
       "GitHub,&amp;nbsp;Inc.\\n      &lt;/span&gt;\\n    &lt;/div&gt;\\n\\n    &lt;nav aria-label=\"Footer\"&gt;\\n      &lt;h3 class=\"sr-only\" \n",
       "id=\"sr-footer-heading\"&gt;Footer navigation&lt;/h3&gt;\\n\\n      &lt;ul class=\"list-style-none d-flex flex-justify-center \n",
       "flex-wrap mb-2 mb-lg-0\" aria-labelledby=\"sr-footer-heading\"&gt;\\n\\n          &lt;li class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "Terms&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:terms&amp;quot;}\" \n",
       "href=\"https://docs.github.com/site-policy/github-terms/github-terms-of-service\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\"&gt;Terms&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "privacy&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:privacy&amp;quot;}\" \n",
       "href=\"https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\"&gt;Privacy&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "security&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:security&amp;quot;}\" href=\"https://github.com/security\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\"&gt;Security&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li \n",
       "class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "status&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:status&amp;quot;}\" href=\"https://www.githubstatus.com/\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\"&gt;Status&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li \n",
       "class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "docs&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:docs&amp;quot;}\" href=\"https://docs.github.com/\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\"&gt;Docs&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li class=\"mx-2\"&gt;\\n            &lt;a \n",
       "data-analytics-event=\"{&amp;quot;category&amp;quot;:&amp;quot;Footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;go to \n",
       "contact&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;text:contact&amp;quot;}\" href=\"https://support.github.com?tags=dotcom-footer\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\"&gt;Contact&lt;/a&gt;\\n          &lt;/li&gt;\\n\\n          &lt;li class=\"mx-2\" \n",
       "&gt;\\n  &lt;cookie-consent-link&gt;\\n    &lt;button\\n      type=\"button\"\\n      class=\"Link--secondary underline-on-hover \n",
       "border-0 p-0 color-bg-transparent\"\\n      data-action=\"click:cookie-consent-link#showConsentManagement\"\\n      \n",
       "data-analytics-event=\"{&amp;quot;location&amp;quot;:&amp;quot;footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;cookies&amp;quot;,&amp;quot;context\n",
       "&amp;quot;:&amp;quot;subfooter&amp;quot;,&amp;quot;tag&amp;quot;:&amp;quot;link&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;cookies_link_subfooter_footer\n",
       "&amp;quot;}\"\\n    &gt;\\n      Manage cookies\\n    &lt;/button&gt;\\n  &lt;/cookie-consent-link&gt;\\n&lt;/li&gt;\\n\\n&lt;li class=\"mx-2\"&gt;\\n  \n",
       "&lt;cookie-consent-link&gt;\\n    &lt;button\\n      type=\"button\"\\n      class=\"Link--secondary underline-on-hover border-0 \n",
       "p-0 color-bg-transparent\"\\n      data-action=\"click:cookie-consent-link#showConsentManagement\"\\n      \n",
       "data-analytics-event=\"{&amp;quot;location&amp;quot;:&amp;quot;footer&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;dont_share_info&amp;quot;,&amp;quot\n",
       ";context&amp;quot;:&amp;quot;subfooter&amp;quot;,&amp;quot;tag&amp;quot;:&amp;quot;link&amp;quot;,&amp;quot;label&amp;quot;:&amp;quot;dont_share_info_link_\n",
       "subfooter_footer&amp;quot;}\"\\n    &gt;\\n      Do not share my personal information\\n    &lt;/button&gt;\\n  \n",
       "&lt;/cookie-consent-link&gt;\\n&lt;/li&gt;\\n\\n      &lt;/ul&gt;\\n    &lt;/nav&gt;\\n  &lt;/div&gt;\\n&lt;/footer&gt;\\n\\n\\n\\n    &lt;ghcc-consent id=\"ghcc\" \n",
       "class=\"position-fixed bottom-0 left-0\" style=\"z-index: 999999\" data-initial-cookie-consent-allowed=\"\" \n",
       "data-cookie-consent-required=\"false\"&gt;&lt;/ghcc-consent&gt;\\n\\n\\n\\n  &lt;div id=\"ajax-error-message\" \n",
       "class=\"ajax-error-message flash flash-error\" hidden&gt;\\n    &lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" \n",
       "version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\"&gt;\\n    &lt;path d=\"M6.457 \n",
       "1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 \n",
       "1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 \n",
       "3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n    \n",
       "&lt;button type=\"button\" class=\"flash-close js-ajax-error-dismiss\" aria-label=\"Dismiss error\"&gt;\\n      &lt;svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-x\"&gt;\\n    &lt;path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 \n",
       "1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 \n",
       "3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n   \n",
       "&lt;/button&gt;\\n    You can’t perform that action at this time.\\n  &lt;/div&gt;\\n\\n    &lt;template id=\"site-details-dialog\"&gt;\\n  \n",
       "&lt;details class=\"details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm\" open&gt;\\n    \n",
       "&lt;summary role=\"button\" aria-label=\"Close dialog\"&gt;&lt;/summary&gt;\\n    &lt;details-dialog class=\"Box Box--overlay d-flex \n",
       "flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal\"&gt;\\n      &lt;button class=\"Box-btn-octicon m-0 btn-octicon \n",
       "position-absolute right-0 top-0\" type=\"button\" aria-label=\"Close dialog\" data-close-dialog&gt;\\n        &lt;svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-x\"&gt;\\n    &lt;path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 \n",
       "1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 \n",
       "3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n   \n",
       "&lt;/button&gt;\\n      &lt;div class=\"octocat-spinner my-6 js-details-dialog-spinner\"&gt;&lt;/div&gt;\\n    &lt;/details-dialog&gt;\\n  \n",
       "&lt;/details&gt;\\n&lt;/template&gt;\\n\\n    &lt;div class=\"Popover js-hovercard-content position-absolute\" style=\"display: none; \n",
       "outline: none;\"&gt;\\n  &lt;div class=\"Popover-message Popover-message--bottom-left Popover-message--large Box \n",
       "color-shadow-large\" style=\"width:360px;\"&gt;\\n  &lt;/div&gt;\\n&lt;/div&gt;\\n\\n    &lt;template id=\"snippet-clipboard-copy-button\"&gt;\\n \n",
       "&lt;div class=\"zeroclipboard-container position-absolute right-0 top-0\"&gt;\\n    &lt;clipboard-copy aria-label=\"Copy\" \n",
       "class=\"ClipboardButton btn js-clipboard-copy m-2 p-0\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\"&gt;\\n   \n",
       "&lt;svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-copy js-clipboard-copy-icon m-2\"&gt;\\n    &lt;path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 \n",
       "1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 \n",
       "1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"&gt;&lt;/path&gt;&lt;path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 \n",
       ".784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 \n",
       ".138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2\"&gt;\\n    &lt;path d=\"M13.78 4.22a.75.75\n",
       "0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 \n",
       "10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n    &lt;/clipboard-copy&gt;\\n  &lt;/div&gt;\\n&lt;/template&gt;\\n&lt;template \n",
       "id=\"snippet-clipboard-copy-button-unpositioned\"&gt;\\n  &lt;div class=\"zeroclipboard-container\"&gt;\\n    &lt;clipboard-copy \n",
       "aria-label=\"Copy\" class=\"ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center \n",
       "flex-items-center\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\"&gt;\\n      &lt;svg aria-hidden=\"true\" \n",
       "height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy \n",
       "js-clipboard-copy-icon\"&gt;\\n    &lt;path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 \n",
       "0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 \n",
       "16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"&gt;&lt;/path&gt;&lt;path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 \n",
       "1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 \n",
       ".138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n      &lt;svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none\"&gt;\\n    &lt;path d=\"M13.78 4.22a.75.75 0 0\n",
       "1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 \n",
       "10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"&gt;&lt;/path&gt;\\n&lt;/svg&gt;\\n    &lt;/clipboard-copy&gt;\\n  &lt;/div&gt;\\n&lt;/template&gt;\\n\\n\\n\\n\\n    \n",
       "&lt;/div&gt;\\n\\n    &lt;div id=\"js-global-screen-reader-notice\" class=\"sr-only mt-n1\" aria-live=\"polite\" aria-atomic=\"true\" \n",
       "&gt;&lt;/div&gt;\\n    &lt;div id=\"js-global-screen-reader-notice-assertive\" class=\"sr-only mt-n1\" aria-live=\"assertive\" \n",
       "aria-atomic=\"true\"&gt;&lt;/div&gt;\\n  &lt;/body&gt;\\n&lt;/html&gt;\\n\\n', 'depth': 2}}, 'stats': {'pages_discovered': 539, \n",
       "'pages_crawled': 97, 'start_time': '2025-03-05T17:53:38.107378', 'end_time': '2025-03-05T17:54:58.242979', \n",
       "'total_pages_crawled': 97}}\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "{'pages': {'https://nepalprabin.github.io': {'title': 'Prabin Nepal', 'html': '<!DOCTYPE html>\\n<html \n",
       "xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"><head>\\n\\n<meta charset=\"utf-8\">\\n<meta \n",
       "name=\"generator\" content=\"quarto-1.6.42\">\\n\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes\">\\n\\n\\n<title>Prabin Nepal</title>\\n<style>\\ncode{white-space: \n",
       "pre-wrap;}\\nspan.smallcaps{font-variant: small-caps;}\\ndiv.columns{display: flex; gap: min(4vw, \n",
       "1.5em);}\\ndiv.column{flex: auto; overflow-x: auto;}\\ndiv.hanging-indent{margin-left: 1.5em; text-indent: \n",
       "-1.5em;}\\nul.task-list{list-style: none;}\\nul.task-list li input[type=\"checkbox\"] {\\n  width: 0.8em;\\n  margin: 0 \n",
       "0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ \\n  \n",
       "vertical-align: middle;\\n}\\n</style>\\n\\n\\n<script src=\"site_libs/quarto-nav/quarto-nav.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-nav/headroom.min.js\"></script>\\n<script \n",
       "src=\"site_libs/clipboard/clipboard.min.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-search/autocomplete.umd.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-search/fuse.min.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-search/quarto-search.js\"></script>\\n<meta name=\"quarto:offset\" content=\"./\">\\n<script \n",
       "src=\"site_libs/quarto-listing/list.min.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-listing/quarto-listing.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-html/quarto.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-html/popper.min.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-html/tippy.umd.min.js\"></script>\\n<script \n",
       "src=\"site_libs/quarto-html/anchor.min.js\"></script>\\n<link href=\"site_libs/quarto-html/tippy.css\" \n",
       "rel=\"stylesheet\">\\n<link \n",
       "href=\"site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css\" rel=\"stylesheet\" \n",
       "class=\"quarto-color-scheme\" id=\"quarto-text-highlighting-styles\">\\n<link \n",
       "href=\"site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css\" rel=\"stylesheet\" \n",
       "class=\"quarto-color-scheme quarto-color-alternate\" id=\"quarto-text-highlighting-styles\">\\n<script \n",
       "src=\"site_libs/bootstrap/bootstrap.min.js\"></script>\\n<link href=\"site_libs/bootstrap/bootstrap-icons.css\" \n",
       "rel=\"stylesheet\">\\n<link href=\"site_libs/bootstrap/bootstrap-d75320580429fd03ccc14abf5aea7e44.min.css\" \n",
       "rel=\"stylesheet\" append-hash=\"true\" class=\"quarto-color-scheme\" id=\"quarto-bootstrap\" data-mode=\"light\">\\n<link \n",
       "href=\"site_libs/bootstrap/bootstrap-dark-03cff2e87a80ce85282700c0d3d2a4d3.min.css\" rel=\"stylesheet\" \n",
       "append-hash=\"true\" class=\"quarto-color-scheme quarto-color-alternate\" id=\"quarto-bootstrap\" \n",
       "data-mode=\"dark\">\\n<script id=\"quarto-search-options\" type=\"application/json\">{\\n  \"location\": \"navbar\",\\n  \n",
       "\"copy-button\": false,\\n  \"collapse-after\": 3,\\n  \"panel-placement\": \"end\",\\n  \"type\": \"overlay\",\\n  \"limit\": 50,\\n \n",
       "\"keyboard-shortcut\": [\\n    \"f\",\\n    \"/\",\\n    \"s\"\\n  ],\\n  \"show-item-context\": false,\\n  \"language\": {\\n    \n",
       "\"search-no-results-text\": \"No results\",\\n    \"search-matching-documents-text\": \"matching documents\",\\n    \n",
       "\"search-copy-link-title\": \"Copy link to search\",\\n    \"search-hide-matches-text\": \"Hide additional matches\",\\n    \n",
       "\"search-more-match-text\": \"more match in this document\",\\n    \"search-more-matches-text\": \"more matches in this \n",
       "document\",\\n    \"search-clear-button-title\": \"Clear\",\\n    \"search-text-placeholder\": \"\",\\n    \n",
       "\"search-detached-cancel-button-title\": \"Cancel\",\\n    \"search-submit-button-title\": \"Submit\",\\n    \"search-label\": \n",
       "\"Search\"\\n  }\\n}</script>\\n<script>\\n\\n  window.document.addEventListener(\"DOMContentLoaded\", function (_event) {\\n\n",
       "const listingTargetEl = window.document.querySelector(\\'#listing-listing .list\\');\\n    if (!listingTargetEl) {\\n  \n",
       "// No listing discovered, do not attach.\\n      return; \\n    }\\n\\n    const options = {\\n      valueNames: \n",
       "[\\'listing-date\\',\\'listing-title\\',\\'listing-author\\',\\'listing-image\\',\\'listing-description\\',\\'listing-categori\n",
       "es\\',{ data: [\\'index\\'] },{ data: [\\'categories\\'] },{ data: [\\'listing-date-sort\\'] },{ data: \n",
       "[\\'listing-file-modified-sort\\'] }],\\n      \\n      searchColumns: \n",
       "[\"listing-date\",\"listing-title\",\"listing-author\",\"listing-image\",\"listing-description\",\"listing-categories\"],\\n    \n",
       "};\\n\\n    window[\\'quarto-listings\\'] = window[\\'quarto-listings\\'] || {};\\n    \n",
       "window[\\'quarto-listings\\'][\\'listing-listing\\'] = new List(\\'listing-listing\\', options);\\n\\n    if \n",
       "(window[\\'quarto-listing-loaded\\']) {\\n      window[\\'quarto-listing-loaded\\']();\\n    }\\n  });\\n\\n  \n",
       "window.addEventListener(\\'hashchange\\',() => {\\n    if (window[\\'quarto-listing-loaded\\']) {\\n      \n",
       "window[\\'quarto-listing-loaded\\']();\\n    }\\n  })\\n  </script>\\n<script async=\"\" \n",
       "src=\"https://www.googletagmanager.com/gtag/js?id=G-5HCLVN4PVB\"></script>\\n\\n<script \n",
       "type=\"text/javascript\">\\n\\nwindow.dataLayer = window.dataLayer || [];\\nfunction \n",
       "gtag(){dataLayer.push(arguments);}\\ngtag(\\'js\\', new Date());\\ngtag(\\'config\\', \\'G-5HCLVN4PVB\\', { \n",
       "\\'anonymize_ip\\': true});\\n</script>\\n\\n  <script \n",
       "src=\"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6\"></script>\\n  <script \n",
       "src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js\" type=\"text/javascript\"></script>\\n\\n<script \n",
       "type=\"text/javascript\">\\nconst typesetMath = (el) => {\\n  if (window.MathJax) {\\n    // MathJax Typeset\\n    \n",
       "window.MathJax.typeset([el]);\\n  } else if (window.katex) {\\n    // KaTeX Render\\n    var mathElements = \n",
       "el.getElementsByClassName(\"math\");\\n    var macros = [];\\n    for (var i = 0; i < mathElements.length; i++) {\\n    \n",
       "var texText = mathElements[i].firstChild;\\n      if (mathElements[i].tagName == \"SPAN\") {\\n        \n",
       "window.katex.render(texText.data, mathElements[i], {\\n          displayMode: \n",
       "mathElements[i].classList.contains(\\'display\\'),\\n          throwOnError: false,\\n          macros: macros,\\n      \n",
       "fleqn: false\\n        });\\n      }\\n    }\\n  }\\n}\\nwindow.Quarto = {\\n  typesetMath\\n};\\n</script>\\n\\n<link \n",
       "rel=\"stylesheet\" href=\"styles.css\">\\n<meta property=\"og:title\" content=\"Prabin Nepal\">\\n<meta property=\"og:image\" \n",
       "content=\"https://nepalprabin.github.io/images/ai_agents.png\">\\n<meta property=\"og:site_name\" content=\"Prabin \n",
       "Nepal\">\\n<meta property=\"og:image:height\" content=\"768\">\\n<meta property=\"og:image:width\" \n",
       "content=\"1024\">\\n</head>\\n\\n<body class=\"nav-fixed\">\\n\\n<div id=\"quarto-search-results\"></div>\\n  <header \n",
       "id=\"quarto-header\" class=\"headroom fixed-top quarto-banner\">\\n    <nav class=\"navbar navbar-expand-lg \" \n",
       "data-bs-theme=\"dark\">\\n      <div class=\"navbar-container container-fluid\">\\n      <div \n",
       "class=\"navbar-brand-container mx-auto\">\\n    <a class=\"navbar-brand\" href=\"./index.html\">\\n    <span \n",
       "class=\"navbar-title\">Prabin Nepal</span>\\n    </a>\\n  </div>\\n            <div id=\"quarto-search\" class=\"\" \n",
       "title=\"Search\"></div>\\n          <button class=\"navbar-toggler\" type=\"button\" data-bs-toggle=\"collapse\" \n",
       "data-bs-target=\"#navbarCollapse\" aria-controls=\"navbarCollapse\" role=\"menu\" aria-expanded=\"false\" \n",
       "aria-label=\"Toggle navigation\" onclick=\"if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }\">\\n  \n",
       "<span class=\"navbar-toggler-icon\"></span>\\n</button>\\n          <div class=\"collapse navbar-collapse\" \n",
       "id=\"navbarCollapse\">\\n            <ul class=\"navbar-nav navbar-nav-scroll ms-auto\">\\n  <li class=\"nav-item\">\\n    \n",
       "<a class=\"nav-link\" href=\"./projects.html\"> \\n<span class=\"menu-text\">Projects</span></a>\\n  </li>  \\n  <li \n",
       "class=\"nav-item compact\">\\n    <a class=\"nav-link\" href=\"https://github.com/nepalprabin\"> <i class=\"bi bi-github\" \n",
       "role=\"img\">\\n</i> \\n<span class=\"menu-text\"></span></a>\\n  </li>  \\n  <li class=\"nav-item compact\">\\n    <a \n",
       "class=\"nav-link\" href=\"https://linkedin.com/in/prabin-nepal\"> <i class=\"bi bi-linkedin\" role=\"img\">\\n</i> \\n<span \n",
       "class=\"menu-text\"></span></a>\\n  </li>  \\n</ul>\\n          </div> <!-- /navcollapse -->\\n            <div \n",
       "class=\"quarto-navbar-tools\">\\n  <a href=\"\" class=\"quarto-color-scheme-toggle quarto-navigation-tool  px-1\" \n",
       "onclick=\"window.quartoToggleColorScheme(); return false;\" title=\"Toggle dark mode\"><i class=\"bi\"></i></a>\\n</div>\\n\n",
       "</div> <!-- /container-fluid -->\\n    </nav>\\n</header>\\n<!-- content -->\\n<header id=\"title-block-header\" \n",
       "class=\"quarto-title-block\"></header><div id=\"quarto-content\" class=\"quarto-container page-columns \n",
       "page-rows-contents page-layout-full page-navbar\">\\n<!-- sidebar -->\\n<!-- margin-sidebar -->\\n    <div \n",
       "id=\"quarto-margin-sidebar\" class=\"sidebar margin-sidebar\">\\n        \\n    <h5 \n",
       "class=\"quarto-listing-category-title\">Categories</h5><div class=\"quarto-listing-category category-default\"><div \n",
       "class=\"category\" data-category=\"\">All <span class=\"quarto-category-count\">(16)</span></div><div class=\"category\" \n",
       "data-category=\"TExN\">LLM <span class=\"quarto-category-count\">(1)</span></div><div class=\"category\" \n",
       "data-category=\"TkxQ\">NLP <span class=\"quarto-category-count\">(4)</span></div><div class=\"category\" \n",
       "data-category=\"YWdlbnRz\">agents <span class=\"quarto-category-count\">(1)</span></div><div class=\"category\" \n",
       "data-category=\"Y29tcHV0ZXItdmlzaW9u\">computer-vision <span class=\"quarto-category-count\">(6)</span></div><div \n",
       "class=\"category\" data-category=\"ZGVlcC1sZWFybmluZw==\">deep-learning <span \n",
       "class=\"quarto-category-count\">(12)</span></div><div class=\"category\" data-category=\"bGxtcw==\">llms <span \n",
       "class=\"quarto-category-count\">(1)</span></div><div class=\"category\" \n",
       "data-category=\"bWFjaGluZS1sZWFybmluZw==\">machine-learning <span class=\"quarto-category-count\">(2)</span></div><div \n",
       "class=\"category\" data-category=\"c2VsZi1zdXBlcnZpc2VkLWxlYXJuaW5n\">self-supervised-learning <span \n",
       "class=\"quarto-category-count\">(1)</span></div></div></div>\\n<!-- main -->\\n<main class=\"content \n",
       "quarto-banner-title-block column-page-left\" id=\"quarto-document-content\">\\n\\n\\n\\n\\n\\n\\n\\n\\n<div \n",
       "class=\"quarto-listing quarto-listing-container-default\" id=\"listing-listing\">\\n<div class=\"list \n",
       "quarto-listing-default\">\\n<div class=\"quarto-post image-right\" data-index=\"0\" \n",
       "data-categories=\"bGxtcyUyQ2FnZW50cw==\" data-listing-date-sort=\"1740873600000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"799\">\\n<div class=\"thumbnail\">\\n<p><a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\">\\n<p><img loading=\"lazy\" \n",
       "src=\"./images/ai_agents.png\" class=\"thumbnail-image\"></p>\\n</a><p><a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"></a></p>\\n</div>\\n<div \n",
       "class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\">Huggingface AI Agents Quiz \n",
       "Solutions</a>\\n</h3>\\n<div class=\"listing-subtitle\">\\n<a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\"></a>\\n</div>\\n<div \n",
       "class=\"listing-categories\">\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'bGxtcw==\\'); \n",
       "return false;\">\\nllms\\n</div>\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'YWdlbnRz\\'); \n",
       "return false;\">\\nagents\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\">I have been diving into AI \n",
       "agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of how to build and\n",
       "deploy AI agents using the <code>smol…</code></a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a \n",
       "href=\"./posts/2025-03-02-huggingface-smolagents-solutions.html\" class=\"no-external\">\\n<div \n",
       "class=\"listing-date\">\\nMar 2, 2025\\n</div>\\n</a>\\n</div>\\n</div>\\n<div class=\"quarto-post image-right\" \n",
       "data-index=\"1\" data-categories=\"bWFjaGluZS1sZWFybmluZyUyQ05MUCUyQ2RlZXAtbGVhcm5pbmclMkNMTE0=\" \n",
       "data-listing-date-sort=\"1688428800000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"9\" data-listing-word-count-sort=\"1630\">\\n<div\n",
       "class=\"thumbnail\">\\n<p><a href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\">\\n<p><img loading=\"lazy\" \n",
       "src=\"./images/augmenting llms.png\" class=\"thumbnail-image\"></p>\\n</a><p><a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\"></a></p>\\n</div>\\n<div \n",
       "class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a href=\"./posts/2023-07-04-augmented-language-models.html\" \n",
       "class=\"no-external\">Augmenting Large Language Models: Expanding Context and Enhancing Relevance</a>\\n</h3>\\n<div \n",
       "class=\"listing-subtitle\">\\n<a href=\"./posts/2023-07-04-augmented-language-models.html\" \n",
       "class=\"no-external\"></a>\\n</div>\\n<div class=\"listing-categories\">\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'bWFjaGluZS1sZWFybmluZw==\\'); return \n",
       "false;\">\\nmachine-learning\\n</div>\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); \n",
       "return false;\">\\nNLP\\n</div>\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return false;\">\\ndeep-learning\\n</div>\\n<div \n",
       "class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TExN\\'); return \n",
       "false;\">\\nLLM\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\">With the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…</a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a \n",
       "href=\"./posts/2023-07-04-augmented-language-models.html\" class=\"no-external\">\\n<div class=\"listing-date\">\\nJul 4, \n",
       "2023\\n</div>\\n</a>\\n</div>\\n</div>\\n<div class=\"quarto-post image-right\" data-index=\"2\" \n",
       "data-categories=\"bWFjaGluZS1sZWFybmluZyUyQ05MUCUyQ2RlZXAtbGVhcm5pbmc=\" data-listing-date-sort=\"1678838400000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"918\">\\n<div class=\"thumbnail\">\\n<p><a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\">\\n<p><img loading=\"lazy\" src=\"./images/gpt-4.jpeg\" \n",
       "class=\"thumbnail-image\"></p>\\n</a><p><a href=\"./posts/2023-05-15-gpt4-summary.html\" \n",
       "class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\">Brief overview of GPT-4</a>\\n</h3>\\n<div \n",
       "class=\"listing-subtitle\">\\n<a href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\"></a>\\n</div>\\n<div \n",
       "class=\"listing-categories\">\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'bWFjaGluZS1sZWFybmluZw==\\'); return \n",
       "false;\">\\nmachine-learning\\n</div>\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); \n",
       "return false;\">\\nNLP\\n</div>\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\">\\ndeep-learning\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2023-05-15-gpt4-summary.html\" class=\"no-external\">Since the release of ChatGPT, there has been \n",
       "significant interest and discussion within the broader AI and natural language processing communities regarding \n",
       "its…<code></code></a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a href=\"./posts/2023-05-15-gpt4-summary.html\" \n",
       "class=\"no-external\">\\n<div class=\"listing-date\">\\nMar 15, 2023\\n</div>\\n</a>\\n</div>\\n</div>\\n<div \n",
       "class=\"quarto-post image-right\" data-index=\"3\" data-categories=\"TkxQJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1666137600000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"10\" \n",
       "data-listing-word-count-sort=\"1880\">\\n<div class=\"thumbnail\">\\n<p><a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\">\\n<p><img loading=\"lazy\" \n",
       "src=\"./images/text-summarization.jpg\" class=\"thumbnail-image\"></p>\\n</a><p><a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3\n",
       "class=\"no-anchor listing-title\">\\n<a href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\">Text\n",
       "Summarization NLP</a>\\n</h3>\\n<div class=\"listing-subtitle\">\\n<a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\"></a>\\n</div>\\n<div \n",
       "class=\"listing-categories\">\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); return \n",
       "false;\">\\nNLP\\n</div>\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\">\\ndeep-learning\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2022-10-19-text-summarization-nlp.html\" class=\"no-external\">Text summarization is one of the Natural \n",
       "Language Processing (NLP) tasks where documents/texts are shortened automatically while holding the same semantic \n",
       "meaning.…</a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a href=\"./posts/2022-10-19-text-summarization-nlp.html\" \n",
       "class=\"no-external\">\\n<div class=\"listing-date\">\\nOct 19, 2022\\n</div>\\n</a>\\n</div>\\n</div>\\n<div \n",
       "class=\"quarto-post image-right\" data-index=\"4\" data-categories=\"TkxQJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1635120000000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"742\">\\n<div \n",
       "class=\"thumbnail\">\\n<p><a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\"></a></p><a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\">\\n<p><img loading=\"lazy\" src=\"./images/autocorrect_example.png\" \n",
       "class=\"thumbnail-image\"></p>\\n</a><p><a href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" \n",
       "class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\">Autocorrect and Minimum \n",
       "Edit Distance</a>\\n</h3>\\n<div class=\"listing-subtitle\">\\n<a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\"></a>\\n</div>\\n<div \n",
       "class=\"listing-categories\">\\n<div class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'TkxQ\\'); return \n",
       "false;\">\\nNLP\\n</div>\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\">\\ndeep-learning\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\">This is my brief note from\n",
       "<em>DeepLearning.AI’s</em> NLP Specialization Course.</a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a \n",
       "href=\"./posts/2021-10-25-autocorrect-and-minimum-edit-distance.html\" class=\"no-external\">\\n<div \n",
       "class=\"listing-date\">\\nOct 25, 2021\\n</div>\\n</a>\\n</div>\\n</div>\\n<div class=\"quarto-post image-right\" \n",
       "data-index=\"5\" data-categories=\"Y29tcHV0ZXItdmlzaW9uJTJDZGVlcC1sZWFybmluZw==\" \n",
       "data-listing-date-sort=\"1627344000000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"919\">\\n<div \n",
       "class=\"thumbnail\">\\n<p><a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\"></a></p><a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\">\\n<p><img loading=\"lazy\" src=\"./images/vision_transformer.gif\" \n",
       "class=\"thumbnail-image\"></p>\\n</a><p><a href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" \n",
       "class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\">Illustrated Vision \n",
       "Transformers</a>\\n</h3>\\n<div class=\"listing-subtitle\">\\n<a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\"></a>\\n</div>\\n<div \n",
       "class=\"listing-categories\">\\n<div class=\"listing-category\" \n",
       "onclick=\"window.quartoListingCategory(\\'Y29tcHV0ZXItdmlzaW9u\\'); return false;\">\\ncomputer-vision\\n</div>\\n<div \n",
       "class=\"listing-category\" onclick=\"window.quartoListingCategory(\\'ZGVlcC1sZWFybmluZw==\\'); return \n",
       "false;\">\\ndeep-learning\\n</div>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\">Ever since Transformer was \n",
       "introduced in 2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP\n",
       "tasks use Transformers and…</a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a \n",
       "href=\"./posts/2021-07-27-illustrated-vision-transformers.html\" class=\"no-external\">\\n<div \n",
       "class=\"listing-date\">\\nJul 27, 2021\\n</div>\\n</a>\\n</div>\\n</div>\\n<div class=\"quarto-post image-right\" \n",
       "data-index=\"6\" data-listing-date-sort=\"1616716800000\" data-listing-file-modified-sort=\"1740955326760\" \n",
       "data-listing-date-modified-sort=\"NaN\" data-listing-reading-time-sort=\"5\" data-listing-word-count-sort=\"901\">\\n<div \n",
       "class=\"thumbnail\">\\n<p><a href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\">\\n<p><img loading=\"lazy\" \n",
       "src=\"./images/contrastive-puzzle.gif\" class=\"thumbnail-image\"></p>\\n</a><p><a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3 \n",
       "class=\"no-anchor listing-title\">\\n<a href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\">Paper \n",
       "Explanation: A Simple Framework for Contrastive Learning of Visual Representations (simCLR)</a>\\n</h3>\\n<div \n",
       "class=\"listing-subtitle\">\\n<a href=\"./posts/2021-03-26-simclr-explained.html\" \n",
       "class=\"no-external\"></a>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2021-03-26-simclr-explained.html\" class=\"no-external\">Various self-supervised learning methods have \n",
       "been proposed in recent years for learning image representations. Though a lot of methods have been proposed, the \n",
       "performance…</a>\\n</div>\\n</div>\\n<div class=\"metadata\">\\n<a href=\"./posts/2021-03-26-simclr-explained.html\" \n",
       "class=\"no-external\">\\n<div class=\"listing-date\">\\nMar 26, 2021\\n</div>\\n</a>\\n</div>\\n</div>\\n<div \n",
       "class=\"quarto-post image-right\" data-index=\"7\" data-listing-date-sort=\"1609459200000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"4\" data-listing-word-count-sort=\"728\">\\n<div class=\"thumbnail\">\\n<p><a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\">\\n<p><img loading=\"lazy\" src=\"./images/residual-block.png\" \n",
       "class=\"thumbnail-image\"></p>\\n</a><p><a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"></a></p>\\n</div>\\n<div class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\">Deep Residual Learning for Image Recognition (ResNet paper explained)</a>\\n</h3>\\n<div \n",
       "class=\"listing-subtitle\">\\n<a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\"></a>\\n</div>\\n<div class=\"listing-description\">\\n<a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\">Deep Neural Networks tend to provide more accuracy as the number of layers increases. But, as \n",
       "we go more deeper in the network, the accuracy of the network decreases instead…<i></i></a>\\n</div>\\n</div>\\n<div \n",
       "class=\"metadata\">\\n<a \n",
       "href=\"./posts/2021-01-01-deep-residual-learning-for-image-recognition-resnet-paper-explained.html\" \n",
       "class=\"no-external\">\\n<div class=\"listing-date\">\\nJan 1, 2021\\n</div>\\n</a>\\n</div>\\n</div>\\n<div \n",
       "class=\"quarto-post image-right\" data-index=\"8\" \n",
       "data-categories=\"ZGVlcC1sZWFybmluZyUyQ3NlbGYtc3VwZXJ2aXNlZC1sZWFybmluZw==\" data-listing-date-sort=\"1607385600000\" \n",
       "data-listing-file-modified-sort=\"1740955326760\" data-listing-date-modified-sort=\"NaN\" \n",
       "data-listing-reading-time-sort=\"6\" data-listing-word-count-sort=\"1181\">\\n<div class=\"thumbnail\">\\n<p><a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\"></a></p><a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\">\\n<p class=\"card-img-top\"><img \n",
       "src=\"images/self-supervised-learning.png\"  class=\"thumbnail-image card-img\"/></p>\\n</a><p><a \n",
       "href=\"./posts/2020-12-08-self-supervised-learning.html\" class=\"no-external\"></a></p>\\n</div>\\n<div \n",
       "class=\"body\">\\n<h3 class=\"no-anchor listing-title\">\\n<a\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       "idden\"><div class=\"react-directory-filename-cell\"><div class=\"react-directory-truncate\"><a title=\"README.md\" \n",
       "aria-label=\"README.md, (File)\" class=\"Link--primary\" \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/blob/master/README.md\">README.md</a></div></div></div></div></\n",
       "td><td class=\"react-directory-row-commit-cell\"><div class=\"Skeleton Skeleton--text\">\\xa0</div></td><td><div \n",
       "class=\"Skeleton Skeleton--text\">\\xa0</div></td></tr><tr class=\"Box-sc-g0xbh4-0 eNCcrz d-none\" \n",
       "data-testid=\"view-all-files-row\"><td colSpan=\"3\" class=\"Box-sc-g0xbh4-0 bHTcCe\"><div><button \n",
       "class=\"prc-Link-Link-85e08\">View all files</button></div></td></tr></tbody></table></div><div \n",
       "class=\"Box-sc-g0xbh4-0 csrIcr\"><div class=\"Box-sc-g0xbh4-0 bUQNHB\"><div itemscope=\"\" \n",
       "itemType=\"https://schema.org/abstract\" class=\"Box-sc-g0xbh4-0 jPdcfu\"><h2 \n",
       "class=\"_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 brGdpi\">Repository files navigation</h2><nav \n",
       "class=\"UnderlineTabbedInterface__StyledComponentUnderlineWrapper-sc-4ilrg0-0 eBevHz\" aria-label=\"Repository \n",
       "files\"><ul role=\"list\" class=\"UnderlineTabbedInterface__StyledComponentUnderlineItemList-sc-4ilrg0-1 ehEdWC\"><li \n",
       "class=\"Box-sc-g0xbh4-0 hUCRAk\"><a href=\"#\" aria-current=\"page\" \n",
       "class=\"UnderlineTabbedInterface__StyledUnderlineItem-sc-4ilrg0-2 beOdPj\"><span data-component=\"icon\"><svg \n",
       "aria-hidden=\"true\" focusable=\"false\" class=\"octicon octicon-book\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" \n",
       "fill=\"currentColor\" style=\"display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible\"><path\n",
       "d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 \n",
       ".75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25\n",
       "0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 \n",
       "2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 \n",
       "2.25 0 0 0-2.25 2.25Z\"></path></svg></span><span data-component=\"text\" \n",
       "data-content=\"README\">README</span></a></li></ul></nav></div><div class=\"Box-sc-g0xbh4-0 QkQOb \n",
       "js-snippet-clipboard-copy-unpositioned undefined\" data-hpc=\"true\"><article class=\"markdown-body entry-content \n",
       "container-lg\" itemprop=\"text\"><div class=\"markdown-heading\" dir=\"auto\"><h1 tabindex=\"-1\" class=\"heading-element\" \n",
       "dir=\"auto\">deeplearning-architecture</h1><a id=\"user-content-deeplearning-architecture\" class=\"anchor\" \n",
       "aria-label=\"Permalink: deeplearning-architecture\" href=\"#deeplearning-architecture\"><svg class=\"octicon \n",
       "octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 \n",
       "1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 \n",
       "1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 \n",
       "1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25\n",
       "1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 \n",
       "1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\\n<p dir=\"auto\">I am trying to keep \n",
       "record of research papers that I have read or trying to read so \n",
       "far.</p>\\n<markdown-accessiblity-table><table>\\n<thead>\\n<tr>\\n<th>Research \n",
       "Papers</th>\\n<th>Link</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>ImageNet Classification with Deep Convolutional \n",
       "Neural Networks (AlexNet)</td>\\n<td><a \n",
       "href=\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" \n",
       "rel=\"nofollow\">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pd\n",
       "f</a></td>\\n</tr>\\n<tr>\\n<td>Very Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)</td>\\n<td><a href=\"https://arxiv.org/pdf/1409.1556.pdf\" \n",
       "rel=\"nofollow\">https://arxiv.org/pdf/1409.1556.pdf</a></td>\\n</tr>\\n<tr>\\n<td>Going Deeper with Convolutions \n",
       "(GoogLeNet)</td>\\n<td><a href=\"https://arxiv.org/abs/1409.4842\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1409.4842</a></td>\\n</tr>\\n<tr>\\n<td>Rich feature hierarchies for accurate \n",
       "object detection and semantic segmentation (R-CNN)</td>\\n<td><a href=\"https://arxiv.org/abs/1311.2524\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1311.2524</a></td>\\n</tr>\\n<tr>\\n<td>U-Net: Convolutional Networks for \n",
       "Biomedical Image Segmentation</td>\\n<td><a href=\"https://arxiv.org/abs/1505.04597\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1505.04597</a></td>\\n</tr>\\n<tr>\\n<td>A Neural Algorithm of Artistic \n",
       "Style</td>\\n<td><a href=\"https://arxiv.org/abs/1508.06576\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1508.06576</a></td>\\n</tr>\\n<tr>\\n<td>Generative Adversarial \n",
       "Networks</td>\\n<td><a href=\"https://arxiv.org/abs/1406.2661\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1406.2661</a></td>\\n</tr>\\n<tr>\\n<td>Conditional Generative Adversarial \n",
       "Nets</td>\\n<td><a href=\"https://arxiv.org/abs/1411.1784\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1411.1784</a></td>\\n</tr>\\n<tr>\\n<td>Unsupervised Representation Learning with\n",
       "Deep Convolutional Generative Adversarial Networks (DCGAN)</td>\\n<td><a href=\"https://arxiv.org/abs/1511.06434\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1511.06434</a></td>\\n</tr>\\n<tr>\\n<td>Image-to-Image Translation with \n",
       "Conditional Adversarial Networks (pix2pix)</td>\\n<td><a href=\"https://arxiv.org/abs/1611.07004\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1611.07004</a></td>\\n</tr>\\n<tr>\\n<td>Unpaired Image-to-Image Translation \n",
       "using Cycle-Consistent Adversarial Networks (CycleGAN)</td>\\n<td><a href=\"https://arxiv.org/abs/1703.10593\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1703.10593</a></td>\\n</tr>\\n<tr>\\n<td>MobileNets: Efficient Convolutional \n",
       "Neural Networks for Mobile Vision Applications</td>\\n<td><a href=\"https://arxiv.org/abs/1704.04861\" \n",
       "rel=\"nofollow\">https://arxiv.org/abs/1704.04861</a></td>\\n</tr>\\n</tbody>\\n</table></markdown-accessiblity-table>\\n\n",
       "</article></div></div></div></div></div> <!-- --> <!-- --> <script type=\"application/json\" \n",
       "id=\"__PRIMER_DATA_:R0:__\">{\"resolvedServerColorMode\":\"day\"}</script></div>\\n</react-partial>\\n\\n      <input \n",
       "type=\"hidden\" data-csrf=\"true\" \n",
       "value=\"0hdd7oDMutqK5cyvH4iWIGeWUV6nVYJ0WCQ45/cYztnZiQTRHuVx9r2SZJrUye/cGPbcMVxBu09skaixg4uNcg==\" />\\n</div>\\n  <div\n",
       "data-view-component=\"true\" class=\"Layout-sidebar\">      \\n\\n      <div class=\"BorderGrid about-margin\" data-pjax>\\n\n",
       "<div class=\"BorderGrid-row\">\\n          <div class=\"BorderGrid-cell\">\\n            <div class=\"hide-sm hide-md\">\\n \n",
       "<h2 class=\"mb-3 h4\">About</h2>\\n\\n      <div class=\"f4 my-3 color-fg-muted text-italic\">\\n        No description, \n",
       "website, or topics provided.\\n      </div>\\n\\n\\n    <h3 class=\"sr-only\">Resources</h3>\\n    <div class=\"mt-2\">\\n   \n",
       "<a class=\"Link--muted\" data-analytics-event=\"{&quot;category&quot;:&quot;Repository \n",
       "Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}\" \n",
       "href=\"#readme-ov-file\">\\n        <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-book mr-2\">\\n    <path d=\"M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 \n",
       "0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0\n",
       "0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 \n",
       "10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 \n",
       "7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z\"></path>\\n</svg>\\n        Readme\\n</a>\n",
       "</div>\\n\\n  \\n\\n\\n\\n  <include-fragment  \n",
       "src=\"/nepalprabin/deeplearning-paper-implementation/hovercards/citation/sidebar_partial?tree_name=master\">\\n  \n",
       "</include-fragment>\\n\\n  <div class=\"mt-2\">\\n    <a href=\"/nepalprabin/deeplearning-paper-implementation/activity\" \n",
       "data-view-component=\"true\" class=\"Link Link--muted\"><svg text=\"gray\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16\n",
       "16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-pulse mr-2\">\\n    <path d=\"M6 2c.306\n",
       "0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 \n",
       "0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 \n",
       "2Z\"></path>\\n</svg>\\n      <span class=\"color-fg-muted\">Activity</span></a>  </div>\\n\\n\\n  <h3 \n",
       "class=\"sr-only\">Stars</h3>\\n  <div class=\"mt-2\">\\n    <a \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/stargazers\" data-view-component=\"true\" class=\"Link \n",
       "Link--muted\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-star mr-2\">\\n    <path d=\"M8 .25a.75.75 0 0 1 .673.418l1.882 \n",
       "3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0\n",
       "0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 \n",
       "5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 \n",
       "0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 \n",
       "2.694Z\"></path>\\n</svg>\\n      <strong>3</strong>\\n      stars</a>  </div>\\n\\n  <h3 class=\"sr-only\">Watchers</h3>\\n\n",
       "<div class=\"mt-2\">\\n    <a href=\"/nepalprabin/deeplearning-paper-implementation/watchers\" \n",
       "data-view-component=\"true\" class=\"Link Link--muted\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" \n",
       "version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-eye mr-2\">\\n    <path d=\"M8 2c1.981 0 \n",
       "3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 \n",
       "3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 \n",
       "0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 \n",
       "1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 \n",
       "2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 \n",
       "0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 \n",
       "10Z\"></path>\\n</svg>\\n      <strong>2</strong>\\n      watching</a>  </div>\\n\\n  <h3 class=\"sr-only\">Forks</h3>\\n  \n",
       "<div class=\"mt-2\">\\n    <a href=\"/nepalprabin/deeplearning-paper-implementation/forks\" data-view-component=\"true\" \n",
       "class=\"Link Link--muted\"><svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-repo-forked mr-2\">\\n    <path d=\"M5 5.372v.878c0 \n",
       ".414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 \n",
       "2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 \n",
       "3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 \n",
       "0 .75.75 0 0 0 1.5 0Z\"></path>\\n</svg>\\n      <strong>1</strong>\\n      fork</a>  </div>\\n\\n    <div \n",
       "class=\"mt-2\">\\n      <a class=\"Link--muted\" \n",
       "href=\"/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fnepalprabin%2Fdeeplearning-paper-implementatio\n",
       "n&amp;report=nepalprabin+%28user%29\">\\n          Report repository\\n</a>    </div>\\n</div>\\n\\n          </div>\\n   \n",
       "</div>\\n\\n        \\n            <div class=\"BorderGrid-row\">\\n              <div class=\"BorderGrid-cell\">\\n        \n",
       "<h2 class=\"h4 mb-3\" data-pjax=\"#repo-content-pjax-container\" data-turbo-frame=\"repo-content-turbo-frame\">\\n  <a \n",
       "href=\"/nepalprabin/deeplearning-paper-implementation/releases\" data-view-component=\"true\" class=\"Link--primary \n",
       "no-underline Link\">Releases</a></h2>\\n\\n    <div class=\"text-small color-fg-muted\">No releases published</div>\\n\\n \n",
       "</div>\\n            </div>\\n\\n        \\n        \\n            <div class=\"BorderGrid-row\">\\n              <div \n",
       "class=\"BorderGrid-cell\">\\n                \\n  <h2 class=\"h4 mb-3\">\\n  <a \n",
       "href=\"/users/nepalprabin/packages?repo_name=deeplearning-paper-implementation\" data-view-component=\"true\" \n",
       "class=\"Link--primary no-underline Link d-flex flex-items-center\">Packages\\n      <span title=\"0\" hidden=\"hidden\" \n",
       "data-view-component=\"true\" class=\"Counter ml-1\">0</span></a></h2>\\n\\n\\n      <div class=\"text-small color-fg-muted\"\n",
       ">\\n        No packages published <br>\\n      </div>\\n\\n\\n\\n              </div>\\n            </div>\\n\\n        \\n  \n",
       "<div class=\"BorderGrid-row\" hidden>\\n              <div class=\"BorderGrid-cell\">\\n                <include-fragment\n",
       "src=\"/nepalprabin/deeplearning-paper-implementation/used_by_list\" \n",
       "accept=\"text/fragment+html\">\\n</include-fragment>\\n              </div>\\n            </div>\\n\\n        \\n        \\n\n",
       "\\n            <div class=\"BorderGrid-row\">\\n              <div class=\"BorderGrid-cell\">\\n                <h2 \n",
       "class=\"h4 mb-3\">Languages</h2>\\n<div class=\"mb-2\">\\n  <span data-view-component=\"true\" class=\"Progress\">\\n    <span\n",
       "style=\"background-color:#DA5B0B !important;;width: 100.0%;\" itemprop=\"keywords\" data-view-component=\"true\" \n",
       "class=\"Progress-item color-bg-success-emphasis\"></span>\\n</span></div>\\n<ul class=\"list-style-none\">\\n    <li \n",
       "class=\"d-inline\">\\n        <a class=\"d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline \n",
       "text-small mr-3\" href=\"/nepalprabin/deeplearning-paper-implementation/search?l=jupyter-notebook\"  \n",
       "data-ga-click=\"Repository, language stats search click, location:repo overview\">\\n          <svg \n",
       "style=\"color:#DA5B0B;\" aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" \n",
       "data-view-component=\"true\" class=\"octicon octicon-dot-fill mr-2\">\\n    <path d=\"M8 4a4 4 0 1 1 0 8 4 4 0 0 1 \n",
       "0-8Z\"></path>\\n</svg>\\n          <span class=\"color-fg-default text-bold mr-1\">Jupyter Notebook</span>\\n          \n",
       "<span>100.0%</span>\\n        </a>\\n    </li>\\n</ul>\\n\\n              </div>\\n            </div>\\n\\n              \n",
       "</div>\\n</div>\\n  \\n</div></div>\\n\\n  </div>\\n\\n\\n  </div>\\n\\n</turbo-frame>\\n\\n\\n    </main>\\n  </div>\\n\\n  \n",
       "</div>\\n\\n          <footer class=\"footer pt-8 pb-6 f6 color-fg-muted p-responsive\" role=\"contentinfo\" >\\n  <h2 \n",
       "class=\\'sr-only\\'>Footer</h2>\\n\\n  \\n\\n\\n  <div class=\"d-flex flex-justify-center flex-items-center \n",
       "flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap\">\\n    <div class=\"d-flex flex-items-center flex-shrink-0 \n",
       "mx-2\">\\n      <a aria-label=\"Homepage\" title=\"GitHub\" class=\"footer-octicon mr-2\" href=\"https://github.com\">\\n     \n",
       "<svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 24 24\" version=\"1.1\" width=\"24\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-mark-github\">\\n    <path d=\"M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 \n",
       "10.91.575.101.79-.244.79-.546 \n",
       "0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014\n",
       "-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 \n",
       "3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 \n",
       "1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 \n",
       "2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 \n",
       "4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 \n",
       "21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z\"></path>\\n</svg>\\n</a>\\n      <span>\\n        &copy; 2025 \n",
       "GitHub,&nbsp;Inc.\\n      </span>\\n    </div>\\n\\n    <nav aria-label=\"Footer\">\\n      <h3 class=\"sr-only\" \n",
       "id=\"sr-footer-heading\">Footer navigation</h3>\\n\\n      <ul class=\"list-style-none d-flex flex-justify-center \n",
       "flex-wrap mb-2 mb-lg-0\" aria-labelledby=\"sr-footer-heading\">\\n\\n          <li class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}\" \n",
       "href=\"https://docs.github.com/site-policy/github-terms/github-terms-of-service\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\">Terms</a>\\n          </li>\\n\\n          <li class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}\" \n",
       "href=\"https://docs.github.com/site-policy/privacy-policies/github-privacy-statement\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\">Privacy</a>\\n          </li>\\n\\n          <li class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "security&quot;,&quot;label&quot;:&quot;text:security&quot;}\" href=\"https://github.com/security\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\">Security</a>\\n          </li>\\n\\n          <li \n",
       "class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "status&quot;,&quot;label&quot;:&quot;text:status&quot;}\" href=\"https://www.githubstatus.com/\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\">Status</a>\\n          </li>\\n\\n          <li \n",
       "class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}\" href=\"https://docs.github.com/\" data-view-component=\"true\" \n",
       "class=\"Link--secondary Link\">Docs</a>\\n          </li>\\n\\n          <li class=\"mx-2\">\\n            <a \n",
       "data-analytics-event=\"{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to \n",
       "contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}\" href=\"https://support.github.com?tags=dotcom-footer\" \n",
       "data-view-component=\"true\" class=\"Link--secondary Link\">Contact</a>\\n          </li>\\n\\n          <li class=\"mx-2\" \n",
       ">\\n  <cookie-consent-link>\\n    <button\\n      type=\"button\"\\n      class=\"Link--secondary underline-on-hover \n",
       "border-0 p-0 color-bg-transparent\"\\n      data-action=\"click:cookie-consent-link#showConsentManagement\"\\n      \n",
       "data-analytics-event=\"{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;cookies&quot;,&quot;context\n",
       "&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;cookies_link_subfooter_footer\n",
       "&quot;}\"\\n    >\\n      Manage cookies\\n    </button>\\n  </cookie-consent-link>\\n</li>\\n\\n<li class=\"mx-2\">\\n  \n",
       "<cookie-consent-link>\\n    <button\\n      type=\"button\"\\n      class=\"Link--secondary underline-on-hover border-0 \n",
       "p-0 color-bg-transparent\"\\n      data-action=\"click:cookie-consent-link#showConsentManagement\"\\n      \n",
       "data-analytics-event=\"{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;dont_share_info&quot;,&quot\n",
       ";context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;dont_share_info_link_\n",
       "subfooter_footer&quot;}\"\\n    >\\n      Do not share my personal information\\n    </button>\\n  \n",
       "</cookie-consent-link>\\n</li>\\n\\n      </ul>\\n    </nav>\\n  </div>\\n</footer>\\n\\n\\n\\n    <ghcc-consent id=\"ghcc\" \n",
       "class=\"position-fixed bottom-0 left-0\" style=\"z-index: 999999\" data-initial-cookie-consent-allowed=\"\" \n",
       "data-cookie-consent-required=\"false\"></ghcc-consent>\\n\\n\\n\\n  <div id=\"ajax-error-message\" \n",
       "class=\"ajax-error-message flash flash-error\" hidden>\\n    <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" \n",
       "version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">\\n    <path d=\"M6.457 \n",
       "1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 \n",
       "1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 \n",
       "3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\"></path>\\n</svg>\\n    \n",
       "<button type=\"button\" class=\"flash-close js-ajax-error-dismiss\" aria-label=\"Dismiss error\">\\n      <svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-x\">\\n    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 \n",
       "1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 \n",
       "3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path>\\n</svg>\\n   \n",
       "</button>\\n    You can’t perform that action at this time.\\n  </div>\\n\\n    <template id=\"site-details-dialog\">\\n  \n",
       "<details class=\"details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm\" open>\\n    \n",
       "<summary role=\"button\" aria-label=\"Close dialog\"></summary>\\n    <details-dialog class=\"Box Box--overlay d-flex \n",
       "flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal\">\\n      <button class=\"Box-btn-octicon m-0 btn-octicon \n",
       "position-absolute right-0 top-0\" type=\"button\" aria-label=\"Close dialog\" data-close-dialog>\\n        <svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-x\">\\n    <path d=\"M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 \n",
       "1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 \n",
       "3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z\"></path>\\n</svg>\\n   \n",
       "</button>\\n      <div class=\"octocat-spinner my-6 js-details-dialog-spinner\"></div>\\n    </details-dialog>\\n  \n",
       "</details>\\n</template>\\n\\n    <div class=\"Popover js-hovercard-content position-absolute\" style=\"display: none; \n",
       "outline: none;\">\\n  <div class=\"Popover-message Popover-message--bottom-left Popover-message--large Box \n",
       "color-shadow-large\" style=\"width:360px;\">\\n  </div>\\n</div>\\n\\n    <template id=\"snippet-clipboard-copy-button\">\\n \n",
       "<div class=\"zeroclipboard-container position-absolute right-0 top-0\">\\n    <clipboard-copy aria-label=\"Copy\" \n",
       "class=\"ClipboardButton btn js-clipboard-copy m-2 p-0\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">\\n   \n",
       "<svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-copy js-clipboard-copy-icon m-2\">\\n    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 \n",
       "1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 \n",
       "1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 \n",
       ".784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 \n",
       ".138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path>\\n</svg>\\n      <svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2\">\\n    <path d=\"M13.78 4.22a.75.75\n",
       "0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 \n",
       "10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path>\\n</svg>\\n    </clipboard-copy>\\n  </div>\\n</template>\\n<template \n",
       "id=\"snippet-clipboard-copy-button-unpositioned\">\\n  <div class=\"zeroclipboard-container\">\\n    <clipboard-copy \n",
       "aria-label=\"Copy\" class=\"ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center \n",
       "flex-items-center\" data-copy-feedback=\"Copied!\" data-tooltip-direction=\"w\">\\n      <svg aria-hidden=\"true\" \n",
       "height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-copy \n",
       "js-clipboard-copy-icon\">\\n    <path d=\"M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 \n",
       "0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 \n",
       "16h-7.5A1.75 1.75 0 0 1 0 14.25Z\"></path><path d=\"M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 \n",
       "1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 \n",
       ".138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z\"></path>\\n</svg>\\n      <svg \n",
       "aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" \n",
       "class=\"octicon octicon-check js-clipboard-check-icon color-fg-success d-none\">\\n    <path d=\"M13.78 4.22a.75.75 0 0\n",
       "1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 \n",
       "10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z\"></path>\\n</svg>\\n    </clipboard-copy>\\n  </div>\\n</template>\\n\\n\\n\\n\\n    \n",
       "</div>\\n\\n    <div id=\"js-global-screen-reader-notice\" class=\"sr-only mt-n1\" aria-live=\"polite\" aria-atomic=\"true\" \n",
       "></div>\\n    <div id=\"js-global-screen-reader-notice-assertive\" class=\"sr-only mt-n1\" aria-live=\"assertive\" \n",
       "aria-atomic=\"true\"></div>\\n  </body>\\n</html>\\n\\n', 'depth': 2}}, 'stats': {'pages_discovered': 539, \n",
       "'pages_crawled': 97, 'start_time': '2025-03-05T17:53:38.107378', 'end_time': '2025-03-05T17:54:58.242979', \n",
       "'total_pages_crawled': 97}}\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 83.13 seconds| Input tokens: 5,282 | Output tokens: 364]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 83.13 seconds| Input tokens: 5,282 | Output tokens: 364]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Extract clean, readable content from the crawled HTML pages</span><span style=\"background-color: #272822\">                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">extracted_content </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> content_extraction_tool(pages</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">crawled_pages[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'pages'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                      </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(extracted_content)</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Extract clean, readable content from the crawled HTML pages\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mextracted_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcontent_extraction_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpages\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcrawled_pages\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mpages\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                      \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mextracted_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "{'https://nepalprabin.github.io': {'title': 'Prabin Nepal', 'text': 'Prabin \n",
       "Nepal\\nCategories\\nAll\\n(16)\\nLLM\\n(1)\\nNLP\\n(4)\\nagents\\n(1)\\ncomputer-vision\\n(6)\\ndeep-learning\\n(12)\\nllms\\n(1)\n",
       "\\nmachine-learning\\n(2)\\nself-supervised-learning\\n(1)\\nHuggingface AI Agents Quiz Solutions\\nllms\\nagents\\nI have \n",
       "been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding\n",
       "of how to build and deploy AI agents using the\\nsmol…\\nMar 2, 2025\\nAugmenting Large Language Models: Expanding \n",
       "Context and Enhancing Relevance\\nmachine-learning\\nNLP\\ndeep-learning\\nLLM\\nWith the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…\\nJul 4, 2023\\nBrief overview of GPT-4\\nmachine-learning\\nNLP\\ndeep-learning\\nSince \n",
       "the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural \n",
       "language processing communities regarding its…\\nMar 15, 2023\\nText Summarization NLP\\nNLP\\ndeep-learning\\nText \n",
       "summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened \n",
       "automatically while holding the same semantic meaning.…\\nOct 19, 2022\\nAutocorrect and Minimum Edit \n",
       "Distance\\nNLP\\ndeep-learning\\nThis is my brief note from\\nDeepLearning.AI’s\\nNLP Specialization Course.\\nOct 25, \n",
       "2021\\nIllustrated Vision Transformers\\ncomputer-vision\\ndeep-learning\\nEver since Transformer was introduced in \n",
       "2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP tasks use \n",
       "Transformers and…\\nJul 27, 2021\\nPaper Explanation: A Simple Framework for Contrastive Learning of Visual \n",
       "Representations (simCLR)\\nVarious self-supervised learning methods have been proposed in recent years for learning \n",
       "image representations. Though a lot of methods have been proposed, the performance…\\nMar 26, 2021\\nDeep Residual \n",
       "Learning for Image Recognition (ResNet paper explained)\\nDeep Neural Networks tend to provide more accuracy as the \n",
       "number of layers increases. But, as we go more deeper in the network, the accuracy of the network decreases \n",
       "instead…\\nJan 1, 2021\\nSelf-supervised Learning\\ndeep-learning\\nself-supervised-learning\\nI have been exploring \n",
       "self-supervised learning and been through papers and blogs to understand it. Self-supervised learning is considered\n",
       "the next big thing in deep learning…\\nDec 8, 2020\\nMobileNet Architecture Explained\\ndeep-learning\\nIn this blog \n",
       "post, I will try to write about the MobileNets and its architecture. MobileNet uses depthwise separable \n",
       "convolutions instead of standard convolution to reduce…\\nSep 21, 2020\\nNeural style transfer and its working\\nHave \n",
       "you ever used an app called Prisma that styles your image using popular paintings and turns your photo stunning? If\n",
       "that’s the case then, the app you are using is the…\\nAug 23, 2020\\nDeep Convolutional Generative Adversarial \n",
       "Networks (DCGANs)\\ncomputer-vision\\ndeep-learning\\nDCGAN (Deep Convolutional General Adversarial Networks) uses \n",
       "convolutional layers in its design.\\nAug 15, 2020\\nGeneral Adversarial Networks \n",
       "(GANs)\\ncomputer-vision\\ndeep-learning\\n“\\nGeneral Adversarial Nets\\nis the most interesting idea in the last 10 \n",
       "years in machine learning”. This was the statement from Yann LeCun regarding GANs when Ian Goodfellow…\\nAug 4, \n",
       "2020\\nPaper Explanation: Going deeper with Convolutions (GoogLeNet)\\ncomputer-vision\\ndeep-learning\\nGoogle \n",
       "proposed a deep Convolution Neural Network named inception that achieved top results for classification and \n",
       "detection in ILSVRC 2014.\\nJun 5, 2020\\nVGGNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nVGGNet is a \n",
       "Convolutional Neural Network architecture proposed by Karen Simonyan and Andrew Zisserman of University of Oxford \n",
       "in 2014. This paper mailny focuses in the…\\nMay 9, 2020\\nAlexNet Architecture \n",
       "Explained\\ncomputer-vision\\ndeep-learning\\nAlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large\n",
       "margin (15.3% vs 26.2%(second place) error rates). Here is the link to original paper.\\nApr 24, 2020\\nNo matching \n",
       "items', 'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes', 'quarto:offset': './'}, 'depth': 0}, 'https://nepalprabin.github.io/index.html': {'title': \n",
       "'Prabin Nepal', 'text': 'Prabin \n",
       "Nepal\\nCategories\\nAll\\n(16)\\nLLM\\n(1)\\nNLP\\n(4)\\nagents\\n(1)\\ncomputer-vision\\n(6)\\ndeep-learning\\n(12)\\nllms\\n(1)\n",
       "\\nmachine-learning\\n(2)\\nself-supervised-learning\\n(1)\\nHuggingface AI Agents Quiz Solutions\\nllms\\nagents\\nI have \n",
       "been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding\n",
       "of how to build and deploy AI agents using the\\nsmol…\\nMar 2, 2025\\nAugmenting Large Language Models: Expanding \n",
       "Context and Enhancing Relevance\\nmachine-learning\\nNLP\\ndeep-learning\\nLLM\\nWith the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…\\nJul 4, 2023\\nBrief overview of GPT-4\\nmachine-learning\\nNLP\\ndeep-learning\\nSince \n",
       "the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural \n",
       "language processing communities regarding its…\\nMar 15, 2023\\nText Summarization NLP\\nNLP\\ndeep-learning\\nText \n",
       "summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened \n",
       "automatically while holding the same semantic meaning.…\\nOct 19, 2022\\nAutocorrect and Minimum Edit \n",
       "Distance\\nNLP\\ndeep-learning\\nThis is my brief note from\\nDeepLearning.AI’s\\nNLP Specialization Course.\\nOct 25, \n",
       "2021\\nIllustrated Vision Transformers\\ncomputer-vision\\ndeep-learning\\nEver since Transformer was introduced in \n",
       "2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP tasks use \n",
       "Transformers and…\\nJul 27, 2021\\nPaper Explanation: A Simple Framework for Contrastive Learning of Visual \n",
       "Representations (simCLR)\\nVarious self-supervised learning methods have been proposed in recent years for learning \n",
       "image representations. Though a lot of methods have been proposed, the performance…\\nMar 26, 2021\\nDeep Residual \n",
       "Learning for Image Recognition (ResNet paper explained)\\nDeep Neural Networks tend to provide more accuracy as the \n",
       "number of layers increases. But, as we go more deeper in the network, the accuracy of the network decreases \n",
       "instead…\\nJan 1, 2021\\nSelf-supervised Learning\\ndeep-learning\\nself-supervised-learning\\nI have been exploring \n",
       "self-supervised learning and been through papers and blogs to understand it. Self-supervised learning is considered\n",
       "the next big thing in deep learning…\\nDec 8, 2020\\nMobileNet Architecture Explained\\ndeep-learning\\nIn this blog \n",
       "post, I will try to write about the MobileNets and its architecture. MobileNet uses depthwise separable \n",
       "convolutions instead of standard convolution to reduce…\\nSep 21, 2020\\nNeural style transfer and its working\\nHave \n",
       "you ever used an app called Prisma that styles your image using popular paintings and turns your photo stunning? If\n",
       "that’s the case then, the app you are using is the…\\nAug 23, 2020\\nDeep Convolutional Generative Adversarial \n",
       "Networks (DCGANs)\\ncomputer-vision\\ndeep-learning\\nDCGAN (Deep Convolutional General Adversarial Networks) uses \n",
       "convolutional layers in its design.\\nAug 15, 2020\\nGeneral Adversarial Networks \n",
       "(GANs)\\ncomputer-vision\\ndeep-learning\\n“\\nGeneral Adversarial Nets\\nis the most interesting idea in the last 10 \n",
       "years in machine learning”. This was the statement from Yann LeCun regarding GANs when Ian Goodfellow…\\nAug 4, \n",
       "2020\\nPaper Explanation: Going deeper with Convolutions (GoogLeNet)\\ncomputer-vision\\ndeep-learning\\nGoogle \n",
       "proposed a deep Convolution Neural Network named inception that achieved top results for classification and \n",
       "detection in ILSVRC 2014.\\nJun 5, 2020\\nVGGNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nVGGNet is a \n",
       "Convolutional Neural Network architecture proposed by Karen Simonyan and Andrew Zisserman of University of Oxford \n",
       "in 2014. This paper mailny focuses in the…\\nMay 9, 2020\\nAlexNet Architecture \n",
       "Explained\\ncomputer-vision\\ndeep-learning\\nAlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large\n",
       "margin (15.3% vs 26.2%(second place) error rates). Here is the link to original paper.\\nApr 24, 2020\\nNo matching \n",
       "items', 'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes', 'quarto:offset': './'}, 'depth': 1}, 'https://nepalprabin.github.io/projects.html': {'title': \n",
       "'Projects – Prabin Nepal', 'text': 'Projects – Prabin Nepal\\n1.\\nStanford NLP Lecture Transcription using OpenAI’s \n",
       "Whisper\\nWhisper is an automatic speech recognition (ASR) model trained on hours of multilingual and multitask \n",
       "supervised data. It is implemented as an encoder-decoder transformer architecture where audio are splitted into 30 \n",
       "seconds of chunks, converted into a log-Mel spectrogram, and then passed into an encoder. The decoder is trained to\n",
       "predict the corresponding text caption, intermixed with special tokens that direct the single model to perform \n",
       "tasks such as language identification, phrase-level timestamps, multilingual speech transcription, and to-English \n",
       "speech translation. For more info about whisper, read\\nhere\\n.\\nI used whisper model to transcribe Stanford NLP \n",
       "lectures into corresponding text captions.\\nHere\\nis the result of the transcribed lectures. This web app is build \n",
       "using Flask and deployed on AWS EC2 instance. You can find transcribed audio file in the form of \n",
       "text\\nhere\\n.\\n2.\\nCustom Named Entity Recognizer for clinical data\\nNamed Entity Recognition (NER) is a subtask of\n",
       "Natural Language Processing (NLP) that involves identifying and categorizing named entities in text.\\nI have \n",
       "developed a custom named entity recognition (NER) model for clinical data using the spacy framework and deployed it\n",
       "using Streamlit. The model is capable of identifying various entities such as diseases, treatments, medications, \n",
       "and anatomical locations from clinical text data. The model classifies entities based on three \n",
       "classes:\\n‘MEDICINE’\\n,\\n“MEDICALCONDITION”\\n, and\\n“PATHOGEN”\\n. The dataset was used from\\nkaggle\\n. You can try \n",
       "the application on this\\nlink\\n3.\\nQuestion Answering using Langchain and OpenAI\\nThis application provides a \n",
       "simple example of how to build a question-answering system using Langchain and pre-trained language models from \n",
       "OpenAI and Streamlit.\\nLangchain helps to build Large Language Models (LLMs) through composability. It helps to \n",
       "combine large language models with other sources of computation.\\nI developed a question answering system using \n",
       "Langchain with OpenAI embeddings. Since, LLMs tends to have fixed context length, Langchain helps to eliminate this\n",
       "issue by introducing chains, where we can break the document into different chunks and run the chain on the whole \n",
       "document. In this application, when a user uploads a file, the contents are converted into embeddings using OpenAI \n",
       "embeddings and stored in Pinecone vector database. Storing embeddings this way, helps for faster retrieval of the \n",
       "embeddings. When a user enters the query, similarity search is conducted to retrieve the similar embeddings from \n",
       "the vector store and the langchain chain passes the formatted response to the LLM.', 'metadata': {'generator': \n",
       "'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', 'quarto:offset': './'}, \n",
       "'depth': 1}, 'https://github.com/nepalprabin': {'title': 'nepalprabin (Prabin Nepal) · GitHub', 'text': \n",
       "\"nepalprabin (Prabin Nepal) · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto \n",
       "refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched \n",
       "accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocus\n",
       "ing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI \n",
       "enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or \n",
       "report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you \n",
       "notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional \n",
       "note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 \n",
       "characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub \n",
       "support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport \n",
       "abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\n/\\nREADME\\n.md\\nHi 👋, I'm Prabin \n",
       "Nepal\\nA passionate software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 \n",
       "Ask me about\\nFull Stack Development, Deep Learning\\n📫 How to reach \n",
       "me\\nprabinnepal1996@gmail.com\\nPinned\\nLoading\\noswrite\\noswrite\\nPublic\\nPython\\n2\\nbasic-deeplearning-notebooks\\n\n",
       "basic-deeplearning-notebooks\\nPublic\\nJupyter \n",
       "Notebook\\ndeeplearning-paper-implementation\\ndeeplearning-paper-implementation\\nPublic\\nJupyter \n",
       "Notebook\\n3\\n1\\nwhisper-webapp\\nwhisper-webapp\\nPublic\\nJupyter Notebook\\nSomething went wrong, please refresh the \n",
       "page to try again.\\nIf the problem persists, check the\\nGitHub status page\\nor\\ncontact support\\n.\\nYou can’t \n",
       "perform that action at this time.\", 'metadata': {'route-pattern': '/:user_id(.:format)', 'route-controller': \n",
       "'profiles', 'route-action': 'show', 'current-catalog-service-hash': \n",
       "'4a1c50a83cf6cc4b55b6b9c53e553e3f847c876b87fb333f71f5d05db8f1a7db', 'request-id': \n",
       "'8825:212693:4608B2:5DA231:67C8D5F4', 'html-safe-nonce': \n",
       "'b2bd1705280defe3c9fec4ef96c15d374642689d4c7ac54a830e84979a8402e4', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODI1OjIxMjY5Mzo0NjA4QjI6NURBMjMxOjY3QzhENUY0IiwidmlzaXRvcl9pZCI6Ijg1MzczND\n",
       "AzNzQxNDk1NTE2MDQiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'c116c9ee9e1158c8253bd84121072faca545d06f33556639b71a2be0e4513444', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'analytics-location': '/&lt;user-name&gt;', 'viewport': \n",
       "'width=device-width', 'description': 'Software Developer. AI enthusiast. nepalprabin has 84 repositories available.\n",
       "Follow their code on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin', 'twitter:image': \n",
       "'https://avatars.githubusercontent.com/u/43682497?v=4?s=400', 'twitter:site': '@github', 'twitter:card': 'summary',\n",
       "'twitter:title': 'nepalprabin - Overview', 'twitter:description': 'Software Developer. AI enthusiast. nepalprabin \n",
       "has 84 repositories available. Follow their code on GitHub.', 'hostname': 'github.com', 'expected-hostname': \n",
       "'github.com', 'turbo-cache-control': 'no-preview', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'turbo-body-classes': 'logged-out env-production page-responsive \n",
       "page-profile', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "1}, 'https://nepalprabin.github.io/posts/2025-03-02-huggingface-smolagents-solutions.html': {'title': 'Huggingface \n",
       "AI Agents Quiz Solutions – Prabin Nepal', 'text': 'Huggingface AI Agents Quiz Solutions – Prabin Nepal\\nI have been\n",
       "diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of \n",
       "how to build and deploy AI agents using the\\nsmolagents\\nlibrary. In this blog, I’ll share insights from the course\n",
       "(Unit 2) and provide code snippets to illustrate key concepts.\\nNote\\nHere is the course link if anyone is \n",
       "interested.\\nAI Agents Course\\nCreate a Basic Code Agent with Web Search Capability\\nOne of the foundational \n",
       "exercises involves creating a CodeAgent equipped with web search capabilities. This agent leverages the \n",
       "DuckDuckGoSearchTool to perform web searches, enabling it to fetch real-time information. Here’s how you can set it\n",
       "up:\\n# Create a CodeAgent with DuckDuckGo search capability\\nfrom\\nsmolagents\\nimport\\nCodeAgent, \n",
       "DuckDuckGoSearchTool, HfApiModel\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\n# Add search tool \n",
       "here\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Add model here\\n)\\nIn this snippet, we \n",
       "initialize a CodeAgent with the DuckDuckGoSearchTool, allowing the agent to perform web searches to answer \n",
       "queries.\\nSet Up a Multi-Agent System with Manager and Web Search Agents\\nMulti-Agent systems are the agents that \n",
       "are specialized on complex tasks with more scalable and robust nature. In\\nsmolagents\\n, various agents can be \n",
       "integrated to produce Python code, invoke external tools, conduct web searches, and more. By coordinating these \n",
       "agents, it’s possible to develop robust workflows. A typical multi-agent system includes:\\n- A manager Agent\\n- A \n",
       "code interpreter Agent\\n- A web Search Agent\\nMulti-agent system allows to separate memories between different \n",
       "sub-tasks and provide great benefits. Firstly, each agent are more focused on its core taks and secondly, \n",
       "separating memories reduces the count of input tokens resulting in reducing latency and cost. Below is the \n",
       "multi-agent system when\\nweb_agent\\nperforms search and\\nmanager_agent\\ngives data analysis capabilities. Also, we \n",
       "can import dependencies (like python libraries) that helps to perform the \n",
       "tasks.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel, \n",
       "VisitWebpageTool\\nweb_agent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool(), \n",
       "VisitWebpageTool()],\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nmax_steps\\n=\\n10\\n,\\\n",
       "nname\\n=\\n\"search\"\\n,\\ndescription\\n=\\n\"Agent to perform web searches and visit \n",
       "webpages.\"\\n)\\nmanager_agent\\n=\\nCodeAgent(\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\n",
       ",\\nmanaged_agents\\n=\\n[web_agent],\\nadditional_authorized_imports\\n=\\n[\\n\"pandas\"\\n,\\n\"time\"\\n,\\n\"numpy\"\\n]\\n# \n",
       "Corrected imports\\n)\\nConfigure Agent Security Settings\\nSecurity is a crucial aspect when deploying AI agents, \n",
       "especially when they execute code. Below code snippet uses E2B to run code in a sandboxed environment. It is a \n",
       "remote execution that run the code in a isolated container.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, \n",
       "HfApiModel\\nfrom\\nsmolagents.sandbox\\nimport\\nE2BSandbox\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\\n",
       "n)\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[],\\nmodel\\n=\\nmodel,\\nsandbox\\n=\\nE2BSandbox(),\\n# Configure the \n",
       "sandbox\\nadditional_authorized_imports\\n=\\n[\\n\"numpy\"\\n],\\n# Authorize numpy import\\n)\\nImplement a Tool-Calling \n",
       "Agent\\nSimilar to\\nCodeAgent\\n,\\nToolCallingAgent\\nis another type of agent available in smolagent library. \n",
       "CodeAgent uses Python code snippets whereas ToolCallingAgent use built-in tool-calling capabilities of LLM \n",
       "providers and generate JSON structures.\\nfrom\\nsmolagents\\nimport\\nToolCallingAgent, HfApiModel, \n",
       "DuckDuckGoSearchTool\\nagent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\nmodel\\n=\\nHfApiModel(model_\n",
       "id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nname\\n=\\n\"SearchAgent\"\\n,\\ndescription\\n=\\n\"An agent that uses \n",
       "DuckDuckGo to search the web.\"\\n,\\nmax_steps\\n=\\n5\\n,\\n)\\nSet Up Model Integration\\nLLM models are the most \n",
       "important aspect when creating AI agents. There are many model availables for various tasks and domains. So we can \n",
       "easily integrate models that is required for our task. Below code snippet switches between two different models \n",
       "providers.\\nfrom\\nsmolagents\\nimport\\nHfApiModel, LiteLLMModel\\n# Initialize Hugging Face \n",
       "model\\nhf_model\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Initialize LiteLLM model as an \n",
       "alternative model\\nother_model\\n=\\nLiteLLMModel(model_id\\n=\\n\"anthropic/claude-3-sonnet\"\\n)\\n# Set the model to \n",
       "hf_model or alternative model\\nmodel\\n=\\nhf_model\\n# Alternatively, you can switch this to `other_model`', \n",
       "'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', \n",
       "'dcterms.date': '2025-03-02', 'quarto:offset': '../'}, 'depth': 1}, \n",
       "'https://nepalprabin.github.io/posts/2023-07-04-augmented-language-models.html': {'title': 'Augmenting Large \n",
       "Language Models: Expanding Context and Enhancing Relevance – Prabin Nepal', 'text': 'Augmenting Large Language \n",
       "Models: Expanding Context and Enhancing Relevance – Prabin Nepal\\nWith the rise of ChatGPT and other large language\n",
       "models (LLMs), the potential for AI to surpass human capabilities has become a topic of both fascination and \n",
       "concern. While LLMs excel at understanding language, following instructions, and reasoning, they often fall short \n",
       "when it comes to performing specific tasks. Simply inputting a prompt into ChatGPT may result in answers that are \n",
       "unrelated or out of context, a phenomenon known as “hallucination.” To obtain relevant information, it is crucial \n",
       "to provide the model with the appropriate context. However, the size of the context window is limited, posing a \n",
       "challenge in capturing all necessary information. Although the context size has increased over time, storing \n",
       "extensive information within a fixed context window remains impractical and expensive. This is where the \n",
       "augmentation of language models comes into play.\\nAugmenting large language models involves three primary \n",
       "approaches:\\nretrieval,\\nchains, and\\ntools.\\nThese methods aim to enhance the capabilities of LLMs by providing \n",
       "them with additional resources and functionalities.\\nRetrieval Augmentation:\\nRetrieval augmentation involves \n",
       "leveraging an external corpus of data for the language model to search through. Traditionally, retrieval algorithms\n",
       "employ queries to rank relevant objects in a collection, which can include images, texts, documents, or other types\n",
       "of data. To enable efficient searching, the documents and their corresponding features are organized within an \n",
       "index. This index maps each feature to the documents containing it, facilitating quick retrieval. Boolean search \n",
       "determines the relevance of documents based on the query, while ranking is typically performed using algorithms \n",
       "like BM25 (Best Match 25).\\nBM25 (Best Match 25) is a ranking function commonly used in information retrieval to \n",
       "measure the relevance of a document to a given query. It is a probabilistic retrieval model that enhances the \n",
       "vector space model by incorporating document length normalization and term frequency saturation.\\nIn BM25, the \n",
       "indexing process involves tokenizing each document in the collection into terms and calculating term statistics \n",
       "such as document frequency (df) and inverse document frequency (idf). Document frequency represents the number of \n",
       "documents in the collection containing a particular term, while inverse document frequency measures the rarity of \n",
       "the term across the collection.\\nDuring the querying phase, the query is tokenized into terms, and term statistics,\n",
       "including query term frequency (qtf) and query term inverse document frequency (qidf), are computed. These \n",
       "statistics capture the occurrence and relevance of terms in the query.\\nWhile traditional retrieval methods \n",
       "primarily rely on keyword matching and statistical techniques, modern approaches leverage AI-centric retrieval \n",
       "methods that utilize embeddings. These methods offer improved search capabilities and help retrieve contextually \n",
       "relevant information.\\nChains\\nChains involve using the output of one language model as the input for another. By \n",
       "cascading multiple models together, the output of each model becomes the input for the subsequent one. This \n",
       "chaining process allows the models to build upon each other’s knowledge and reasoning abilities, potentially \n",
       "leading to more accurate and contextually appropriate responses.\\nThe sequential arrangement of models in a chain \n",
       "creates a pipeline of of interconnected language models, where the output of one model serves as the input for the \n",
       "next. This pipeline allows for a cascading flow of information and reasoning, enabling the models to collectively \n",
       "enhance their understanding and generate more accurate responses. By leveraging a chain of language models, each \n",
       "model can contribute its specialized knowledge and capabilities to the overall task. For example, one model may \n",
       "excel at language comprehension, while another may possess domain-specific knowledge.\\nAs the input passes through \n",
       "the chain, each model can refine and expand upon the information, leading to a more comprehensive and contextually \n",
       "relevant output. The chaining process in language models has the potential to address the limitations of indivi\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       " 'https://github.com/nepalprabin/nepalprabin': {'title': 'GitHub - nepalprabin/nepalprabin', 'text': \"GitHub - \n",
       "nepalprabin/nepalprabin\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\nnepalprabin\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/nepalprabin\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n14 \n",
       "Commits\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\nHi 👋, I'm Prabin Nepal\\nA passionate \n",
       "software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull \n",
       "Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nAbout\\nNo description, website, or\n",
       "topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nYou can’t perform that action at \n",
       "this time.\", 'metadata': {'route-pattern': '/:user_id/:repository', 'route-controller': 'files', 'route-action': \n",
       "'disambiguate', 'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb',\n",
       "'request-id': '885D:148B86:468AB6:5EA3B6:67C8D639', 'html-safe-nonce': \n",
       "'2e85c74115beb5e1e134f0c55ba7d98d8191a15ecc34599c10cf561436845743', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVEOjE0OEI4Njo0NjhBQjY6NUVBM0I2OjY3QzhENjM5IiwidmlzaXRvcl9pZCI6IjczODY4MD\n",
       "cyMDIwNzE3NjI0ODkiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'44b6648ccdfe752ed85305ebb06add2ba0881ec0366c36e35d31bdf78566a2aa', 'hovercard-subject-tag': \n",
       "'repository:278281752', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/nepalprabin development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/nepalprabin', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/938931e393aefe0802f7134e6271f2c2d66d2eacd02f8ab7f9f16dfbc37c3816/nepalprabin/ne\n",
       "palprabin', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'twitter:description': 'Contribute to nepalprabin/nepalprabin development by creating an \n",
       "account on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': \n",
       "'no-preview', 'go-import': 'github.com/nepalprabin/nepalprabin git https://github.com/nepalprabin/nepalprabin.git',\n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '278281752', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/nepalprabin', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '278281752',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/nepalprabin', 'turbo-body-classes': 'logged-out \n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2}, \n",
       "'https://camo.githubusercontent.com/33cf16865184db58d654ab7a61230f414cfce1b7328964bd6d054c104e00cd30/68747470733a2f\n",
       "2f6b6f6d617265762e636f6d2f67687076632f3f757365726e616d653d6e6570616c70726162696e': {'title': 'No title', 'text': \n",
       "'Profile views\\nProfile views\\n1,725\\n1,725', 'metadata': {}, 'depth': 2}, 'https://fb.com/prabin.nepal.92': \n",
       "{'title': 'Prabin Nepal', 'text': 'Prabin Nepal', 'metadata': {'bingbot': 'noarchive', 'viewport': \n",
       "'width=device-width,initial-scale=1,maximum-scale=2,shrink-to-fit=no', 'apple-itunes-app': 'app-id=284882215, \n",
       "app-argument=fb://profile/100005550337615', 'description': 'Prabin Nepal is on Facebook. Join Facebook to connect \n",
       "with Prabin Nepal and others you may know. Facebook gives people the power to share and makes the...', 'referrer': \n",
       "'default', 'robots': 'noodp,noydir,noimageindex,noarchive', 'twitter:card': 'summary', 'twitter:title': 'Prabin \n",
       "Nepal', 'twitter:description': 'Prabin Nepal is on Facebook. Join Facebook to connect with Prabin Nepal and others \n",
       "you may know. Facebook gives people the power to share and makes the world more open and connected.', \n",
       "'twitter:image': \n",
       "'https://scontent-iad3-2.xx.fbcdn.net/v/t39.30808-1/311694731_2004875619707430_4977667565115494685_n.jpg?cstp=mx958\n",
       "x960&amp;ctp=s720x720&amp;_nc_cat=111&amp;ccb=1-7&amp;_nc_sid=3ab345&amp;_nc_ohc=E7yTPHDsMbUQ7kNvgHfCwy9&amp;_nc_oc=AdhtfnD-MgJsMR1vujUJ3NC\n",
       "jtpm9zzwU0ZlH-lQ7hKsJGt0ncLvbTycNtznNS5WLyUnuxiR48ic96BDsuJlhsqWJ&amp;_nc_zt=24&amp;_nc_ht=scontent-iad3-2.xx&amp;_nc_gid=Ai4Ff\n",
       "9EYub8-ff99Uc1eTfa&amp;oh=00_AYB-Twf9stZNSnfASNNWYxlcboE3bMZ5COKeN8xZKARGOg&amp;oe=67CEC0E6', 'twitter:image:alt': 'Prabin \n",
       "Nepal', 'twitter:site': '@facebookapp', 'color-scheme': 'light', 'theme-color': '#FFFFFF'}, 'depth': 2}, \n",
       "'https://medium.com/@prabinnepal1996': {'title': 'Medium', 'text': 'Medium\\nOpen in app\\nSign up\\nSign \n",
       "in\\nWrite\\nSign up\\nSign in\\nPAGE NOT FOUND\\n404\\nOut of nothing, something.\\nYou can find (just about) anything \n",
       "on\\nMedium\\n— apparently even a page that doesn’t exist. Maybe these stories will take you somewhere new?\\nHome\\nWe\n",
       "overestimate AI’s impact in the short-term and underestimate it long-term\\nThe Medium Newsletter\\nin\\nThe Medium \n",
       "Blog\\nMar 5, 2025\\n·\\n3 min read\\nWe overestimate AI’s impact in the short-term and underestimate it long-term\\nThe\n",
       "Medium Newsletter\\nin\\nThe Medium Blog\\nMar 5, 2025\\n·\\n3 min read\\nAt sea with the Black Knight\\nEYE IN THE \n",
       "SKY\\nFeb 25, 2025\\n·\\n13 min read\\nAt sea with the Black Knight\\nEYE IN THE SKY\\nFeb 25, 2025\\n·\\n13 min \n",
       "read\\nFinding My Photo Mojo, Light, and Equanimity in the Desert\\nCynthia A Whelan\\nin\\nLive View\\nMar 3, \n",
       "2025\\n·\\n5 min read\\nMember-only\\nFinding My Photo Mojo, Light, and Equanimity in the Desert\\nCynthia A \n",
       "Whelan\\nin\\nLive View\\nMar 3, 2025\\n·\\n5 min read\\nMember-only\\nWhy is DOGE not at all, like not even remotely, \n",
       "similar to the 1990s Program Review in Canada?\\nJennifer Robson\\nMar 5, 2025\\n·\\n16 min read\\nWhy is DOGE not at \n",
       "all, like not even remotely, similar to the 1990s Program Review in Canada?\\nJennifer Robson\\nMar 5, 2025\\n·\\n16 \n",
       "min read', 'metadata': {'viewport': 'width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1', \n",
       "'theme-color': '#000000', 'twitter:app:name:iphone': 'Medium', 'twitter:app:id:iphone': '828256236'}, 'depth': 2}, \n",
       "'https://github.com/nepalprabin/oswrite': {'title': 'GitHub - nepalprabin/oswrite', 'text': 'GitHub - \n",
       "nepalprabin/oswrite\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\noswrite\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n2\\n2\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/oswrite\\nmain\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n32 \n",
       "Commits\\n.github/\\nworkflows\\n.github/\\nworkflows\\n.vscode\\n.vscode\\noswrite\\noswrite\\ntests\\ntests\\n.gitignore\\n.g\n",
       "itignore\\nREADME.md\\nREADME.md\\npyproject.toml\\npyproject.toml\\nView all files\\nRepository files \n",
       "navigation\\noswrite\\nCLI tool for running audio through the OpenAI whisper API\\nSee oswrite: a CLI tool for running\n",
       "audio through the OpenAI whisper API.\\nPS: It is inspired by Simon Willamson\\'s\\nosread\\nInstallation\\nInstall this\n",
       "tool using pip:\\npip\\ninstall\\noswrite\\nUsage\\noswrite --audio_file \"test.mp3\"\\nYou will need an OpenAI API key. \n",
       "You can set that as an environment variable:\\nexport OPENAI_API_KEY=\"...\"\\nOr you can pass it using \n",
       "--token:\\noswrite --token \"...\" --audio_file \"test.mp3\"\\nSaving transcribed result\\nIf you want to save transcribed\n",
       "result to a file, additionally you can add\\noutput\\nparameter with a filename.\\nFor text file:\\noswrite --token \n",
       "\"...\" --audio_file \"test.mp3 --output \"test.txt\"\\nFor docx file:\\noswrite --token \"...\" --audio_file \"test.mp3 \n",
       "--output \"test.docx\"\\nAbout\\nNo description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n2\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\n2\\nSupport to save result on disk\\nLatest\\nNov 7, 2023\\n+ 1 release\\nPackages\\n0\\nNo packages\n",
       "published\\nLanguages\\nPython\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'885F:1F5C5:449271:5BCF22:67C8D63E', 'html-safe-nonce': \n",
       "'166a7a4f4707343e818a87768b023016b69ac32c5b90fef7dacdf5e4b2b0adf9', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVGOjFGNUM1OjQ0OTI3MTo1QkNGMjI6NjdDOEQ2M0UiLCJ2aXNpdG9yX2lkIjoiNjQzOTc0Mz\n",
       "kwNTE2Mzk1NzgyMiIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'034b3de39629545272c8aa9a7cac28004775b84dc86d15f7a64084d21225219e', 'hovercard-subject-tag': \n",
       "'repository:715451925', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/oswrite development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/oswrite', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/948bd8e074e80abcac6ae0915e97960a11403df0a73719647f98e60739ad4d37/nepalprabin/os\n",
       "write', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/oswrite', 'twitter:description': 'Contribute to nepalprabin/oswrite development by creating an account \n",
       "on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'go-import': 'github.com/nepalprabin/oswrite git https://github.com/nepalprabin/oswrite.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '715451925', 'octolytics-dimension-repository_nwo': 'nepalprabin/oswrite', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '715451925', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/oswrite', 'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/oswrite/stargazers': {'title': 'Stargazers · nepalprabin/oswrite · GitHub', \n",
       "'text': 'Stargazers · nepalprabin/oswrite · GitHub\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\noswrite\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n2\\nStargazers\\numeshbudha1\\nIs from South Dakota, US\\nSouth Dakota, \n",
       "US\\nFollow\\nbipulbhattarai\\nIs from USA\\nUSA\\nFollow\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/:user_id/:repository/stargazers(.:format)', 'route-controller': 'repositories', 'route-action':\n",
       "'stargazers', 'current-catalog-service-hash': '505a3631cbcc69b4198e2324e6cd4015c05647a2165333b8faf6274e25e2d290', \n",
       "'request-id': '885F:377FE1:47E201:5FD0F6:67C8D63F', 'html-safe-nonce': \n",
       "'efe8207eaed6a84581c664439f2253c10fec185416926cce1092ad3fd6db000c', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVGOjM3N0ZFMTo0N0UyMDE6NUZEMEY2OjY3QzhENjNGIiwidmlzaXRvcl9pZCI6Ijc4MDIyMT\n",
       "ExOTA0OTA4NDY3ODMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'54b5b56befb052c1c41202937e0623802a7ed340e159107fec22d0e43c2db78c', 'hovercard-subject-tag': \n",
       "'repository:715451925', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;/repositories/stargazers', 'viewport': 'width=device-width', \n",
       "'description': 'Contribute to nepalprabin/oswrite development by creating an account on GitHub.', \n",
       "'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/nepalprabin/oswrite/stargazers', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/948bd8e074e80abcac6ae0915e97960a11403df0a73719647f98e60739ad4d37/nepalprabin/os\n",
       "write', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'Stargazers · \n",
       "nepalprabin/oswrite', 'twitter:description': 'Contribute to nepalprabin/oswrite development by creating an account \n",
       "on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'go-import': 'github.com/nepalprabin/oswrite git https://github.com/nepalprabin/oswrite.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '715451925', 'octolytics-dimension-repository_nwo': 'nepalprabin/oswrite', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '715451925', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/oswrite', 'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/basic-deeplearning-notebooks': {'title': 'GitHub - \n",
       "nepalprabin/basic-deeplearning-notebooks', 'text': 'GitHub - nepalprabin/basic-deeplearning-notebooks\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nnepalprabin\\n/\\nbasic-deeplearning-notebooks\\nPublic\\nNotifications\\nYou must be \n",
       "signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/basic-deeplearning-notebooks\\nmaster\\nBranches\\nTags\\nGo to \n",
       "file\\nCode\\nFolders and files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n12 \n",
       "Commits\\nANN_in_tensorflow2_0.ipynb\\nANN_in_tensorflow2_0.ipynb\\nConvoluiton_Neural_Networks.ipynb\\nConvoluiton_Neu\n",
       "ral_Networks.ipynb\\nData_Augmentation.ipynb\\nData_Augmentation.ipynb\\nImage_Classification.ipynb\\nImage_Classificat\n",
       "ion.ipynb\\nImage_segmentation.ipynb\\nImage_segmentation.ipynb\\nREADME.md\\nREADME.md\\nRecurrent_Neural_Networks.ipyn\n",
       "b\\nRecurrent_Neural_Networks.ipynb\\nTransfer_Learning.ipynb\\nTransfer_Learning.ipynb\\naerial_cactus_identification.\n",
       "ipynb\\naerial_cactus_identification.ipynb\\nfeedforward_nn.ipynb\\nfeedforward_nn.ipynb\\nmnist.ipynb\\nmnist.ipynb\\nVi\n",
       "ew all files\\nRepository files navigation\\ntensorflow\\nIt consists all the work done using tensorflow \n",
       "library.\\nAbout\\nNo description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n0\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8860:7DBF0:48C01E:62149F:67C8D640', 'html-safe-nonce': \n",
       "'73b42403e91732c2d7d5e815bbf1bcdf9638f4ebdbc2ea49af90ec9a212cc06a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYwOjdEQkYwOjQ4QzAxRTo2MjE0OUY6NjdDOEQ2NDAiLCJ2aXNpdG9yX2lkIjoiODA5NDg3MT\n",
       "UyNDc2MDY3MTgwOCIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'52e419063c5fc43cbc4f893f806e8ad984dc70dec9c773a26703fad8bde4d26b', 'hovercard-subject-tag': \n",
       "'repository:174201663', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/basic-deeplearning-notebooks development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/basic-deeplearning-notebooks', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/9417e881c66303a5cfe0f3f694bdba6ba72c1a476113f10e84fc0ad9056a2aa2/nepalprabin/ba\n",
       "sic-deeplearning-notebooks', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': \n",
       "'GitHub - nepalprabin/basic-deeplearning-notebooks', 'twitter:description': 'Contribute to \n",
       "nepalprabin/basic-deeplearning-notebooks development by creating an account on GitHub.', 'hostname': 'github.com', \n",
       "'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/basic-deeplearning-notebooks git \n",
       "https://github.com/nepalprabin/basic-deeplearning-notebooks.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '174201663', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/basic-deeplearning-notebooks', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '174201663', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/basic-deeplearning-notebooks', 'turbo-body-classes': 'logged-out env-production page-responsive', \n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/deeplearning-paper-implementation': {'title': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation', 'text': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\ndeeplearning-paper-implementation\\nPublic\\nNotifications\\nYou must be signed in to change \n",
       "notification settings\\nFork\\n1\\nStar\\n3\\n3\\nstars\\n1\\nfork\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must\n",
       "be signed in to change notification \n",
       "settings\\nnepalprabin/deeplearning-paper-implementation\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n13 \n",
       "Commits\\nAlexNet\\nAlexNet\\nGoogLeNet\\nGoogLeNet\\nR-CNN\\nR-CNN\\nStyleTransfer\\nStyleTransfer\\nU-Net\\nU-Net\\nVGGNet\\n\n",
       "VGGNet\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\ndeeplearning-architecture\\nI am trying \n",
       "to keep record of research papers that I have read or trying to read so far.\\nResearch Papers\\nLink\\nImageNet \n",
       "Classification with Deep Convolutional Neural Networks \n",
       "(AlexNet)\\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\\nV\n",
       "ery Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)\\nhttps://arxiv.org/pdf/1409.1556.pdf\\nGoing Deeper with Convolutions \n",
       "(GoogLeNet)\\nhttps://arxiv.org/abs/1409.4842\\nRich feature hierarchies for accurate object detection and semantic \n",
       "segmentation (R-CNN)\\nhttps://arxiv.org/abs/1311.2524\\nU-Net: Convolutional Networks for Biomedical Image \n",
       "Segmentation\\nhttps://arxiv.org/abs/1505.04597\\nA Neural Algorithm of Artistic \n",
       "Style\\nhttps://arxiv.org/abs/1508.06576\\nGenerative Adversarial \n",
       "Networks\\nhttps://arxiv.org/abs/1406.2661\\nConditional Generative Adversarial \n",
       "Nets\\nhttps://arxiv.org/abs/1411.1784\\nUnsupervised Representation Learning with Deep Convolutional Generative \n",
       "Adversarial Networks (DCGAN)\\nhttps://arxiv.org/abs/1511.06434\\nImage-to-Image Translation with Conditional \n",
       "Adversarial Networks (pix2pix)\\nhttps://arxiv.org/abs/1611.07004\\nUnpaired Image-to-Image Translation using \n",
       "Cycle-Consistent Adversarial Networks (CycleGAN)\\nhttps://arxiv.org/abs/1703.10593\\nMobileNets: Efficient \n",
       "Convolutional Neural Networks for Mobile Vision Applications\\nhttps://arxiv.org/abs/1704.04861\\nAbout\\nNo \n",
       "description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n3\\nstars\\nWatchers\\n2\\nwatching\\nForks\\n1\\nfork\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8861:E962E:4963E9:62AD24:67C8D641', 'html-safe-nonce': \n",
       "'fa28ef0c6b8e54602c65b7c94eda697096b167245b463addfeac76a55a0b8a8f', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYxOkU5NjJFOjQ5NjNFOTo2MkFEMjQ6NjdDOEQ2NDEiLCJ2aXNpdG9yX2lkIjoiMjkyNzYzMD\n",
       "cyNjM4NjQ3MjUxMyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'06349d64488eaba132857900847a3799ab3e3f32e13f4f60145e227afed47ce4', 'hovercard-subject-tag': \n",
       "'repository:258506110', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/deeplearning-paper-implementation', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/d61eb70bb4254782d7a0f8845a227f0e3d5e12fd0c4d55302ba65e77920654d9/nepalprabin/de\n",
       "eplearning-paper-implementation', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', \n",
       "'twitter:title': 'GitHub - nepalprabin/deeplearning-paper-implementation', 'twitter:description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'hostname': \n",
       "'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/deeplearning-paper-implementation git \n",
       "https://github.com/nepalprabin/deeplearning-paper-implementation.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '258506110', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/deeplearning-paper-implementation', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '258506110', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/deeplearning-paper-implementation', 'turbo-body-classes': 'logged-out env-production page-responsive',\n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}}\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "{'https://nepalprabin.github.io': {'title': 'Prabin Nepal', 'text': 'Prabin \n",
       "Nepal\\nCategories\\nAll\\n(16)\\nLLM\\n(1)\\nNLP\\n(4)\\nagents\\n(1)\\ncomputer-vision\\n(6)\\ndeep-learning\\n(12)\\nllms\\n(1)\n",
       "\\nmachine-learning\\n(2)\\nself-supervised-learning\\n(1)\\nHuggingface AI Agents Quiz Solutions\\nllms\\nagents\\nI have \n",
       "been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding\n",
       "of how to build and deploy AI agents using the\\nsmol…\\nMar 2, 2025\\nAugmenting Large Language Models: Expanding \n",
       "Context and Enhancing Relevance\\nmachine-learning\\nNLP\\ndeep-learning\\nLLM\\nWith the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…\\nJul 4, 2023\\nBrief overview of GPT-4\\nmachine-learning\\nNLP\\ndeep-learning\\nSince \n",
       "the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural \n",
       "language processing communities regarding its…\\nMar 15, 2023\\nText Summarization NLP\\nNLP\\ndeep-learning\\nText \n",
       "summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened \n",
       "automatically while holding the same semantic meaning.…\\nOct 19, 2022\\nAutocorrect and Minimum Edit \n",
       "Distance\\nNLP\\ndeep-learning\\nThis is my brief note from\\nDeepLearning.AI’s\\nNLP Specialization Course.\\nOct 25, \n",
       "2021\\nIllustrated Vision Transformers\\ncomputer-vision\\ndeep-learning\\nEver since Transformer was introduced in \n",
       "2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP tasks use \n",
       "Transformers and…\\nJul 27, 2021\\nPaper Explanation: A Simple Framework for Contrastive Learning of Visual \n",
       "Representations (simCLR)\\nVarious self-supervised learning methods have been proposed in recent years for learning \n",
       "image representations. Though a lot of methods have been proposed, the performance…\\nMar 26, 2021\\nDeep Residual \n",
       "Learning for Image Recognition (ResNet paper explained)\\nDeep Neural Networks tend to provide more accuracy as the \n",
       "number of layers increases. But, as we go more deeper in the network, the accuracy of the network decreases \n",
       "instead…\\nJan 1, 2021\\nSelf-supervised Learning\\ndeep-learning\\nself-supervised-learning\\nI have been exploring \n",
       "self-supervised learning and been through papers and blogs to understand it. Self-supervised learning is considered\n",
       "the next big thing in deep learning…\\nDec 8, 2020\\nMobileNet Architecture Explained\\ndeep-learning\\nIn this blog \n",
       "post, I will try to write about the MobileNets and its architecture. MobileNet uses depthwise separable \n",
       "convolutions instead of standard convolution to reduce…\\nSep 21, 2020\\nNeural style transfer and its working\\nHave \n",
       "you ever used an app called Prisma that styles your image using popular paintings and turns your photo stunning? If\n",
       "that’s the case then, the app you are using is the…\\nAug 23, 2020\\nDeep Convolutional Generative Adversarial \n",
       "Networks (DCGANs)\\ncomputer-vision\\ndeep-learning\\nDCGAN (Deep Convolutional General Adversarial Networks) uses \n",
       "convolutional layers in its design.\\nAug 15, 2020\\nGeneral Adversarial Networks \n",
       "(GANs)\\ncomputer-vision\\ndeep-learning\\n“\\nGeneral Adversarial Nets\\nis the most interesting idea in the last 10 \n",
       "years in machine learning”. This was the statement from Yann LeCun regarding GANs when Ian Goodfellow…\\nAug 4, \n",
       "2020\\nPaper Explanation: Going deeper with Convolutions (GoogLeNet)\\ncomputer-vision\\ndeep-learning\\nGoogle \n",
       "proposed a deep Convolution Neural Network named inception that achieved top results for classification and \n",
       "detection in ILSVRC 2014.\\nJun 5, 2020\\nVGGNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nVGGNet is a \n",
       "Convolutional Neural Network architecture proposed by Karen Simonyan and Andrew Zisserman of University of Oxford \n",
       "in 2014. This paper mailny focuses in the…\\nMay 9, 2020\\nAlexNet Architecture \n",
       "Explained\\ncomputer-vision\\ndeep-learning\\nAlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large\n",
       "margin (15.3% vs 26.2%(second place) error rates). Here is the link to original paper.\\nApr 24, 2020\\nNo matching \n",
       "items', 'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes', 'quarto:offset': './'}, 'depth': 0}, 'https://nepalprabin.github.io/index.html': {'title': \n",
       "'Prabin Nepal', 'text': 'Prabin \n",
       "Nepal\\nCategories\\nAll\\n(16)\\nLLM\\n(1)\\nNLP\\n(4)\\nagents\\n(1)\\ncomputer-vision\\n(6)\\ndeep-learning\\n(12)\\nllms\\n(1)\n",
       "\\nmachine-learning\\n(2)\\nself-supervised-learning\\n(1)\\nHuggingface AI Agents Quiz Solutions\\nllms\\nagents\\nI have \n",
       "been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding\n",
       "of how to build and deploy AI agents using the\\nsmol…\\nMar 2, 2025\\nAugmenting Large Language Models: Expanding \n",
       "Context and Enhancing Relevance\\nmachine-learning\\nNLP\\ndeep-learning\\nLLM\\nWith the rise of ChatGPT and other \n",
       "large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both \n",
       "fascination and concern. While…\\nJul 4, 2023\\nBrief overview of GPT-4\\nmachine-learning\\nNLP\\ndeep-learning\\nSince \n",
       "the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural \n",
       "language processing communities regarding its…\\nMar 15, 2023\\nText Summarization NLP\\nNLP\\ndeep-learning\\nText \n",
       "summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened \n",
       "automatically while holding the same semantic meaning.…\\nOct 19, 2022\\nAutocorrect and Minimum Edit \n",
       "Distance\\nNLP\\ndeep-learning\\nThis is my brief note from\\nDeepLearning.AI’s\\nNLP Specialization Course.\\nOct 25, \n",
       "2021\\nIllustrated Vision Transformers\\ncomputer-vision\\ndeep-learning\\nEver since Transformer was introduced in \n",
       "2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP tasks use \n",
       "Transformers and…\\nJul 27, 2021\\nPaper Explanation: A Simple Framework for Contrastive Learning of Visual \n",
       "Representations (simCLR)\\nVarious self-supervised learning methods have been proposed in recent years for learning \n",
       "image representations. Though a lot of methods have been proposed, the performance…\\nMar 26, 2021\\nDeep Residual \n",
       "Learning for Image Recognition (ResNet paper explained)\\nDeep Neural Networks tend to provide more accuracy as the \n",
       "number of layers increases. But, as we go more deeper in the network, the accuracy of the network decreases \n",
       "instead…\\nJan 1, 2021\\nSelf-supervised Learning\\ndeep-learning\\nself-supervised-learning\\nI have been exploring \n",
       "self-supervised learning and been through papers and blogs to understand it. Self-supervised learning is considered\n",
       "the next big thing in deep learning…\\nDec 8, 2020\\nMobileNet Architecture Explained\\ndeep-learning\\nIn this blog \n",
       "post, I will try to write about the MobileNets and its architecture. MobileNet uses depthwise separable \n",
       "convolutions instead of standard convolution to reduce…\\nSep 21, 2020\\nNeural style transfer and its working\\nHave \n",
       "you ever used an app called Prisma that styles your image using popular paintings and turns your photo stunning? If\n",
       "that’s the case then, the app you are using is the…\\nAug 23, 2020\\nDeep Convolutional Generative Adversarial \n",
       "Networks (DCGANs)\\ncomputer-vision\\ndeep-learning\\nDCGAN (Deep Convolutional General Adversarial Networks) uses \n",
       "convolutional layers in its design.\\nAug 15, 2020\\nGeneral Adversarial Networks \n",
       "(GANs)\\ncomputer-vision\\ndeep-learning\\n“\\nGeneral Adversarial Nets\\nis the most interesting idea in the last 10 \n",
       "years in machine learning”. This was the statement from Yann LeCun regarding GANs when Ian Goodfellow…\\nAug 4, \n",
       "2020\\nPaper Explanation: Going deeper with Convolutions (GoogLeNet)\\ncomputer-vision\\ndeep-learning\\nGoogle \n",
       "proposed a deep Convolution Neural Network named inception that achieved top results for classification and \n",
       "detection in ILSVRC 2014.\\nJun 5, 2020\\nVGGNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nVGGNet is a \n",
       "Convolutional Neural Network architecture proposed by Karen Simonyan and Andrew Zisserman of University of Oxford \n",
       "in 2014. This paper mailny focuses in the…\\nMay 9, 2020\\nAlexNet Architecture \n",
       "Explained\\ncomputer-vision\\ndeep-learning\\nAlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large\n",
       "margin (15.3% vs 26.2%(second place) error rates). Here is the link to original paper.\\nApr 24, 2020\\nNo matching \n",
       "items', 'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, \n",
       "user-scalable=yes', 'quarto:offset': './'}, 'depth': 1}, 'https://nepalprabin.github.io/projects.html': {'title': \n",
       "'Projects – Prabin Nepal', 'text': 'Projects – Prabin Nepal\\n1.\\nStanford NLP Lecture Transcription using OpenAI’s \n",
       "Whisper\\nWhisper is an automatic speech recognition (ASR) model trained on hours of multilingual and multitask \n",
       "supervised data. It is implemented as an encoder-decoder transformer architecture where audio are splitted into 30 \n",
       "seconds of chunks, converted into a log-Mel spectrogram, and then passed into an encoder. The decoder is trained to\n",
       "predict the corresponding text caption, intermixed with special tokens that direct the single model to perform \n",
       "tasks such as language identification, phrase-level timestamps, multilingual speech transcription, and to-English \n",
       "speech translation. For more info about whisper, read\\nhere\\n.\\nI used whisper model to transcribe Stanford NLP \n",
       "lectures into corresponding text captions.\\nHere\\nis the result of the transcribed lectures. This web app is build \n",
       "using Flask and deployed on AWS EC2 instance. You can find transcribed audio file in the form of \n",
       "text\\nhere\\n.\\n2.\\nCustom Named Entity Recognizer for clinical data\\nNamed Entity Recognition (NER) is a subtask of\n",
       "Natural Language Processing (NLP) that involves identifying and categorizing named entities in text.\\nI have \n",
       "developed a custom named entity recognition (NER) model for clinical data using the spacy framework and deployed it\n",
       "using Streamlit. The model is capable of identifying various entities such as diseases, treatments, medications, \n",
       "and anatomical locations from clinical text data. The model classifies entities based on three \n",
       "classes:\\n‘MEDICINE’\\n,\\n“MEDICALCONDITION”\\n, and\\n“PATHOGEN”\\n. The dataset was used from\\nkaggle\\n. You can try \n",
       "the application on this\\nlink\\n3.\\nQuestion Answering using Langchain and OpenAI\\nThis application provides a \n",
       "simple example of how to build a question-answering system using Langchain and pre-trained language models from \n",
       "OpenAI and Streamlit.\\nLangchain helps to build Large Language Models (LLMs) through composability. It helps to \n",
       "combine large language models with other sources of computation.\\nI developed a question answering system using \n",
       "Langchain with OpenAI embeddings. Since, LLMs tends to have fixed context length, Langchain helps to eliminate this\n",
       "issue by introducing chains, where we can break the document into different chunks and run the chain on the whole \n",
       "document. In this application, when a user uploads a file, the contents are converted into embeddings using OpenAI \n",
       "embeddings and stored in Pinecone vector database. Storing embeddings this way, helps for faster retrieval of the \n",
       "embeddings. When a user enters the query, similarity search is conducted to retrieve the similar embeddings from \n",
       "the vector store and the langchain chain passes the formatted response to the LLM.', 'metadata': {'generator': \n",
       "'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', 'quarto:offset': './'}, \n",
       "'depth': 1}, 'https://github.com/nepalprabin': {'title': 'nepalprabin (Prabin Nepal) · GitHub', 'text': \n",
       "\"nepalprabin (Prabin Nepal) · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto \n",
       "refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched \n",
       "accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocus\n",
       "ing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI \n",
       "enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or \n",
       "report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you \n",
       "notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional \n",
       "note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 \n",
       "characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub \n",
       "support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport \n",
       "abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\n/\\nREADME\\n.md\\nHi 👋, I'm Prabin \n",
       "Nepal\\nA passionate software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 \n",
       "Ask me about\\nFull Stack Development, Deep Learning\\n📫 How to reach \n",
       "me\\nprabinnepal1996@gmail.com\\nPinned\\nLoading\\noswrite\\noswrite\\nPublic\\nPython\\n2\\nbasic-deeplearning-notebooks\\n\n",
       "basic-deeplearning-notebooks\\nPublic\\nJupyter \n",
       "Notebook\\ndeeplearning-paper-implementation\\ndeeplearning-paper-implementation\\nPublic\\nJupyter \n",
       "Notebook\\n3\\n1\\nwhisper-webapp\\nwhisper-webapp\\nPublic\\nJupyter Notebook\\nSomething went wrong, please refresh the \n",
       "page to try again.\\nIf the problem persists, check the\\nGitHub status page\\nor\\ncontact support\\n.\\nYou can’t \n",
       "perform that action at this time.\", 'metadata': {'route-pattern': '/:user_id(.:format)', 'route-controller': \n",
       "'profiles', 'route-action': 'show', 'current-catalog-service-hash': \n",
       "'4a1c50a83cf6cc4b55b6b9c53e553e3f847c876b87fb333f71f5d05db8f1a7db', 'request-id': \n",
       "'8825:212693:4608B2:5DA231:67C8D5F4', 'html-safe-nonce': \n",
       "'b2bd1705280defe3c9fec4ef96c15d374642689d4c7ac54a830e84979a8402e4', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODI1OjIxMjY5Mzo0NjA4QjI6NURBMjMxOjY3QzhENUY0IiwidmlzaXRvcl9pZCI6Ijg1MzczND\n",
       "AzNzQxNDk1NTE2MDQiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'c116c9ee9e1158c8253bd84121072faca545d06f33556639b71a2be0e4513444', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'analytics-location': '/<user-name>', 'viewport': \n",
       "'width=device-width', 'description': 'Software Developer. AI enthusiast. nepalprabin has 84 repositories available.\n",
       "Follow their code on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin', 'twitter:image': \n",
       "'https://avatars.githubusercontent.com/u/43682497?v=4?s=400', 'twitter:site': '@github', 'twitter:card': 'summary',\n",
       "'twitter:title': 'nepalprabin - Overview', 'twitter:description': 'Software Developer. AI enthusiast. nepalprabin \n",
       "has 84 repositories available. Follow their code on GitHub.', 'hostname': 'github.com', 'expected-hostname': \n",
       "'github.com', 'turbo-cache-control': 'no-preview', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'turbo-body-classes': 'logged-out env-production page-responsive \n",
       "page-profile', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "1}, 'https://nepalprabin.github.io/posts/2025-03-02-huggingface-smolagents-solutions.html': {'title': 'Huggingface \n",
       "AI Agents Quiz Solutions – Prabin Nepal', 'text': 'Huggingface AI Agents Quiz Solutions – Prabin Nepal\\nI have been\n",
       "diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of \n",
       "how to build and deploy AI agents using the\\nsmolagents\\nlibrary. In this blog, I’ll share insights from the course\n",
       "(Unit 2) and provide code snippets to illustrate key concepts.\\nNote\\nHere is the course link if anyone is \n",
       "interested.\\nAI Agents Course\\nCreate a Basic Code Agent with Web Search Capability\\nOne of the foundational \n",
       "exercises involves creating a CodeAgent equipped with web search capabilities. This agent leverages the \n",
       "DuckDuckGoSearchTool to perform web searches, enabling it to fetch real-time information. Here’s how you can set it\n",
       "up:\\n# Create a CodeAgent with DuckDuckGo search capability\\nfrom\\nsmolagents\\nimport\\nCodeAgent, \n",
       "DuckDuckGoSearchTool, HfApiModel\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\n# Add search tool \n",
       "here\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Add model here\\n)\\nIn this snippet, we \n",
       "initialize a CodeAgent with the DuckDuckGoSearchTool, allowing the agent to perform web searches to answer \n",
       "queries.\\nSet Up a Multi-Agent System with Manager and Web Search Agents\\nMulti-Agent systems are the agents that \n",
       "are specialized on complex tasks with more scalable and robust nature. In\\nsmolagents\\n, various agents can be \n",
       "integrated to produce Python code, invoke external tools, conduct web searches, and more. By coordinating these \n",
       "agents, it’s possible to develop robust workflows. A typical multi-agent system includes:\\n- A manager Agent\\n- A \n",
       "code interpreter Agent\\n- A web Search Agent\\nMulti-agent system allows to separate memories between different \n",
       "sub-tasks and provide great benefits. Firstly, each agent are more focused on its core taks and secondly, \n",
       "separating memories reduces the count of input tokens resulting in reducing latency and cost. Below is the \n",
       "multi-agent system when\\nweb_agent\\nperforms search and\\nmanager_agent\\ngives data analysis capabilities. Also, we \n",
       "can import dependencies (like python libraries) that helps to perform the \n",
       "tasks.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel, \n",
       "VisitWebpageTool\\nweb_agent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool(), \n",
       "VisitWebpageTool()],\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nmax_steps\\n=\\n10\\n,\\\n",
       "nname\\n=\\n\"search\"\\n,\\ndescription\\n=\\n\"Agent to perform web searches and visit \n",
       "webpages.\"\\n)\\nmanager_agent\\n=\\nCodeAgent(\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\n",
       ",\\nmanaged_agents\\n=\\n[web_agent],\\nadditional_authorized_imports\\n=\\n[\\n\"pandas\"\\n,\\n\"time\"\\n,\\n\"numpy\"\\n]\\n# \n",
       "Corrected imports\\n)\\nConfigure Agent Security Settings\\nSecurity is a crucial aspect when deploying AI agents, \n",
       "especially when they execute code. Below code snippet uses E2B to run code in a sandboxed environment. It is a \n",
       "remote execution that run the code in a isolated container.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, \n",
       "HfApiModel\\nfrom\\nsmolagents.sandbox\\nimport\\nE2BSandbox\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\\n",
       "n)\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[],\\nmodel\\n=\\nmodel,\\nsandbox\\n=\\nE2BSandbox(),\\n# Configure the \n",
       "sandbox\\nadditional_authorized_imports\\n=\\n[\\n\"numpy\"\\n],\\n# Authorize numpy import\\n)\\nImplement a Tool-Calling \n",
       "Agent\\nSimilar to\\nCodeAgent\\n,\\nToolCallingAgent\\nis another type of agent available in smolagent library. \n",
       "CodeAgent uses Python code snippets whereas ToolCallingAgent use built-in tool-calling capabilities of LLM \n",
       "providers and generate JSON structures.\\nfrom\\nsmolagents\\nimport\\nToolCallingAgent, HfApiModel, \n",
       "DuckDuckGoSearchTool\\nagent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\nmodel\\n=\\nHfApiModel(model_\n",
       "id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nname\\n=\\n\"SearchAgent\"\\n,\\ndescription\\n=\\n\"An agent that uses \n",
       "DuckDuckGo to search the web.\"\\n,\\nmax_steps\\n=\\n5\\n,\\n)\\nSet Up Model Integration\\nLLM models are the most \n",
       "important aspect when creating AI agents. There are many model availables for various tasks and domains. So we can \n",
       "easily integrate models that is required for our task. Below code snippet switches between two different models \n",
       "providers.\\nfrom\\nsmolagents\\nimport\\nHfApiModel, LiteLLMModel\\n# Initialize Hugging Face \n",
       "model\\nhf_model\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Initialize LiteLLM model as an \n",
       "alternative model\\nother_model\\n=\\nLiteLLMModel(model_id\\n=\\n\"anthropic/claude-3-sonnet\"\\n)\\n# Set the model to \n",
       "hf_model or alternative model\\nmodel\\n=\\nhf_model\\n# Alternatively, you can switch this to `other_model`', \n",
       "'metadata': {'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', \n",
       "'dcterms.date': '2025-03-02', 'quarto:offset': '../'}, 'depth': 1}, \n",
       "'https://nepalprabin.github.io/posts/2023-07-04-augmented-language-models.html': {'title': 'Augmenting Large \n",
       "Language Models: Expanding Context and Enhancing Relevance – Prabin Nepal', 'text': 'Augmenting Large Language \n",
       "Models: Expanding Context and Enhancing Relevance – Prabin Nepal\\nWith the rise of ChatGPT and other large language\n",
       "models (LLMs), the potential for AI to surpass human capabilities has become a topic of both fascination and \n",
       "concern. While LLMs excel at understanding language, following instructions, and reasoning, they often fall short \n",
       "when it comes to performing specific tasks. Simply inputting a prompt into ChatGPT may result in answers that are \n",
       "unrelated or out of context, a phenomenon known as “hallucination.” To obtain relevant information, it is crucial \n",
       "to provide the model with the appropriate context. However, the size of the context window is limited, posing a \n",
       "challenge in capturing all necessary information. Although the context size has increased over time, storing \n",
       "extensive information within a fixed context window remains impractical and expensive. This is where the \n",
       "augmentation of language models comes into play.\\nAugmenting large language models involves three primary \n",
       "approaches:\\nretrieval,\\nchains, and\\ntools.\\nThese methods aim to enhance the capabilities of LLMs by providing \n",
       "them with additional resources and functionalities.\\nRetrieval Augmentation:\\nRetrieval augmentation involves \n",
       "leveraging an external corpus of data for the language model to search through. Traditionally, retrieval algorithms\n",
       "employ queries to rank relevant objects in a collection, which can include images, texts, documents, or other types\n",
       "of data. To enable efficient searching, the documents and their corresponding features are organized within an \n",
       "index. This index maps each feature to the documents containing it, facilitating quick retrieval. Boolean search \n",
       "determines the relevance of documents based on the query, while ranking is typically performed using algorithms \n",
       "like BM25 (Best Match 25).\\nBM25 (Best Match 25) is a ranking function commonly used in information retrieval to \n",
       "measure the relevance of a document to a given query. It is a probabilistic retrieval model that enhances the \n",
       "vector space model by incorporating document length normalization and term frequency saturation.\\nIn BM25, the \n",
       "indexing process involves tokenizing each document in the collection into terms and calculating term statistics \n",
       "such as document frequency (df) and inverse document frequency (idf). Document frequency represents the number of \n",
       "documents in the collection containing a particular term, while inverse document frequency measures the rarity of \n",
       "the term across the collection.\\nDuring the querying phase, the query is tokenized into terms, and term statistics,\n",
       "including query term frequency (qtf) and query term inverse document frequency (qidf), are computed. These \n",
       "statistics capture the occurrence and relevance of terms in the query.\\nWhile traditional retrieval methods \n",
       "primarily rely on keyword matching and statistical techniques, modern approaches leverage AI-centric retrieval \n",
       "methods that utilize embeddings. These methods offer improved search capabilities and help retrieve contextually \n",
       "relevant information.\\nChains\\nChains involve using the output of one language model as the input for another. By \n",
       "cascading multiple models together, the output of each model becomes the input for the subsequent one. This \n",
       "chaining process allows the models to build upon each other’s knowledge and reasoning abilities, potentially \n",
       "leading to more accurate and contextually appropriate responses.\\nThe sequential arrangement of models in a chain \n",
       "creates a pipeline of of interconnected language models, where the output of one model serves as the input for the \n",
       "next. This pipeline allows for a cascading flow of information and reasoning, enabling the models to collectively \n",
       "enhance their understanding and generate more accurate responses. By leveraging a chain of language models, each \n",
       "model can contribute its specialized knowledge and capabilities to the overall task. For example, one model may \n",
       "excel at language comprehension, while another may possess domain-specific knowledge.\\nAs the input passes through \n",
       "the chain, each model can refine and expand upon the information, leading to a more comprehensive and contextually \n",
       "relevant output. The chaining process in language models has the potential to address the limitations of indivi\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       " 'https://github.com/nepalprabin/nepalprabin': {'title': 'GitHub - nepalprabin/nepalprabin', 'text': \"GitHub - \n",
       "nepalprabin/nepalprabin\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\nnepalprabin\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/nepalprabin\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n14 \n",
       "Commits\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\nHi 👋, I'm Prabin Nepal\\nA passionate \n",
       "software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull \n",
       "Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nAbout\\nNo description, website, or\n",
       "topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nYou can’t perform that action at \n",
       "this time.\", 'metadata': {'route-pattern': '/:user_id/:repository', 'route-controller': 'files', 'route-action': \n",
       "'disambiguate', 'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb',\n",
       "'request-id': '885D:148B86:468AB6:5EA3B6:67C8D639', 'html-safe-nonce': \n",
       "'2e85c74115beb5e1e134f0c55ba7d98d8191a15ecc34599c10cf561436845743', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVEOjE0OEI4Njo0NjhBQjY6NUVBM0I2OjY3QzhENjM5IiwidmlzaXRvcl9pZCI6IjczODY4MD\n",
       "cyMDIwNzE3NjI0ODkiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'44b6648ccdfe752ed85305ebb06add2ba0881ec0366c36e35d31bdf78566a2aa', 'hovercard-subject-tag': \n",
       "'repository:278281752', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/nepalprabin development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/nepalprabin', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/938931e393aefe0802f7134e6271f2c2d66d2eacd02f8ab7f9f16dfbc37c3816/nepalprabin/ne\n",
       "palprabin', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'twitter:description': 'Contribute to nepalprabin/nepalprabin development by creating an \n",
       "account on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': \n",
       "'no-preview', 'go-import': 'github.com/nepalprabin/nepalprabin git https://github.com/nepalprabin/nepalprabin.git',\n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '278281752', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/nepalprabin', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '278281752',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/nepalprabin', 'turbo-body-classes': 'logged-out \n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2}, \n",
       "'https://camo.githubusercontent.com/33cf16865184db58d654ab7a61230f414cfce1b7328964bd6d054c104e00cd30/68747470733a2f\n",
       "2f6b6f6d617265762e636f6d2f67687076632f3f757365726e616d653d6e6570616c70726162696e': {'title': 'No title', 'text': \n",
       "'Profile views\\nProfile views\\n1,725\\n1,725', 'metadata': {}, 'depth': 2}, 'https://fb.com/prabin.nepal.92': \n",
       "{'title': 'Prabin Nepal', 'text': 'Prabin Nepal', 'metadata': {'bingbot': 'noarchive', 'viewport': \n",
       "'width=device-width,initial-scale=1,maximum-scale=2,shrink-to-fit=no', 'apple-itunes-app': 'app-id=284882215, \n",
       "app-argument=fb://profile/100005550337615', 'description': 'Prabin Nepal is on Facebook. Join Facebook to connect \n",
       "with Prabin Nepal and others you may know. Facebook gives people the power to share and makes the...', 'referrer': \n",
       "'default', 'robots': 'noodp,noydir,noimageindex,noarchive', 'twitter:card': 'summary', 'twitter:title': 'Prabin \n",
       "Nepal', 'twitter:description': 'Prabin Nepal is on Facebook. Join Facebook to connect with Prabin Nepal and others \n",
       "you may know. Facebook gives people the power to share and makes the world more open and connected.', \n",
       "'twitter:image': \n",
       "'https://scontent-iad3-2.xx.fbcdn.net/v/t39.30808-1/311694731_2004875619707430_4977667565115494685_n.jpg?cstp=mx958\n",
       "x960&ctp=s720x720&_nc_cat=111&ccb=1-7&_nc_sid=3ab345&_nc_ohc=E7yTPHDsMbUQ7kNvgHfCwy9&_nc_oc=AdhtfnD-MgJsMR1vujUJ3NC\n",
       "jtpm9zzwU0ZlH-lQ7hKsJGt0ncLvbTycNtznNS5WLyUnuxiR48ic96BDsuJlhsqWJ&_nc_zt=24&_nc_ht=scontent-iad3-2.xx&_nc_gid=Ai4Ff\n",
       "9EYub8-ff99Uc1eTfa&oh=00_AYB-Twf9stZNSnfASNNWYxlcboE3bMZ5COKeN8xZKARGOg&oe=67CEC0E6', 'twitter:image:alt': 'Prabin \n",
       "Nepal', 'twitter:site': '@facebookapp', 'color-scheme': 'light', 'theme-color': '#FFFFFF'}, 'depth': 2}, \n",
       "'https://medium.com/@prabinnepal1996': {'title': 'Medium', 'text': 'Medium\\nOpen in app\\nSign up\\nSign \n",
       "in\\nWrite\\nSign up\\nSign in\\nPAGE NOT FOUND\\n404\\nOut of nothing, something.\\nYou can find (just about) anything \n",
       "on\\nMedium\\n— apparently even a page that doesn’t exist. Maybe these stories will take you somewhere new?\\nHome\\nWe\n",
       "overestimate AI’s impact in the short-term and underestimate it long-term\\nThe Medium Newsletter\\nin\\nThe Medium \n",
       "Blog\\nMar 5, 2025\\n·\\n3 min read\\nWe overestimate AI’s impact in the short-term and underestimate it long-term\\nThe\n",
       "Medium Newsletter\\nin\\nThe Medium Blog\\nMar 5, 2025\\n·\\n3 min read\\nAt sea with the Black Knight\\nEYE IN THE \n",
       "SKY\\nFeb 25, 2025\\n·\\n13 min read\\nAt sea with the Black Knight\\nEYE IN THE SKY\\nFeb 25, 2025\\n·\\n13 min \n",
       "read\\nFinding My Photo Mojo, Light, and Equanimity in the Desert\\nCynthia A Whelan\\nin\\nLive View\\nMar 3, \n",
       "2025\\n·\\n5 min read\\nMember-only\\nFinding My Photo Mojo, Light, and Equanimity in the Desert\\nCynthia A \n",
       "Whelan\\nin\\nLive View\\nMar 3, 2025\\n·\\n5 min read\\nMember-only\\nWhy is DOGE not at all, like not even remotely, \n",
       "similar to the 1990s Program Review in Canada?\\nJennifer Robson\\nMar 5, 2025\\n·\\n16 min read\\nWhy is DOGE not at \n",
       "all, like not even remotely, similar to the 1990s Program Review in Canada?\\nJennifer Robson\\nMar 5, 2025\\n·\\n16 \n",
       "min read', 'metadata': {'viewport': 'width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1', \n",
       "'theme-color': '#000000', 'twitter:app:name:iphone': 'Medium', 'twitter:app:id:iphone': '828256236'}, 'depth': 2}, \n",
       "'https://github.com/nepalprabin/oswrite': {'title': 'GitHub - nepalprabin/oswrite', 'text': 'GitHub - \n",
       "nepalprabin/oswrite\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\noswrite\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n2\\n2\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/oswrite\\nmain\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n32 \n",
       "Commits\\n.github/\\nworkflows\\n.github/\\nworkflows\\n.vscode\\n.vscode\\noswrite\\noswrite\\ntests\\ntests\\n.gitignore\\n.g\n",
       "itignore\\nREADME.md\\nREADME.md\\npyproject.toml\\npyproject.toml\\nView all files\\nRepository files \n",
       "navigation\\noswrite\\nCLI tool for running audio through the OpenAI whisper API\\nSee oswrite: a CLI tool for running\n",
       "audio through the OpenAI whisper API.\\nPS: It is inspired by Simon Willamson\\'s\\nosread\\nInstallation\\nInstall this\n",
       "tool using pip:\\npip\\ninstall\\noswrite\\nUsage\\noswrite --audio_file \"test.mp3\"\\nYou will need an OpenAI API key. \n",
       "You can set that as an environment variable:\\nexport OPENAI_API_KEY=\"...\"\\nOr you can pass it using \n",
       "--token:\\noswrite --token \"...\" --audio_file \"test.mp3\"\\nSaving transcribed result\\nIf you want to save transcribed\n",
       "result to a file, additionally you can add\\noutput\\nparameter with a filename.\\nFor text file:\\noswrite --token \n",
       "\"...\" --audio_file \"test.mp3 --output \"test.txt\"\\nFor docx file:\\noswrite --token \"...\" --audio_file \"test.mp3 \n",
       "--output \"test.docx\"\\nAbout\\nNo description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n2\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\n2\\nSupport to save result on disk\\nLatest\\nNov 7, 2023\\n+ 1 release\\nPackages\\n0\\nNo packages\n",
       "published\\nLanguages\\nPython\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'885F:1F5C5:449271:5BCF22:67C8D63E', 'html-safe-nonce': \n",
       "'166a7a4f4707343e818a87768b023016b69ac32c5b90fef7dacdf5e4b2b0adf9', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVGOjFGNUM1OjQ0OTI3MTo1QkNGMjI6NjdDOEQ2M0UiLCJ2aXNpdG9yX2lkIjoiNjQzOTc0Mz\n",
       "kwNTE2Mzk1NzgyMiIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'034b3de39629545272c8aa9a7cac28004775b84dc86d15f7a64084d21225219e', 'hovercard-subject-tag': \n",
       "'repository:715451925', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/oswrite development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/oswrite', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/948bd8e074e80abcac6ae0915e97960a11403df0a73719647f98e60739ad4d37/nepalprabin/os\n",
       "write', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/oswrite', 'twitter:description': 'Contribute to nepalprabin/oswrite development by creating an account \n",
       "on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'go-import': 'github.com/nepalprabin/oswrite git https://github.com/nepalprabin/oswrite.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '715451925', 'octolytics-dimension-repository_nwo': 'nepalprabin/oswrite', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '715451925', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/oswrite', 'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/oswrite/stargazers': {'title': 'Stargazers · nepalprabin/oswrite · GitHub', \n",
       "'text': 'Stargazers · nepalprabin/oswrite · GitHub\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\noswrite\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n2\\nStargazers\\numeshbudha1\\nIs from South Dakota, US\\nSouth Dakota, \n",
       "US\\nFollow\\nbipulbhattarai\\nIs from USA\\nUSA\\nFollow\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/:user_id/:repository/stargazers(.:format)', 'route-controller': 'repositories', 'route-action':\n",
       "'stargazers', 'current-catalog-service-hash': '505a3631cbcc69b4198e2324e6cd4015c05647a2165333b8faf6274e25e2d290', \n",
       "'request-id': '885F:377FE1:47E201:5FD0F6:67C8D63F', 'html-safe-nonce': \n",
       "'efe8207eaed6a84581c664439f2253c10fec185416926cce1092ad3fd6db000c', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVGOjM3N0ZFMTo0N0UyMDE6NUZEMEY2OjY3QzhENjNGIiwidmlzaXRvcl9pZCI6Ijc4MDIyMT\n",
       "ExOTA0OTA4NDY3ODMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'54b5b56befb052c1c41202937e0623802a7ed340e159107fec22d0e43c2db78c', 'hovercard-subject-tag': \n",
       "'repository:715451925', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>/repositories/stargazers', 'viewport': 'width=device-width', \n",
       "'description': 'Contribute to nepalprabin/oswrite development by creating an account on GitHub.', \n",
       "'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/nepalprabin/oswrite/stargazers', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/948bd8e074e80abcac6ae0915e97960a11403df0a73719647f98e60739ad4d37/nepalprabin/os\n",
       "write', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'Stargazers · \n",
       "nepalprabin/oswrite', 'twitter:description': 'Contribute to nepalprabin/oswrite development by creating an account \n",
       "on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'go-import': 'github.com/nepalprabin/oswrite git https://github.com/nepalprabin/oswrite.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '715451925', 'octolytics-dimension-repository_nwo': 'nepalprabin/oswrite', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '715451925', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/oswrite', 'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/basic-deeplearning-notebooks': {'title': 'GitHub - \n",
       "nepalprabin/basic-deeplearning-notebooks', 'text': 'GitHub - nepalprabin/basic-deeplearning-notebooks\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nnepalprabin\\n/\\nbasic-deeplearning-notebooks\\nPublic\\nNotifications\\nYou must be \n",
       "signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/basic-deeplearning-notebooks\\nmaster\\nBranches\\nTags\\nGo to \n",
       "file\\nCode\\nFolders and files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n12 \n",
       "Commits\\nANN_in_tensorflow2_0.ipynb\\nANN_in_tensorflow2_0.ipynb\\nConvoluiton_Neural_Networks.ipynb\\nConvoluiton_Neu\n",
       "ral_Networks.ipynb\\nData_Augmentation.ipynb\\nData_Augmentation.ipynb\\nImage_Classification.ipynb\\nImage_Classificat\n",
       "ion.ipynb\\nImage_segmentation.ipynb\\nImage_segmentation.ipynb\\nREADME.md\\nREADME.md\\nRecurrent_Neural_Networks.ipyn\n",
       "b\\nRecurrent_Neural_Networks.ipynb\\nTransfer_Learning.ipynb\\nTransfer_Learning.ipynb\\naerial_cactus_identification.\n",
       "ipynb\\naerial_cactus_identification.ipynb\\nfeedforward_nn.ipynb\\nfeedforward_nn.ipynb\\nmnist.ipynb\\nmnist.ipynb\\nVi\n",
       "ew all files\\nRepository files navigation\\ntensorflow\\nIt consists all the work done using tensorflow \n",
       "library.\\nAbout\\nNo description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n0\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8860:7DBF0:48C01E:62149F:67C8D640', 'html-safe-nonce': \n",
       "'73b42403e91732c2d7d5e815bbf1bcdf9638f4ebdbc2ea49af90ec9a212cc06a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYwOjdEQkYwOjQ4QzAxRTo2MjE0OUY6NjdDOEQ2NDAiLCJ2aXNpdG9yX2lkIjoiODA5NDg3MT\n",
       "UyNDc2MDY3MTgwOCIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'52e419063c5fc43cbc4f893f806e8ad984dc70dec9c773a26703fad8bde4d26b', 'hovercard-subject-tag': \n",
       "'repository:174201663', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/basic-deeplearning-notebooks development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/basic-deeplearning-notebooks', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/9417e881c66303a5cfe0f3f694bdba6ba72c1a476113f10e84fc0ad9056a2aa2/nepalprabin/ba\n",
       "sic-deeplearning-notebooks', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': \n",
       "'GitHub - nepalprabin/basic-deeplearning-notebooks', 'twitter:description': 'Contribute to \n",
       "nepalprabin/basic-deeplearning-notebooks development by creating an account on GitHub.', 'hostname': 'github.com', \n",
       "'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/basic-deeplearning-notebooks git \n",
       "https://github.com/nepalprabin/basic-deeplearning-notebooks.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '174201663', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/basic-deeplearning-notebooks', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '174201663', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/basic-deeplearning-notebooks', 'turbo-body-classes': 'logged-out env-production page-responsive', \n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}, 'https://github.com/nepalprabin/deeplearning-paper-implementation': {'title': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation', 'text': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\ndeeplearning-paper-implementation\\nPublic\\nNotifications\\nYou must be signed in to change \n",
       "notification settings\\nFork\\n1\\nStar\\n3\\n3\\nstars\\n1\\nfork\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must\n",
       "be signed in to change notification \n",
       "settings\\nnepalprabin/deeplearning-paper-implementation\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n13 \n",
       "Commits\\nAlexNet\\nAlexNet\\nGoogLeNet\\nGoogLeNet\\nR-CNN\\nR-CNN\\nStyleTransfer\\nStyleTransfer\\nU-Net\\nU-Net\\nVGGNet\\n\n",
       "VGGNet\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\ndeeplearning-architecture\\nI am trying \n",
       "to keep record of research papers that I have read or trying to read so far.\\nResearch Papers\\nLink\\nImageNet \n",
       "Classification with Deep Convolutional Neural Networks \n",
       "(AlexNet)\\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\\nV\n",
       "ery Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)\\nhttps://arxiv.org/pdf/1409.1556.pdf\\nGoing Deeper with Convolutions \n",
       "(GoogLeNet)\\nhttps://arxiv.org/abs/1409.4842\\nRich feature hierarchies for accurate object detection and semantic \n",
       "segmentation (R-CNN)\\nhttps://arxiv.org/abs/1311.2524\\nU-Net: Convolutional Networks for Biomedical Image \n",
       "Segmentation\\nhttps://arxiv.org/abs/1505.04597\\nA Neural Algorithm of Artistic \n",
       "Style\\nhttps://arxiv.org/abs/1508.06576\\nGenerative Adversarial \n",
       "Networks\\nhttps://arxiv.org/abs/1406.2661\\nConditional Generative Adversarial \n",
       "Nets\\nhttps://arxiv.org/abs/1411.1784\\nUnsupervised Representation Learning with Deep Convolutional Generative \n",
       "Adversarial Networks (DCGAN)\\nhttps://arxiv.org/abs/1511.06434\\nImage-to-Image Translation with Conditional \n",
       "Adversarial Networks (pix2pix)\\nhttps://arxiv.org/abs/1611.07004\\nUnpaired Image-to-Image Translation using \n",
       "Cycle-Consistent Adversarial Networks (CycleGAN)\\nhttps://arxiv.org/abs/1703.10593\\nMobileNets: Efficient \n",
       "Convolutional Neural Networks for Mobile Vision Applications\\nhttps://arxiv.org/abs/1704.04861\\nAbout\\nNo \n",
       "description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n3\\nstars\\nWatchers\\n2\\nwatching\\nForks\\n1\\nfork\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8861:E962E:4963E9:62AD24:67C8D641', 'html-safe-nonce': \n",
       "'fa28ef0c6b8e54602c65b7c94eda697096b167245b463addfeac76a55a0b8a8f', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYxOkU5NjJFOjQ5NjNFOTo2MkFEMjQ6NjdDOEQ2NDEiLCJ2aXNpdG9yX2lkIjoiMjkyNzYzMD\n",
       "cyNjM4NjQ3MjUxMyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'06349d64488eaba132857900847a3799ab3e3f32e13f4f60145e227afed47ce4', 'hovercard-subject-tag': \n",
       "'repository:258506110', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/deeplearning-paper-implementation', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/d61eb70bb4254782d7a0f8845a227f0e3d5e12fd0c4d55302ba65e77920654d9/nepalprabin/de\n",
       "eplearning-paper-implementation', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', \n",
       "'twitter:title': 'GitHub - nepalprabin/deeplearning-paper-implementation', 'twitter:description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'hostname': \n",
       "'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/deeplearning-paper-implementation git \n",
       "https://github.com/nepalprabin/deeplearning-paper-implementation.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '258506110', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/deeplearning-paper-implementation', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '258506110', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/deeplearning-paper-implementation', 'turbo-body-classes': 'logged-out env-production page-responsive',\n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2}}\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 5.48 seconds| Input tokens: 26,220 | Output tokens: 565]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 5.48 seconds| Input tokens: 26,220 | Output tokens: 565]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Evaluate the relevance of each extracted content based on the given prompt</span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prompt </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Extract all the blog contents based on this prompt\"</span><span style=\"background-color: #272822\">                                                  </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">relevant_content </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> relevance_evaluation_tool(extracted_content</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">extracted_content, prompt</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prompt)</span><span style=\"background-color: #272822\">               </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(relevant_content)</span><span style=\"background-color: #272822\">                                                                                        </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Evaluate the relevance of each extracted content based on the given prompt\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprompt\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mExtract all the blog contents based on this prompt\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mrelevant_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevance_evaluation_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mextracted_content\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mextracted_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprompt\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprompt\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m               \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "{'https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip': {'title': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub', 'text': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nnepalprabin\\n/\\nwhisper-webapp\\nPublic\\nNotifications\\nYou must be signed in to \n",
       "change notification settings\\nFork\\n0\\nStar\\n0\\nFiles\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nCopy \n",
       "path\\nLatest commit\\nHistory\\nHistory\\n1.99 MB\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nTop\\nFile metadata \n",
       "and controls\\nCode\\nBlame\\n1.99 MB\\nRaw\\nView raw\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/:user_id/:repository/blob/*name(/*path)', 'route-controller': 'blob', 'route-action': 'show', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8825:212693:4639CC:5DE385:67C8D5FF', 'html-safe-nonce': \n",
       "'a73a88e30ba87696ba2c0f96fe9d20f3fefb8c4d427df35f678c3a170f3204da', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODI1OjIxMjY5Mzo0NjM5Q0M6NURFMzg1OjY3QzhENUZGIiwidmlzaXRvcl9pZCI6IjgyMjQ4MT\n",
       "U2MzE0NTIxMzI4NjMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'a3880ad0092bd286210060f48997f74d487d4ffc78c3e5bd4a2ea33b29728c50', 'hovercard-subject-tag': \n",
       "'repository:577396001', 'github-keyboard-shortcuts': 'repository,source-code,file-tree,copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;/blob/show', \n",
       "'viewport': 'width=device-width', 'description': 'Contribute to nepalprabin/whisper-webapp development by creating \n",
       "an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/484f653911c7141bb44f0082f00bf81b8485eaa351a0b07118e66484dadc85b1/nepalprabin/wh\n",
       "isper-webapp', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp', 'twitter:description': \n",
       "'Contribute to nepalprabin/whisper-webapp development by creating an account on GitHub.', 'hostname': 'github.com',\n",
       "'expected-hostname': 'github.com', 'turbo-cache-control': 'no-cache', 'go-import': \n",
       "'github.com/nepalprabin/whisper-webapp git https://github.com/nepalprabin/whisper-webapp.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '577396001', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/whisper-webapp', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '577396001',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/whisper-webapp', 'turbo-body-classes': 'logged-out\n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2, 'relevance_score': 0.24178938567638397}, \n",
       "'https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html': {'title': 'Text Summarization NLP – \n",
       "Prabin Nepal', 'text': 'Text Summarization NLP – Prabin Nepal\\nWhat is text summarization?\\nText summarization is \n",
       "one of the Natural Language Processing (NLP) tasks where documents/texts are shortened automatically while holding \n",
       "the same semantic meaning. Summarization process generates short, fluent and accurate summary of the long \n",
       "documents. The main idea of text summarization is to find the subset of the most important information from the \n",
       "entire document and present it in a human readable format. Text summarization has its application in other NLP \n",
       "tasks such as Question Answering (QA), Text Classification, Text Generation and other fields.\\nTypes of \n",
       "summarization\\nBased on how the texts are extracted from the documents, the summarization process can be divided \n",
       "into two types: extractive summarization and abstractive summarization.\\nExtractive Summarization\\nExtractive \n",
       "summarization picks up the most important sentences directly from the documents and forms a coherent summary. This \n",
       "is done using a scoring function. Extractive summarization takes a sentence as an input and produces a probability \n",
       "vector as the output. This probability vector represents the probability of a sentence being included in the \n",
       "summary.\\nImplementing extractive summarization based on word frequency\\nWe can implement extractive summarization \n",
       "using word frequency in five simple steps:\\na. Creating word frequency table\\nWe count the frequency of the words \n",
       "present in the text and create a frequency table which is a dictionary to store the count. While creating the \n",
       "frequency table, we do not account for the stop words present in the text and remove those \n",
       "words.\\ndef\\nfrequency_table(text):\\n# all unique stopwords of \n",
       "english\\nstop_words\\n=\\nset\\n(stopwords.words(\\n\"english\"\\n))\\nwords\\n=\\nword_tokenize(text)\\nfreq_table\\n=\\ndict\\n\n",
       "()\\n# creating frequency table to keep the count of each \n",
       "word\\nfor\\nword\\nin\\nwords:\\nword\\n=\\nword.lower()\\nif\\nword\\nin\\nstop_words:\\ncontinue\\nif\\nword\\nin\\nfreq_table:\\\n",
       "nfreq_table[word]\\n+=\\n1\\nelse\\n:\\nfreq_table[word]\\n=\\n1\\nreturn\\nfreq_table\\nb. Tokenizing the sentences\\nHere we\n",
       "tokenize the sentences using NLTK’s sent_tokenize() method. This separates paragraphs into individual \n",
       "sentences.\\ndef\\ntokenize_sentence(text):\\nreturn\\nsent_tokenize(text)\\nc.\\xa0Scoring the sentences using term \n",
       "frequency\\nHere, we score a sentence by its words, by adding frequency of every word present in the sentence \n",
       "excluding stop words. One downside of this approach is, if the sentence is long, the value of frequency \n",
       "increases.\\ndef\\nterm_frequency_score(sentence, freq_table):\\n# dictionary to keep the \n",
       "score\\nsentence_value\\n=\\ndict\\n()\\nfor\\nsentence\\nin\\nsentences:\\nfor\\nword, \n",
       "freq\\nin\\nfreq_table.items():\\nif\\nword\\nin\\nsentence.lower():\\nif\\nsentence\\nin\\nsentence_value:\\nsentence_value[s\n",
       "entence]\\n+=\\nfreq\\nelse\\n:\\nsentence_value[sentence]\\n=\\nfreq\\nreturn\\nsentence_value\\nd.\\xa0Finding the threshold\n",
       "score\\nAfter calculating the term frequency, we calculate the threshold \n",
       "score.\\ndef\\ncalculate_average_score(sentence_value):\\n# To compare the sentences within the text, we assign a \n",
       "score.\\nsum_values\\n=\\n0\\nfor\\nsentence\\nin\\nsentence_value:\\nsum_values\\n+=\\nsentence_value[sentence]\\n# \n",
       "Calculating average score of the sentence. This average score can be a good \n",
       "threshold.\\naverage\\n=\\nint\\n(sum_values\\n/\\nlen\\n(sentence_value))\\nreturn\\naverage\\ne. Generating the summary \n",
       "based on the threshold value\\nBased on the threshold value, we generate the summary of the \n",
       "text.\\ndef\\ncreate_summary(sentences, sentence_value, threshold):\\n# Applying the threshold value and storing \n",
       "sentences in an order into the \n",
       "summary.\\nsummary\\n=\\n\\'\\'\\nfor\\nsentence\\nin\\nsentences:\\nif\\n(sentence\\nin\\nsentence_value)\\nand\\n(sentence_value\n",
       "[sentence]\\n&gt;\\n(\\n1.2\\n*\\nthreshold)):\\nsummary\\n+=\\n\" \"\\n+\\nsentence\\nreturn\\nsummary\\nAbstractive \n",
       "Summarization\\nIn abstractive summarization, the model forms its own phrases and sentences to provide a consistent \n",
       "summary. Abstractive summarization does not simply copy the sentences to form the summary but create new phrases \n",
       "that are relevant to the original document. This summarization technique uses deep learning techniques (like \n",
       "seq2seq) to paraphrase and shorten the original document.\\nAbstractive Summarization using \n",
       "Transformers\\nTransformers is an architecture which uses attention mechanisms to solve sequence to sequence \n",
       "problems while solving long term dependencies. Ever since it was introduced in 2017, transformers have been widely \n",
       "used in various NLP tasks such as text generation, question answering, text classification, language translation \n",
       "and so on. The transformer architecture consists of encoder and decoder parts. The encoder component consists of 6 \n",
       "encoders each of which consists of two sub layers: self-attention and feed forward networks. The input text is \n",
       "first converted into vectors using text embedding methods. Then the vector is passed into the self attention layer \n",
       "and the output from the self attention layer is passed through the feed forward network. The decoder also consists \n",
       "of both self attention and feed forward network layer. An additional layer is present in between these components \n",
       "which is an attention layer that helps the decoder to focus on the relevant parts of the input sentence.\\nFig. \n",
       "Transformer architecture (from original paper)\\nHuggingface Transformers provide various pre-trained models to \n",
       "perform NLP tasks. It provides APIs and tools to download and train state-of-the-art pre-trained models. Not only \n",
       "NLP, huggingface supports Computer Vision tasks like image classification, object detection and segmentation, audio\n",
       "classification and recognition, and multimodal tasks like table question answering, optical character recognition, \n",
       "and many more.\\nBasic transformer pipeline for summarization\\nHuggingface transformers provide an easy to use model\n",
       "for inference using pipeline. These pipelines are the objects that hide complex code and provide a simple API to \n",
       "perform various \n",
       "tasks.\\nfrom\\ntransformers\\nimport\\npipeline\\nclassifier\\n=\\npipeline(\\n\"summarization\"\\n)\\ntext\\n=\\n\"\"\"Acnesol Gel\n",
       "is an antibiotic that fights bacteria. It is used to treat acne, which appears as spots or pimples on your face, \n",
       "chest or back. This medicine works by attacking the bacteria that cause these pimples.Acnesol Gel is only meant for\n",
       "external use and should be used as advised by your doctor. You should normally wash and dry the affected area \n",
       "before applying a thin layer of the medicine. It should not be applied to broken or damaged skin.  Avoid any \n",
       "contact with your eyes, nose, or mouth. Rinse it off with water if you accidentally get it in these areas. It may \n",
       "take several weeks for your symptoms to improve, but you should keep using this medicine regularly. Do not stop \n",
       "using it as soon as your acne starts to get better. Ask your doctor when you should stop treatment. Common side \n",
       "effects like minor itching, burning, or redness of the skin and oily skin may be seen in some people. These are \n",
       "usually temporary and resolve on their own. Consult your doctor if they bother you or do not go away.It is a safe \n",
       "medicine, but you should inform your doctor if you have any problems with your bowels (intestines). Also, inform \n",
       "the doctor if you have ever had bloody diarrhea caused by taking antibiotics or if you are using any other \n",
       "medicines to treat skin conditions. Consult your doctor about using this medicine if you are pregnant or \n",
       "breastfeeding.\"\"\"\\nclassifier(text)\\nResult:\\n[{\\n\\'summary_text\\'\\n:\\n\\' Acnesol Gel is an antibiotic that fights \n",
       "bacteria that causes pimples . It is used to treat acne, which appears as spots or pimples on your face, chest or \n",
       "back . The medicine is only meant for external use and should be used as advised by your doctor \n",
       ".\\'\\n}]\\nThe\\npipeline()\\ntakes the name of the task to be performed (if we want to perform a question-answering \n",
       "task, then we can simply pass “question-answering” into the pipeline() and it automatically loads the model to \n",
       "perform the specific task.\\nFine-tuning summarization model for medical dataset\\nSummarization using abstractive \n",
       "technique is hard as compared to extractive summarization as we need to generate new text as the output. Different \n",
       "architectures like GTP, T5, BART are used to perform summarization tasks. We will be using the PubMed dataset. It \n",
       "contains datasets of long and structured documents obtained from PubMed OpenAccess repositories. from datasets \n",
       "import load_dataset\\npubmed\\n=\\nload_dataset(\\n\"ccdv/pubmed-summarization\"\\n)\\nThe PubMed dataset contains article,\n",
       "abstract and section_names as columns. The first step after loading the dataset is tokenizing the training data. \n",
       "Tokenization is the process of splitting paragraphs, sentences into smaller units called tokens. tokenizer = \n",
       "AutoTokenizer.from_pretrained(‘facebook/bart-large-cnn’)\\nThe next step is to preprocess the data. Before training \n",
       "the data, we need to convert our data into expected model input \n",
       "format.\\ndef\\npreprocess_function(examples):\\ninputs\\n=\\n[doc\\nfor\\ndoc\\nin\\nexamples[\\n\"article\"\\n]]\\nmodel_inputs\n",
       "\\n=\\ntokenizer(inputs, max_length\\n=\\n1024\\n, \n",
       "truncation\\n=\\nTrue\\n)\\nlabels\\n=\\ntokenizer(examples[\\n\"abstract\"\\n], max_length\\n=\\n128\\n, truncation\\n=\\nTrue\\n,\n",
       "padding\\n=\\nTrue\\n)\\nmodel_inputs[\\n\"labels\"\\n]\\n=\\nlabels[\\n\"input_ids\"\\n]\\nreturn\\nmodel_inputs\\nWe need to apply\n",
       "the processing function over the entire dataset. Setting flag\\nbatched=True\\nhelps to speed up the processing of \n",
       "multiple elements of the dataset at once.\\ntokenized_pubmed\\n=\\npubmed.\\nmap\\n(preprocess_function, \n",
       "batched\\n=\\nTrue\\n)\\nNext, we need to create a batch for all the examples. Huggingface provides a data collator to \n",
       "create a batch for the \n",
       "examples.\\ntokenized_datasets\\n=\\ntokenized_pubmed.remove_columns(pubmed[\\n\"train\"\\n].column_names)\\ndata_collator\\\n",
       "n=\\nDataCollatorForSeq2Seq(tokenizer\\n=\\ntokenizer, model\\n=\\n\"facebook/bart-large-cnn\"\\n)\\nHuggingface provides \n",
       "various pre-trained models that we can leverage to perform a variety of machine learning \n",
       "tasks.\\nmodel\\n=\\nAutoModelForSeq2SeqLM.from_pretrained(model)\\nBefore training the model, we need to define our \n",
       "training hyperparamaters using training arguments. Since text summarization is a sequence to sequence tasks, we are\n",
       "using Seq2SeqTrainingArguments. And, we need to define our trainer by passing training and test dataset along with \n",
       "training arguments.\\n# training \n",
       "arguments\\ntraining_arguments\\n=\\nSeq2SeqTrainingArguments(\\noutput_dir\\n=\\n\\'./results\\'\\n,\\nevaluation_strategy\\n\n",
       "=\\n\\'epoch\\'\\n,\\nlearning_rate\\n=\\n2e-5\\n,\\nper_device_train_batch_size\\n=\\n8\\n,\\nper_device_eval_batch_size\\n=\\n8\\\n",
       "n,\\nweight_decay\\n=\\n0.01\\n,\\nsave_total_limit\\n=\\n3\\n,\\nnum_train_epochs\\n=\\n3\\n,\\n# \n",
       "remove_unused_columns=False,\\n# \n",
       "fp16=True,\\n)\\ntrainer\\n=\\nSeq2SeqTrainer(\\nmodel\\n=\\nmodel,\\nargs\\n=\\ntraining_arguments,\\ntrain_dataset\\n=\\ntoken\n",
       "ized_pubmed[\\n\\'train\\'\\n],\\neval_dataset\\n=\\ntokenized_pubmed[\\n\\'validation\\'\\n],\\ntokenizer\\n=\\ntokenizer,\\ndata\n",
       "_collator\\n=\\ndata_collator\\n)\\nThe last step is to call\\ntrain()\\nto fine-tune our \n",
       "model.\\ntrainer.train()\\nConclusion\\nSummarization helps to generalize the long documents by paraphrasing the \n",
       "important sentences from the whole document. It is very helpful in various applications like summarizing legal \n",
       "contracts, medical documents, news information and many more.', 'metadata': {'generator': 'quarto-1.6.42', \n",
       "'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', 'dcterms.date': '2022-10-19', \n",
       "'quarto:offset': '../'}, 'depth': 1, 'relevance_score': 0.23108184337615967}, \n",
       "'https://github.com/nepalprabin/deeplearning-paper-implementation': {'title': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation', 'text': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\ndeeplearning-paper-implementation\\nPublic\\nNotifications\\nYou must be signed in to change \n",
       "notification settings\\nFork\\n1\\nStar\\n3\\n3\\nstars\\n1\\nfork\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must\n",
       "be signed in to change notification \n",
       "settings\\nnepalprabin/deeplearning-paper-implementation\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n13 \n",
       "Commits\\nAlexNet\\nAlexNet\\nGoogLeNet\\nGoogLeNet\\nR-CNN\\nR-CNN\\nStyleTransfer\\nStyleTransfer\\nU-Net\\nU-Net\\nVGGNet\\n\n",
       "VGGNet\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\ndeeplearning-architecture\\nI am trying \n",
       "to keep record of research papers that I have read or trying to read so far.\\nResearch Papers\\nLink\\nImageNet \n",
       "Classification with Deep Convolutional Neural Networks \n",
       "(AlexNet)\\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\\nV\n",
       "ery Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)\\nhttps://arxiv.org/pdf/1409.1556.pdf\\nGoing Deeper with Convolutions \n",
       "(GoogLeNet)\\nhttps://arxiv.org/abs/1409.4842\\nRich feature hierarchies for accurate object detection and semantic \n",
       "segmentation (R-CNN)\\nhttps://arxiv.org/abs/1311.2524\\nU-Net: Convolutional Networks for Biomedical Image \n",
       "Segmentation\\nhttps://arxiv.org/abs/1505.04597\\nA Neural Algorithm of Artistic \n",
       "Style\\nhttps://arxiv.org/abs/1508.06576\\nGenerative Adversarial \n",
       "Networks\\nhttps://arxiv.org/abs/1406.2661\\nConditional Generative Adversarial \n",
       "Nets\\nhttps://arxiv.org/abs/1411.1784\\nUnsupervised Representation Learning with Deep Convolutional Generative \n",
       "Adversarial Networks (DCGAN)\\nhttps://arxiv.org/abs/1511.06434\\nImage-to-Image Translation with Conditional \n",
       "Adversarial Networks (pix2pix)\\nhttps://arxiv.org/abs/1611.07004\\nUnpaired Image-to-Image Translation using \n",
       "Cycle-Consistent Adversarial Networks (CycleGAN)\\nhttps://arxiv.org/abs/1703.10593\\nMobileNets: Efficient \n",
       "Convolutional Neural Networks for Mobile Vision Applications\\nhttps://arxiv.org/abs/1704.04861\\nAbout\\nNo \n",
       "description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n3\\nstars\\nWatchers\\n2\\nwatching\\nForks\\n1\\nfork\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8861:E962E:4963E9:62AD24:67C8D641', 'html-safe-nonce': \n",
       "'fa28ef0c6b8e54602c65b7c94eda697096b167245b463addfeac76a55a0b8a8f', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYxOkU5NjJFOjQ5NjNFOTo2MkFEMjQ6NjdDOEQ2NDEiLCJ2aXNpdG9yX2lkIjoiMjkyNzYzMD\n",
       "cyNjM4NjQ3MjUxMyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'06349d64488eaba132857900847a3799ab3e3f32e13f4f60145e227afed47ce4', 'hovercard-subject-tag': \n",
       "'repository:258506110', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/deeplearning-paper-implementation', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/d61eb70bb4254782d7a0f8845a227f0e3d5e12fd0c4d55302ba65e77920654d9/nepalprabin/de\n",
       "eplearning-paper-implementation', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', \n",
       "'twitter:title': 'GitHub - nepalprabin/deeplearning-paper-implementation', 'twitter:description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'hostname': \n",
       "'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/deeplearning-paper-implementation git \n",
       "https://github.com/nepalprabin/deeplearning-paper-implementation.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '258506110', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/deeplearning-paper-implementation', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '258506110', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/deeplearning-paper-implementation', 'turbo-body-classes': 'logged-out env-production page-responsive',\n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.2060489058494568}, \n",
       "'https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax': {'title': \n",
       "'Understanding GitHub Code Search syntax - GitHub Docs', 'text': 'Understanding GitHub Code Search syntax - GitHub \n",
       "Docs\\nSkip to main content\\nUnderstanding GitHub Code Search syntax\\nYou can build search queries for the results \n",
       "you want with specialized code qualifiers, regular expressions, and boolean operations.\\nIn this article\\nAbout \n",
       "code search query structure\\nThe search syntax in this article only applies to searching code with GitHub code \n",
       "search. Note that the syntax and qualifiers for searching for non-code content, such as issues, users, and \n",
       "discussions, is not the same as the syntax for code search. For more information on non-code search, see\\nAbout \n",
       "searching on GitHub\\nand\\nSearching on GitHub\\n.\\nSearch queries consist of search terms, comprising text you want \n",
       "to search for, and qualifiers, which narrow down the search.\\nA bare term with no qualifiers will match either the \n",
       "content of a file or the file\\'s path.\\nFor example, the following query:\\nhttp-push\\nThe above query will match \n",
       "the file\\ndocs/http-push.txt\\n, even if it doesn\\'t contain the term\\nhttp-push\\n. It will also match a file \n",
       "called\\nexample.txt\\nif it contains the term\\nhttp-push\\n.\\nYou can enter multiple terms separated by whitespace to\n",
       "search for documents that satisfy both terms.\\nFor example, the following query:\\nsparse index\\nThe search results \n",
       "would include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order. As examples, it would \n",
       "match a file containing\\nSparseIndexVector\\n, a file with the phrase\\nindex for sparse trees\\n, and even a file \n",
       "named\\nindex.txt\\nthat contains the term\\nsparse\\n.\\nSearching for multiple terms separated by whitespace is the \n",
       "equivalent to the search\\nhello AND world\\n. Other boolean operations, such as\\nhello OR world\\n, are also \n",
       "supported. For more information about boolean operations, see\\nUsing boolean operations\\n.\\nCode search also \n",
       "supports searching for an exact string, including whitespace. For more information, see\\nQuery for an exact \n",
       "match\\n.\\nYou can narrow your code search with specialized qualifiers, such as\\nrepo:\\n,\\nlanguage:\\nand\\npath:\\n. \n",
       "For more information on the qualifiers you can use in code search, see\\nUsing qualifiers\\n.\\nYou can also use \n",
       "regular expressions in your searches by surrounding the expression in slashes. For more information on using \n",
       "regular expressions, see\\nUsing regular expressions\\n.\\nQuery for an exact match\\nTo search for an exact string, \n",
       "including whitespace, you can surround the string in quotes. For example:\\n\"sparse index\"\\nYou can also use quoted \n",
       "strings in qualifiers, for example:\\npath:git language:\"protocol buffers\"\\nSearching for quotes and backslashes\\nTo\n",
       "search for code containing a quotation mark, you can escape the quotation mark using a backslash. For example, to \n",
       "find the exact string\\nname = \"tensorflow\"\\n, you can search:\\n\"name = \\\\\"tensorflow\\\\\"\"\\nTo search for code \n",
       "containing a backslash,\\n\\\\\\n, use a double backslash,\\n\\\\\\\\\\n.\\nThe two escape sequences\\n\\\\\\\\\\nand\\n\\\\\"\\ncan be \n",
       "used outside of quotes as well. No other escape sequences are recognized, though. A backslash that isn\\'t followed \n",
       "by either\\n\"\\nor\\n\\\\\\nis included in the search, unchanged.\\nAdditional escape sequences, such as\\n\\\\n\\nto match a \n",
       "newline character, are supported in regular expressions. See\\nUsing regular expressions\\n.\\nUsing boolean \n",
       "operations\\nCode search supports boolean expressions. You can use the operators\\nAND\\n,\\nOR\\n, and\\nNOT\\nto combine\n",
       "search terms.\\nBy default, adjacent terms separated by whitespace are equivalent to using the\\nAND\\noperator. For \n",
       "example, the search query\\nsparse index\\nis the same as\\nsparse AND index\\n, meaning that the search results will \n",
       "include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order.\\nTo search for documents \n",
       "containing either one term or the other, you can use the\\nOR\\noperator. For example, the following query will match\n",
       "d\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       " organization. Monitor access, permission changes, user changes, and other events.\\nLearn more\\nRepository \n",
       "rules\\nEnhance your organization's security with scalable source code protections, and use rule insights to easily \n",
       "review how and why code changes occurred in your repositories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise \n",
       "accounts\\nEnable collaboration between your organization and GitHub environments with a single point of visibility \n",
       "and management via an enterprise account.\\nLearn more\\nRequires GitHub Enterprise\\nGitHub Connect\\nShare features \n",
       "and workflows between your GitHub Enterprise Server instance and GitHub Enterprise Cloud.\\nLearn more\\nRequires \n",
       "GitHub Enterprise\\nSAML\\nSecurely control access to organization resources like repositories, issues, and pull \n",
       "requests with SAML, while allowing users to authenticate with their GitHub usernames.\\nLearn more\\nRequires GitHub \n",
       "Enterprise\\nLDAP\\nCentralize repository management. LDAP is one of the most common protocols used to integrate \n",
       "third-party software with large company user directories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise \n",
       "Managed Users\\nManage the lifecycle and authentication of users on GitHub Enterprise Cloud from your identity \n",
       "provider (IdP).\\nLearn more\\nRequires GitHub Enterprise\\nBring your own identity provider for Enterprise Managed \n",
       "Users\\nUse the SSO and SCIM providers of your choice for Enterprise Managed Users, separate from one another, for a\n",
       "more flexible approach to user lifecycle management.\\nLearn more\\nGitHub Sponsors\\nFinancially support the open \n",
       "source projects your code depends on. Sponsor a contributor, maintainer, or project with one time or recurring \n",
       "contributions.\\nLearn more\\nGitHub Skills\\nLearn new skills by completing tasks and projects directly within \n",
       "GitHub, guided by our friendly bot.\\nLearn more\\nElectron\\nWrite cross-platform desktop applications using \n",
       "JavaScript, HTML, and CSS with the Electron framework, based on Node.js and Chromium.\\nLearn \n",
       "more\\nEducation\\nGitHub Education is a commitment to bringing tech and open source collaboration to students and \n",
       "educators across the globe.\\nLearn more\\nReady to get started?\\nExplore all the plans to find the solution that \n",
       "fits your needs.\\nView pricing plans\\nYou can’t perform that action at this time.\", 'metadata': {'route-pattern': \n",
       "'/features(.:format)', 'route-controller': 'site_features', 'route-action': 'index', \n",
       "'current-catalog-service-hash': '79cf51f992068789f17556b35146105313c98e5893e538d4903986cbf7e2509a', 'request-id': \n",
       "'8831:2297B9:415D13:5722F9:67C8D60C', 'html-safe-nonce': \n",
       "'c11b035633246196fa625cd4002ab734c4d477bd0afe5db947fb9ce3fa58b52a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODMxOjIyOTdCOTo0MTVEMTM6NTcyMkY5OjY3QzhENjBDIiwidmlzaXRvcl9pZCI6IjkxNDU3OD\n",
       "A4ODE3MDgzNDA3NDgiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'245b9f475903edc1d07278b47cc9a3b2e97b7adb56ecd6b5d65188ae69d51324', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/features', \n",
       "'twitter:image': 'https://github.githubassets.com/assets/features-launchpad-6c57787ff41d.png', 'twitter:site': \n",
       "'@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub Features', 'twitter:description': 'Get \n",
       "the right tools for the job. Automate your CI/CD and DevOps workflow with GitHub Actions, build securely, manage \n",
       "teams and projects, and review code in one place.', 'hostname': 'github.com', 'expected-hostname': 'github.com', \n",
       "'turbo-cache-control': 'no-cache', 'is_logged_out_page': 'true', 'octolytics-page-type': 'marketing', \n",
       "'turbo-body-classes': 'logged-out env-production page-responsive header-overlay', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.11251894384622574}, 'https://nepalprabin.github.io/posts/2023-05-15-gpt4-summary.html': \n",
       "{'title': 'Brief overview of GPT-4 – Prabin Nepal', 'text': 'Brief overview of GPT-4 – Prabin Nepal\\nSince the \n",
       "release of ChatGPT, there has been significant interest and discussion within the broader AI and natural language \n",
       "processing communities regarding its capabilities. In addition to this, ChatGPT has captured the attention of the \n",
       "internet at large due to its remarkable ability to generate fluent and natural-sounding responses across a wide \n",
       "range of prompts and language tasks. Due to this, it became fastest growing consumer application in the history, \n",
       "just two months after the launch. ChatGPT is fine-tuned from a model in the GPT-3.5 series and can write articles, \n",
       "jokes, poetrys in response to the prompt. Though powerful, there have also been concerns raised about the potential\n",
       "risks associated with it and other large language models (LLMs), particularly with respect to issues such as bias, \n",
       "and misinformation. One of the major concern for LLMs is that it suffers from\\nhallucination\\n.\\nHallucination \n",
       "refers to the phenomenon where the model generates responses that are not supported by the input or are \n",
       "inconsistent with reality. This can happen when the model generates text that appears to be coherent and relevant, \n",
       "but is not grounded in any factual or contextual information.\\nA year after releasing ChatGPT, OpenAI released \n",
       "GPT-4 (on 14th March, an improved version of GPT-3.5 model that supports multimodal data. It is capable of \n",
       "processing text and image data to generate textual data. It achieved human level performance on various \n",
       "professional and academic benchmarks. On a simulated bar exam, GPT-4 achieved a score that falls on the top 10% of \n",
       "the exam takes. In contrast, the score achieved by previous model GPT-3.5 fell on bottom 10%. This shows the level \n",
       "of improvement achieved by the latest version of GPT. It is also important to mention that the model was not \n",
       "specifically trained on these exams. A minority of problems were seen by model while training.\\nCapabilities of \n",
       "GPT-4\\nThough the report does not provide any details about architecture (including model size), hardware, training\n",
       "compute, dataset construction, or training method, a demo run by\\nGreg Brockman\\n(President and Co-founder, OpenAI)\n",
       "after the release of GPT-4 shows various capabilities of the model.\\nYou can watch the GPT-4 Developer Livestream \n",
       "replay here:\\n1. Supports longer context\\nGPT-4 is capable of handling over 25,000 words of text, that enables its \n",
       "usage in situations that require the creation of lengthy content, extended dialogues, or the exploration and \n",
       "analysis of extensive documents.\\n2. Hand-drawn pencil drawing turned into a fully functional website\\nGPT-4 is \n",
       "also capable of handling visual input, such as hand-drawn pencil drawings that looks like a mock design, and \n",
       "generating code to create a website. The generated output is mind blowing. Another important aspect is the accuracy\n",
       "by which the model is able to perform OCR task with such messy handwritings.\\nFig. Left is the mock design and \n",
       "right is the website created using the code generated from gpt4-model.\\nsource\\n3. GPT-4 can describe the \n",
       "image.\\nAs opposed to text on prompts (on previous GPT version), this model accepts inputs containing both text and\n",
       "images. It lets user specify any language or vision tasks. GPT-4 displays comparable skills on various types of \n",
       "content, such as documents containing both textual and visual elements like photographs, diagrams, or screenshots, \n",
       "as it does when dealing with text-only inputs.\\nExample prompt demonstrating GPT-4’s visual input capability. The \n",
       "prompt consists of a question about an image with multiple panels which GPT-4 is able to answer.\\nsource\\n4. Human \n",
       "level performance on professional and academic benchmarks\\nGPT outperforms the previous state-of-the-art models on \n",
       "various standardized exams, such as GRE, SAT, BAR, and APs, along with other research benchmarks like MMLU, \n",
       "HellaSWAG, and TextQA. GPT-4 outperforms the English language performance of GPT 3.5 and existing language models \n",
       "(\\nChinchilla\\nand\\nPaLM\\n), including low-resource languages such as Latvian, Welsh, and Swahili.\\nLimitations of \n",
       "GPT-4\\nThough there has been a tremendous improvement as compared to previous models, GPT-4 has similar limitations\n",
       "as earlier GPT models. It is not fully reliable and hallucinates.\\nSince GPT-4 is trained on the data available \n",
       "till September 2021, it lacks knowledge of the events occured after that time period.\\nRisks and mitigations\\nThe \n",
       "prompts entered by the users are not always safe. When providing unsafe inputs to the model, it may generate \n",
       "undesirable text like commiting crimes. To mitigate these risks, various approaches like Adversarial Testing, Model\n",
       "Assisted Safety Pipeline are carried out. Using domain experts and their findings, model is improved to refuse \n",
       "request for unsafe inputs like synthesizing dangerous chemicals.\\nExamples of how unsafe inputs are refused by the \n",
       "model\\nConclusion\\nThe recent advancements in GPT-4, have proven to outperform existing language models in a \n",
       "collection of NLP tasks. The improved capabilities of GPT-4 are not limited to the English language, as predictable\n",
       "scaling allows for accurate predictions in many different languages. However, the increased capabilities of GPT-4 \n",
       "also present new risks, which require significant work to understand and improve its safety and alignment. \n",
       "Nevertheless, GPT-4 marks a significant milestone towards the development of broadly useful and safely deployed AI \n",
       "systems.\\nReferences:\\nGPT-4 Technical Report\\nGPT-4 Blog Post\\nchat.openai.com\\nPS\\nWhile GPT-4 may have stolen \n",
       "the headlines, it was not the only new technology on display. AnthropicAI unveiled\\nClaude\\n, next gen AI assistant\n",
       "can help with use cases including summarization, search, creative and collaborative writing, Q&amp;A, coding, and more.\n",
       "Meanwhile, Google AI released\\nPaLM\\n, an entry point for Google’s large language models with variety of \n",
       "applications. With these three new systems, the future of AI looks brighter than ever before.', 'metadata': \n",
       "{'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', \n",
       "'dcterms.date': '2023-03-15', 'quarto:offset': '../'}, 'depth': 1, 'relevance_score': 0.11177341639995575}, \n",
       "'https://github.com/collections': {'title': 'Collections · GitHub', 'text': \"Collections · GitHub\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nCollections\\nCurated lists and insight into burgeoning industries, topics, and \n",
       "communities.\\n#\\nGame Engines\\nFrameworks for building games across multiple platforms.\\nLearn to Code\\nResources \n",
       "to help people learn to code\\nPixel Art Tools\\nCreating pixel art for fun or animated sprites for a game? The \n",
       "digital artist in you will love these apps and tools!\\n#\\nHow to choose (and contribute to) your first open source \n",
       "project\\nNew to open source? Here’s how to find projects that need help and start making impactful \n",
       "contributions.\\n#\\nClean code linters\\nMake sure your code matches your style guide with these essential code \n",
       "linters.\\n#\\nOpen journalism\\nSee how publications and data-driven journalists use open source to power their \n",
       "newsroom and ensure information is reported fairly and accurately.\\n#\\nDesign essentials\\nThis collection of design\n",
       "libraries are the best on the web, and will complete your toolset for designing stunning products.\\n#\\nMusic\\nDrop \n",
       "the code bass with these musically themed repositories.\\nGovernment apps\\nSites, apps, and tools built by \n",
       "governments across the world to make government work better, together. Read more at \n",
       "https://government.github.com\\n#\\nDevOps tools\\nThese tools help you manage servers and deploy happier and more \n",
       "often with more confidence.\\n#\\nFront-end JavaScript frameworks\\nWhile the number of ways to organize JavaScript is\n",
       "almost infinite, here are some tools that help you build single-page applications.\\n#\\nGitHub Browser \n",
       "Extensions\\nSome useful and fun browser extensions to personalize your GitHub browser experience.\\nGitHub Pages \n",
       "examples\\nFine examples of projects using GitHub Pages (https://pages.github.com).\\nHacking Minecraft\\nMinecraft is\n",
       "a game about building blocks, but it doesn’t end there. Take Minecraft further with some of the projects below, or \n",
       "dive into the code mines and hammer your own!\\n#\\nJavaScript Game Engines\\nLearn or level up your 1337 gamedev \n",
       "skills and build amazing games together for web, desktop, or mobile using these HTML5 / JavaScript game \n",
       "engines.\\nLearn to Code\\nResources to help people learn to code\\n#\\nGetting started with machine learning\\nToday, \n",
       "machine learning—the study of algorithms that make data-based predictions—has found a new audience and a new set of\n",
       "possibilities.\\nMade in Africa\\nDevelopers in Africa use open source technology to solve some of the world's most \n",
       "intractable problems and grow their business ecosystems. Here's a snapshot of local projects across the \n",
       "continent.\\nNet neutrality\\nSoftware, research, and organizations protecting the free and open internet.\\n#\\nOpen \n",
       "data\\nExamples of using GitHub to store, publish, and collaborate on open, machine-readable datasets\\nOpen source \n",
       "organizations\\nA showcase of organizations showcasing their open source projects.\\n#\\nPolicies\\nFrom federal \n",
       "governments to corporations to student clubs, groups of all sizes are using GitHub to share, discuss, and improve \n",
       "laws. *Ask not what the repository can do for you...*\\n#\\nSoftware productivity tools\\nBuild software faster with \n",
       "fewer headaches, using these tools and tricks.\\nLoad more…\\nYou can’t perform that action at this time.\", \n",
       "'metadata': {'route-pattern': '/collections(.:format)', 'route-controller': 'collections', 'route-action': 'index',\n",
       "'current-catalog-service-hash': '68905b05f2811955010ef44286a1edf6dad580d793d21bb719e7abcf48e7a0ae', 'request-id': \n",
       "'884C:1F90E5:457F11:5CDB64:67C8D626', 'html-safe-nonce': \n",
       "'6dec25dad345f21777f56f8108fb1fb97a169fa8ef8dc8450daf90735512020a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODRDOjFGOTBFNTo0NTdGMTE6NUNEQjY0OjY3QzhENjI2IiwidmlzaXRvcl9pZCI6IjU0MDYwMT\n",
       "g2NTIyMzgwNDI2NjMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'c7f2ee3f43777769145e652af2e60e77d1b3bac35e5b2a2c6765960ab1eba326', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/collections', \n",
       "'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.10756564885377884}, 'https://github.com/features/code-review': {'title': 'GitHub Code \n",
       "Review · GitHub', 'text': 'GitHub Code Review · GitHub\\nSkip to content\\nGitHub Copilot is now available for \n",
       "free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCode Review\\nWrite better code\\nOn GitHub, lightweight \n",
       "code review tools are built into every pull request. Your team can create review processes that improve the quality\n",
       "of your code and fit neatly into your workflow.\\nGet started\\nContact sales\\nEvery change starts with a pull \n",
       "request.\\nLearn pull request fundamentals\\nStart a new feature or propose a change to existing code with a pull \n",
       "request\\n—a base for your team to coordinate details and refine your changes.\\nPull requests are fundamental to how\n",
       "teams review and improve code on GitHub\\n. Evolve projects, propose new features, and discuss implementation \n",
       "details before changing your source code.\\nDiffs\\nPreview changes in context with your code to see what is being \n",
       "proposed. Side-by-side Diffs highlight added, edited, and deleted code right next to the original file, so you can \n",
       "easily spot changes.\\nLearn more\\nHistory\\nBrowse commits, comments, and references related to your pull request in\n",
       "a timeline-style interface. Your pull request will also highlight what’s changed since you last checked.\\nLearn \n",
       "more\\nBlame\\nSee what a file looked like before a particular change. With blame view, you can see how any portion \n",
       "of your file has evolved over time without viewing the file’s full history.\\nLearn more\\nComments\\nOn GitHub, \n",
       "conversations happen alongside your code. Leave detailed comments on code syntax and ask questions about structure \n",
       "inline.\\nReview requests\\nIf you’re on the other side of the code, requesting peer reviews is easy. Add users to \n",
       "your pull request, and they’ll receive a notification letting them know you need their feedback.\\nReviews\\nSave \n",
       "your teammates a few notifications. Bundle your comments into one cohesive review, then specify whether comments \n",
       "are required changes or just suggestions.\\nResolve simple conflicts\\nYou can’t always avoid conflict. Merge pull \n",
       "requests faster by resolving simple merge conflicts on GitHub—no command line necessary.\\nLearn how to resolve \n",
       "merge conflicts\\nFast, relevant results\\nGive collaborators as much access as they need through your repository \n",
       "settings. You can extend access to a few teams and select which ones can read or write to your files. The options \n",
       "you have for permissions depend on your plan.\\nSee plan options\\nProtected branches\\nProtected Branches help you \n",
       "maintain the integrity of your code. Limit who can push to a branch, and disable force pushes to specific branches.\n",
       "Then scale your policies with the Protected Branches API.\\nLearn more\\nRequired status checks\\nCreate required \n",
       "status checks to add an extra layer of error prevention on branches. Use the Status API to enforce checks and \n",
       "disable the merge button until they pass. To err is human; to automate, divine!\\nStatus API doc\\nEvery change \n",
       "starts with a pull request.\\nGet started\\nContact sales\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/features/code-review(.:format)', 'route-controller': 'site_features_code_review', \n",
       "'route-action': 'index', 'current-catalog-service-hash': \n",
       "'79cf51f992068789f17556b35146105313c98e5893e538d4903986cbf7e2509a', 'request-id': \n",
       "'882E:366203:4623C7:5E4068:67C8D60A', 'html-safe-nonce': \n",
       "'5e1fd3cb165203bc3f236d66b1c7db1d9ddd07d91501b71cbabd02f9abdb3ae1', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODJFOjM2NjIwMzo0NjIzQzc6NUU0MDY4OjY3QzhENjBBIiwidmlzaXRvcl9pZCI6IjY0NDgzOD\n",
       "A5ODk5MDY5MzMyNTgiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'4d72ea962ca9e838546ea8cc4820c762485b5937011b853cee3f60be92abf9f7', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/features/code-review', \n",
       "'twitter:image': 'https://github.githubassets.com/assets/features-4761c659150b.png', 'twitter:site': '@github', \n",
       "'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub Code Review', 'twitter:description': 'Make code \n",
       "review seamless with GitHub. Request reviews, propose changes, keep track of versions, and protect branches on the \n",
       "path to better code with your team.', 'hostname': 'github.com', 'expected-hostname': 'github.com', \n",
       "'turbo-cache-control': 'no-cache', 'is_logged_out_page': 'true', 'octolytics-page-type': 'marketing', \n",
       "'octolytics-revenue-play': 'Platform', 'turbo-body-classes': 'logged-out env-production page-responsive \n",
       "header-dark', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.10641869902610779}, 'https://github.com/nepalprabin/nepalprabin': {'title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'text': \"GitHub - nepalprabin/nepalprabin\\nSkip to content\\nYou signed in with another \n",
       "tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your\n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\nnepalprabin\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/nepalprabin\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n14 \n",
       "Commits\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\nHi 👋, I'm Prabin Nepal\\nA passionate \n",
       "software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull \n",
       "Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nAbout\\nNo description, website, or\n",
       "topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nYou can’t perform that action at \n",
       "this time.\", 'metadata': {'route-pattern': '/:user_id/:repository', 'route-controller': 'files', 'route-action': \n",
       "'disambiguate', 'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb',\n",
       "'request-id': '885D:148B86:468AB6:5EA3B6:67C8D639', 'html-safe-nonce': \n",
       "'2e85c74115beb5e1e134f0c55ba7d98d8191a15ecc34599c10cf561436845743', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVEOjE0OEI4Njo0NjhBQjY6NUVBM0I2OjY3QzhENjM5IiwidmlzaXRvcl9pZCI6IjczODY4MD\n",
       "cyMDIwNzE3NjI0ODkiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'44b6648ccdfe752ed85305ebb06add2ba0881ec0366c36e35d31bdf78566a2aa', 'hovercard-subject-tag': \n",
       "'repository:278281752', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/&lt;user-name&gt;/&lt;repo-name&gt;', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/nepalprabin development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/nepalprabin', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/938931e393aefe0802f7134e6271f2c2d66d2eacd02f8ab7f9f16dfbc37c3816/nepalprabin/ne\n",
       "palprabin', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'twitter:description': 'Contribute to nepalprabin/nepalprabin development by creating an \n",
       "account on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': \n",
       "'no-preview', 'go-import': 'github.com/nepalprabin/nepalprabin git https://github.com/nepalprabin/nepalprabin.git',\n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '278281752', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/nepalprabin', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '278281752',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/nepalprabin', 'turbo-body-classes': 'logged-out \n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2, 'relevance_score': 0.10383956879377365}}\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "{'https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip': {'title': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub', 'text': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nnepalprabin\\n/\\nwhisper-webapp\\nPublic\\nNotifications\\nYou must be signed in to \n",
       "change notification settings\\nFork\\n0\\nStar\\n0\\nFiles\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nCopy \n",
       "path\\nLatest commit\\nHistory\\nHistory\\n1.99 MB\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nTop\\nFile metadata \n",
       "and controls\\nCode\\nBlame\\n1.99 MB\\nRaw\\nView raw\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/:user_id/:repository/blob/*name(/*path)', 'route-controller': 'blob', 'route-action': 'show', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8825:212693:4639CC:5DE385:67C8D5FF', 'html-safe-nonce': \n",
       "'a73a88e30ba87696ba2c0f96fe9d20f3fefb8c4d427df35f678c3a170f3204da', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODI1OjIxMjY5Mzo0NjM5Q0M6NURFMzg1OjY3QzhENUZGIiwidmlzaXRvcl9pZCI6IjgyMjQ4MT\n",
       "U2MzE0NTIxMzI4NjMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'a3880ad0092bd286210060f48997f74d487d4ffc78c3e5bd4a2ea33b29728c50', 'hovercard-subject-tag': \n",
       "'repository:577396001', 'github-keyboard-shortcuts': 'repository,source-code,file-tree,copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'analytics-location': '/<user-name>/<repo-name>/blob/show', \n",
       "'viewport': 'width=device-width', 'description': 'Contribute to nepalprabin/whisper-webapp development by creating \n",
       "an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/484f653911c7141bb44f0082f00bf81b8485eaa351a0b07118e66484dadc85b1/nepalprabin/wh\n",
       "isper-webapp', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': \n",
       "'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp', 'twitter:description': \n",
       "'Contribute to nepalprabin/whisper-webapp development by creating an account on GitHub.', 'hostname': 'github.com',\n",
       "'expected-hostname': 'github.com', 'turbo-cache-control': 'no-cache', 'go-import': \n",
       "'github.com/nepalprabin/whisper-webapp git https://github.com/nepalprabin/whisper-webapp.git', \n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '577396001', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/whisper-webapp', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '577396001',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/whisper-webapp', 'turbo-body-classes': 'logged-out\n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2, 'relevance_score': 0.24178938567638397}, \n",
       "'https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html': {'title': 'Text Summarization NLP – \n",
       "Prabin Nepal', 'text': 'Text Summarization NLP – Prabin Nepal\\nWhat is text summarization?\\nText summarization is \n",
       "one of the Natural Language Processing (NLP) tasks where documents/texts are shortened automatically while holding \n",
       "the same semantic meaning. Summarization process generates short, fluent and accurate summary of the long \n",
       "documents. The main idea of text summarization is to find the subset of the most important information from the \n",
       "entire document and present it in a human readable format. Text summarization has its application in other NLP \n",
       "tasks such as Question Answering (QA), Text Classification, Text Generation and other fields.\\nTypes of \n",
       "summarization\\nBased on how the texts are extracted from the documents, the summarization process can be divided \n",
       "into two types: extractive summarization and abstractive summarization.\\nExtractive Summarization\\nExtractive \n",
       "summarization picks up the most important sentences directly from the documents and forms a coherent summary. This \n",
       "is done using a scoring function. Extractive summarization takes a sentence as an input and produces a probability \n",
       "vector as the output. This probability vector represents the probability of a sentence being included in the \n",
       "summary.\\nImplementing extractive summarization based on word frequency\\nWe can implement extractive summarization \n",
       "using word frequency in five simple steps:\\na. Creating word frequency table\\nWe count the frequency of the words \n",
       "present in the text and create a frequency table which is a dictionary to store the count. While creating the \n",
       "frequency table, we do not account for the stop words present in the text and remove those \n",
       "words.\\ndef\\nfrequency_table(text):\\n# all unique stopwords of \n",
       "english\\nstop_words\\n=\\nset\\n(stopwords.words(\\n\"english\"\\n))\\nwords\\n=\\nword_tokenize(text)\\nfreq_table\\n=\\ndict\\n\n",
       "()\\n# creating frequency table to keep the count of each \n",
       "word\\nfor\\nword\\nin\\nwords:\\nword\\n=\\nword.lower()\\nif\\nword\\nin\\nstop_words:\\ncontinue\\nif\\nword\\nin\\nfreq_table:\\\n",
       "nfreq_table[word]\\n+=\\n1\\nelse\\n:\\nfreq_table[word]\\n=\\n1\\nreturn\\nfreq_table\\nb. Tokenizing the sentences\\nHere we\n",
       "tokenize the sentences using NLTK’s sent_tokenize() method. This separates paragraphs into individual \n",
       "sentences.\\ndef\\ntokenize_sentence(text):\\nreturn\\nsent_tokenize(text)\\nc.\\xa0Scoring the sentences using term \n",
       "frequency\\nHere, we score a sentence by its words, by adding frequency of every word present in the sentence \n",
       "excluding stop words. One downside of this approach is, if the sentence is long, the value of frequency \n",
       "increases.\\ndef\\nterm_frequency_score(sentence, freq_table):\\n# dictionary to keep the \n",
       "score\\nsentence_value\\n=\\ndict\\n()\\nfor\\nsentence\\nin\\nsentences:\\nfor\\nword, \n",
       "freq\\nin\\nfreq_table.items():\\nif\\nword\\nin\\nsentence.lower():\\nif\\nsentence\\nin\\nsentence_value:\\nsentence_value[s\n",
       "entence]\\n+=\\nfreq\\nelse\\n:\\nsentence_value[sentence]\\n=\\nfreq\\nreturn\\nsentence_value\\nd.\\xa0Finding the threshold\n",
       "score\\nAfter calculating the term frequency, we calculate the threshold \n",
       "score.\\ndef\\ncalculate_average_score(sentence_value):\\n# To compare the sentences within the text, we assign a \n",
       "score.\\nsum_values\\n=\\n0\\nfor\\nsentence\\nin\\nsentence_value:\\nsum_values\\n+=\\nsentence_value[sentence]\\n# \n",
       "Calculating average score of the sentence. This average score can be a good \n",
       "threshold.\\naverage\\n=\\nint\\n(sum_values\\n/\\nlen\\n(sentence_value))\\nreturn\\naverage\\ne. Generating the summary \n",
       "based on the threshold value\\nBased on the threshold value, we generate the summary of the \n",
       "text.\\ndef\\ncreate_summary(sentences, sentence_value, threshold):\\n# Applying the threshold value and storing \n",
       "sentences in an order into the \n",
       "summary.\\nsummary\\n=\\n\\'\\'\\nfor\\nsentence\\nin\\nsentences:\\nif\\n(sentence\\nin\\nsentence_value)\\nand\\n(sentence_value\n",
       "[sentence]\\n>\\n(\\n1.2\\n*\\nthreshold)):\\nsummary\\n+=\\n\" \"\\n+\\nsentence\\nreturn\\nsummary\\nAbstractive \n",
       "Summarization\\nIn abstractive summarization, the model forms its own phrases and sentences to provide a consistent \n",
       "summary. Abstractive summarization does not simply copy the sentences to form the summary but create new phrases \n",
       "that are relevant to the original document. This summarization technique uses deep learning techniques (like \n",
       "seq2seq) to paraphrase and shorten the original document.\\nAbstractive Summarization using \n",
       "Transformers\\nTransformers is an architecture which uses attention mechanisms to solve sequence to sequence \n",
       "problems while solving long term dependencies. Ever since it was introduced in 2017, transformers have been widely \n",
       "used in various NLP tasks such as text generation, question answering, text classification, language translation \n",
       "and so on. The transformer architecture consists of encoder and decoder parts. The encoder component consists of 6 \n",
       "encoders each of which consists of two sub layers: self-attention and feed forward networks. The input text is \n",
       "first converted into vectors using text embedding methods. Then the vector is passed into the self attention layer \n",
       "and the output from the self attention layer is passed through the feed forward network. The decoder also consists \n",
       "of both self attention and feed forward network layer. An additional layer is present in between these components \n",
       "which is an attention layer that helps the decoder to focus on the relevant parts of the input sentence.\\nFig. \n",
       "Transformer architecture (from original paper)\\nHuggingface Transformers provide various pre-trained models to \n",
       "perform NLP tasks. It provides APIs and tools to download and train state-of-the-art pre-trained models. Not only \n",
       "NLP, huggingface supports Computer Vision tasks like image classification, object detection and segmentation, audio\n",
       "classification and recognition, and multimodal tasks like table question answering, optical character recognition, \n",
       "and many more.\\nBasic transformer pipeline for summarization\\nHuggingface transformers provide an easy to use model\n",
       "for inference using pipeline. These pipelines are the objects that hide complex code and provide a simple API to \n",
       "perform various \n",
       "tasks.\\nfrom\\ntransformers\\nimport\\npipeline\\nclassifier\\n=\\npipeline(\\n\"summarization\"\\n)\\ntext\\n=\\n\"\"\"Acnesol Gel\n",
       "is an antibiotic that fights bacteria. It is used to treat acne, which appears as spots or pimples on your face, \n",
       "chest or back. This medicine works by attacking the bacteria that cause these pimples.Acnesol Gel is only meant for\n",
       "external use and should be used as advised by your doctor. You should normally wash and dry the affected area \n",
       "before applying a thin layer of the medicine. It should not be applied to broken or damaged skin.  Avoid any \n",
       "contact with your eyes, nose, or mouth. Rinse it off with water if you accidentally get it in these areas. It may \n",
       "take several weeks for your symptoms to improve, but you should keep using this medicine regularly. Do not stop \n",
       "using it as soon as your acne starts to get better. Ask your doctor when you should stop treatment. Common side \n",
       "effects like minor itching, burning, or redness of the skin and oily skin may be seen in some people. These are \n",
       "usually temporary and resolve on their own. Consult your doctor if they bother you or do not go away.It is a safe \n",
       "medicine, but you should inform your doctor if you have any problems with your bowels (intestines). Also, inform \n",
       "the doctor if you have ever had bloody diarrhea caused by taking antibiotics or if you are using any other \n",
       "medicines to treat skin conditions. Consult your doctor about using this medicine if you are pregnant or \n",
       "breastfeeding.\"\"\"\\nclassifier(text)\\nResult:\\n[{\\n\\'summary_text\\'\\n:\\n\\' Acnesol Gel is an antibiotic that fights \n",
       "bacteria that causes pimples . It is used to treat acne, which appears as spots or pimples on your face, chest or \n",
       "back . The medicine is only meant for external use and should be used as advised by your doctor \n",
       ".\\'\\n}]\\nThe\\npipeline()\\ntakes the name of the task to be performed (if we want to perform a question-answering \n",
       "task, then we can simply pass “question-answering” into the pipeline() and it automatically loads the model to \n",
       "perform the specific task.\\nFine-tuning summarization model for medical dataset\\nSummarization using abstractive \n",
       "technique is hard as compared to extractive summarization as we need to generate new text as the output. Different \n",
       "architectures like GTP, T5, BART are used to perform summarization tasks. We will be using the PubMed dataset. It \n",
       "contains datasets of long and structured documents obtained from PubMed OpenAccess repositories. from datasets \n",
       "import load_dataset\\npubmed\\n=\\nload_dataset(\\n\"ccdv/pubmed-summarization\"\\n)\\nThe PubMed dataset contains article,\n",
       "abstract and section_names as columns. The first step after loading the dataset is tokenizing the training data. \n",
       "Tokenization is the process of splitting paragraphs, sentences into smaller units called tokens. tokenizer = \n",
       "AutoTokenizer.from_pretrained(‘facebook/bart-large-cnn’)\\nThe next step is to preprocess the data. Before training \n",
       "the data, we need to convert our data into expected model input \n",
       "format.\\ndef\\npreprocess_function(examples):\\ninputs\\n=\\n[doc\\nfor\\ndoc\\nin\\nexamples[\\n\"article\"\\n]]\\nmodel_inputs\n",
       "\\n=\\ntokenizer(inputs, max_length\\n=\\n1024\\n, \n",
       "truncation\\n=\\nTrue\\n)\\nlabels\\n=\\ntokenizer(examples[\\n\"abstract\"\\n], max_length\\n=\\n128\\n, truncation\\n=\\nTrue\\n,\n",
       "padding\\n=\\nTrue\\n)\\nmodel_inputs[\\n\"labels\"\\n]\\n=\\nlabels[\\n\"input_ids\"\\n]\\nreturn\\nmodel_inputs\\nWe need to apply\n",
       "the processing function over the entire dataset. Setting flag\\nbatched=True\\nhelps to speed up the processing of \n",
       "multiple elements of the dataset at once.\\ntokenized_pubmed\\n=\\npubmed.\\nmap\\n(preprocess_function, \n",
       "batched\\n=\\nTrue\\n)\\nNext, we need to create a batch for all the examples. Huggingface provides a data collator to \n",
       "create a batch for the \n",
       "examples.\\ntokenized_datasets\\n=\\ntokenized_pubmed.remove_columns(pubmed[\\n\"train\"\\n].column_names)\\ndata_collator\\\n",
       "n=\\nDataCollatorForSeq2Seq(tokenizer\\n=\\ntokenizer, model\\n=\\n\"facebook/bart-large-cnn\"\\n)\\nHuggingface provides \n",
       "various pre-trained models that we can leverage to perform a variety of machine learning \n",
       "tasks.\\nmodel\\n=\\nAutoModelForSeq2SeqLM.from_pretrained(model)\\nBefore training the model, we need to define our \n",
       "training hyperparamaters using training arguments. Since text summarization is a sequence to sequence tasks, we are\n",
       "using Seq2SeqTrainingArguments. And, we need to define our trainer by passing training and test dataset along with \n",
       "training arguments.\\n# training \n",
       "arguments\\ntraining_arguments\\n=\\nSeq2SeqTrainingArguments(\\noutput_dir\\n=\\n\\'./results\\'\\n,\\nevaluation_strategy\\n\n",
       "=\\n\\'epoch\\'\\n,\\nlearning_rate\\n=\\n2e-5\\n,\\nper_device_train_batch_size\\n=\\n8\\n,\\nper_device_eval_batch_size\\n=\\n8\\\n",
       "n,\\nweight_decay\\n=\\n0.01\\n,\\nsave_total_limit\\n=\\n3\\n,\\nnum_train_epochs\\n=\\n3\\n,\\n# \n",
       "remove_unused_columns=False,\\n# \n",
       "fp16=True,\\n)\\ntrainer\\n=\\nSeq2SeqTrainer(\\nmodel\\n=\\nmodel,\\nargs\\n=\\ntraining_arguments,\\ntrain_dataset\\n=\\ntoken\n",
       "ized_pubmed[\\n\\'train\\'\\n],\\neval_dataset\\n=\\ntokenized_pubmed[\\n\\'validation\\'\\n],\\ntokenizer\\n=\\ntokenizer,\\ndata\n",
       "_collator\\n=\\ndata_collator\\n)\\nThe last step is to call\\ntrain()\\nto fine-tune our \n",
       "model.\\ntrainer.train()\\nConclusion\\nSummarization helps to generalize the long documents by paraphrasing the \n",
       "important sentences from the whole document. It is very helpful in various applications like summarizing legal \n",
       "contracts, medical documents, news information and many more.', 'metadata': {'generator': 'quarto-1.6.42', \n",
       "'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', 'dcterms.date': '2022-10-19', \n",
       "'quarto:offset': '../'}, 'depth': 1, 'relevance_score': 0.23108184337615967}, \n",
       "'https://github.com/nepalprabin/deeplearning-paper-implementation': {'title': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation', 'text': 'GitHub - \n",
       "nepalprabin/deeplearning-paper-implementation\\nSkip to content\\nYou signed in with another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your \n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\ndeeplearning-paper-implementation\\nPublic\\nNotifications\\nYou must be signed in to change \n",
       "notification settings\\nFork\\n1\\nStar\\n3\\n3\\nstars\\n1\\nfork\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must\n",
       "be signed in to change notification \n",
       "settings\\nnepalprabin/deeplearning-paper-implementation\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n13 \n",
       "Commits\\nAlexNet\\nAlexNet\\nGoogLeNet\\nGoogLeNet\\nR-CNN\\nR-CNN\\nStyleTransfer\\nStyleTransfer\\nU-Net\\nU-Net\\nVGGNet\\n\n",
       "VGGNet\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\ndeeplearning-architecture\\nI am trying \n",
       "to keep record of research papers that I have read or trying to read so far.\\nResearch Papers\\nLink\\nImageNet \n",
       "Classification with Deep Convolutional Neural Networks \n",
       "(AlexNet)\\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\\nV\n",
       "ery Deep Convolutional Networks for Large-scale Image \n",
       "Recognition(VGGNet)\\nhttps://arxiv.org/pdf/1409.1556.pdf\\nGoing Deeper with Convolutions \n",
       "(GoogLeNet)\\nhttps://arxiv.org/abs/1409.4842\\nRich feature hierarchies for accurate object detection and semantic \n",
       "segmentation (R-CNN)\\nhttps://arxiv.org/abs/1311.2524\\nU-Net: Convolutional Networks for Biomedical Image \n",
       "Segmentation\\nhttps://arxiv.org/abs/1505.04597\\nA Neural Algorithm of Artistic \n",
       "Style\\nhttps://arxiv.org/abs/1508.06576\\nGenerative Adversarial \n",
       "Networks\\nhttps://arxiv.org/abs/1406.2661\\nConditional Generative Adversarial \n",
       "Nets\\nhttps://arxiv.org/abs/1411.1784\\nUnsupervised Representation Learning with Deep Convolutional Generative \n",
       "Adversarial Networks (DCGAN)\\nhttps://arxiv.org/abs/1511.06434\\nImage-to-Image Translation with Conditional \n",
       "Adversarial Networks (pix2pix)\\nhttps://arxiv.org/abs/1611.07004\\nUnpaired Image-to-Image Translation using \n",
       "Cycle-Consistent Adversarial Networks (CycleGAN)\\nhttps://arxiv.org/abs/1703.10593\\nMobileNets: Efficient \n",
       "Convolutional Neural Networks for Mobile Vision Applications\\nhttps://arxiv.org/abs/1704.04861\\nAbout\\nNo \n",
       "description, website, or topics \n",
       "provided.\\nResources\\nReadme\\nActivity\\nStars\\n3\\nstars\\nWatchers\\n2\\nwatching\\nForks\\n1\\nfork\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter \n",
       "Notebook\\n100.0%\\nYou can’t perform that action at this time.', 'metadata': {'route-pattern': \n",
       "'/:user_id/:repository', 'route-controller': 'files', 'route-action': 'disambiguate', \n",
       "'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb', 'request-id': \n",
       "'8861:E962E:4963E9:62AD24:67C8D641', 'html-safe-nonce': \n",
       "'fa28ef0c6b8e54602c65b7c94eda697096b167245b463addfeac76a55a0b8a8f', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODYxOkU5NjJFOjQ5NjNFOTo2MkFEMjQ6NjdDOEQ2NDEiLCJ2aXNpdG9yX2lkIjoiMjkyNzYzMD\n",
       "cyNjM4NjQ3MjUxMyIsInJlZ2lvbl9lZGdlIjoiaWFkIiwicmVnaW9uX3JlbmRlciI6ImlhZCJ9', 'visitor-hmac': \n",
       "'06349d64488eaba132857900847a3799ab3e3f32e13f4f60145e227afed47ce4', 'hovercard-subject-tag': \n",
       "'repository:258506110', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'apple-itunes-app': \n",
       "'app-id=1477376905, app-argument=https://github.com/nepalprabin/deeplearning-paper-implementation', \n",
       "'twitter:image': \n",
       "'https://opengraph.githubassets.com/d61eb70bb4254782d7a0f8845a227f0e3d5e12fd0c4d55302ba65e77920654d9/nepalprabin/de\n",
       "eplearning-paper-implementation', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', \n",
       "'twitter:title': 'GitHub - nepalprabin/deeplearning-paper-implementation', 'twitter:description': 'Contribute to \n",
       "nepalprabin/deeplearning-paper-implementation development by creating an account on GitHub.', 'hostname': \n",
       "'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', 'go-import': \n",
       "'github.com/nepalprabin/deeplearning-paper-implementation git \n",
       "https://github.com/nepalprabin/deeplearning-paper-implementation.git', 'octolytics-dimension-user_id': '43682497', \n",
       "'octolytics-dimension-user_login': 'nepalprabin', 'octolytics-dimension-repository_id': '258506110', \n",
       "'octolytics-dimension-repository_nwo': 'nepalprabin/deeplearning-paper-implementation', \n",
       "'octolytics-dimension-repository_public': 'true', 'octolytics-dimension-repository_is_fork': 'false', \n",
       "'octolytics-dimension-repository_network_root_id': '258506110', 'octolytics-dimension-repository_network_root_nwo':\n",
       "'nepalprabin/deeplearning-paper-implementation', 'turbo-body-classes': 'logged-out env-production page-responsive',\n",
       "'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.2060489058494568}, \n",
       "'https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax': {'title': \n",
       "'Understanding GitHub Code Search syntax - GitHub Docs', 'text': 'Understanding GitHub Code Search syntax - GitHub \n",
       "Docs\\nSkip to main content\\nUnderstanding GitHub Code Search syntax\\nYou can build search queries for the results \n",
       "you want with specialized code qualifiers, regular expressions, and boolean operations.\\nIn this article\\nAbout \n",
       "code search query structure\\nThe search syntax in this article only applies to searching code with GitHub code \n",
       "search. Note that the syntax and qualifiers for searching for non-code content, such as issues, users, and \n",
       "discussions, is not the same as the syntax for code search. For more information on non-code search, see\\nAbout \n",
       "searching on GitHub\\nand\\nSearching on GitHub\\n.\\nSearch queries consist of search terms, comprising text you want \n",
       "to search for, and qualifiers, which narrow down the search.\\nA bare term with no qualifiers will match either the \n",
       "content of a file or the file\\'s path.\\nFor example, the following query:\\nhttp-push\\nThe above query will match \n",
       "the file\\ndocs/http-push.txt\\n, even if it doesn\\'t contain the term\\nhttp-push\\n. It will also match a file \n",
       "called\\nexample.txt\\nif it contains the term\\nhttp-push\\n.\\nYou can enter multiple terms separated by whitespace to\n",
       "search for documents that satisfy both terms.\\nFor example, the following query:\\nsparse index\\nThe search results \n",
       "would include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order. As examples, it would \n",
       "match a file containing\\nSparseIndexVector\\n, a file with the phrase\\nindex for sparse trees\\n, and even a file \n",
       "named\\nindex.txt\\nthat contains the term\\nsparse\\n.\\nSearching for multiple terms separated by whitespace is the \n",
       "equivalent to the search\\nhello AND world\\n. Other boolean operations, such as\\nhello OR world\\n, are also \n",
       "supported. For more information about boolean operations, see\\nUsing boolean operations\\n.\\nCode search also \n",
       "supports searching for an exact string, including whitespace. For more information, see\\nQuery for an exact \n",
       "match\\n.\\nYou can narrow your code search with specialized qualifiers, such as\\nrepo:\\n,\\nlanguage:\\nand\\npath:\\n. \n",
       "For more information on the qualifiers you can use in code search, see\\nUsing qualifiers\\n.\\nYou can also use \n",
       "regular expressions in your searches by surrounding the expression in slashes. For more information on using \n",
       "regular expressions, see\\nUsing regular expressions\\n.\\nQuery for an exact match\\nTo search for an exact string, \n",
       "including whitespace, you can surround the string in quotes. For example:\\n\"sparse index\"\\nYou can also use quoted \n",
       "strings in qualifiers, for example:\\npath:git language:\"protocol buffers\"\\nSearching for quotes and backslashes\\nTo\n",
       "search for code containing a quotation mark, you can escape the quotation mark using a backslash. For example, to \n",
       "find the exact string\\nname = \"tensorflow\"\\n, you can search:\\n\"name = \\\\\"tensorflow\\\\\"\"\\nTo search for code \n",
       "containing a backslash,\\n\\\\\\n, use a double backslash,\\n\\\\\\\\\\n.\\nThe two escape sequences\\n\\\\\\\\\\nand\\n\\\\\"\\ncan be \n",
       "used outside of quotes as well. No other escape sequences are recognized, though. A backslash that isn\\'t followed \n",
       "by either\\n\"\\nor\\n\\\\\\nis included in the search, unchanged.\\nAdditional escape sequences, such as\\n\\\\n\\nto match a \n",
       "newline character, are supported in regular expressions. See\\nUsing regular expressions\\n.\\nUsing boolean \n",
       "operations\\nCode search supports boolean expressions. You can use the operators\\nAND\\n,\\nOR\\n, and\\nNOT\\nto combine\n",
       "search terms.\\nBy default, adjacent terms separated by whitespace are equivalent to using the\\nAND\\noperator. For \n",
       "example, the search query\\nsparse index\\nis the same as\\nsparse AND index\\n, meaning that the search results will \n",
       "include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order.\\nTo search for documents \n",
       "containing either one term or the other, you can use the\\nOR\\noperator. For example, the following query will match\n",
       "d\n",
       "..._This content has been truncated to stay below 50000 characters_...\n",
       " organization. Monitor access, permission changes, user changes, and other events.\\nLearn more\\nRepository \n",
       "rules\\nEnhance your organization's security with scalable source code protections, and use rule insights to easily \n",
       "review how and why code changes occurred in your repositories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise \n",
       "accounts\\nEnable collaboration between your organization and GitHub environments with a single point of visibility \n",
       "and management via an enterprise account.\\nLearn more\\nRequires GitHub Enterprise\\nGitHub Connect\\nShare features \n",
       "and workflows between your GitHub Enterprise Server instance and GitHub Enterprise Cloud.\\nLearn more\\nRequires \n",
       "GitHub Enterprise\\nSAML\\nSecurely control access to organization resources like repositories, issues, and pull \n",
       "requests with SAML, while allowing users to authenticate with their GitHub usernames.\\nLearn more\\nRequires GitHub \n",
       "Enterprise\\nLDAP\\nCentralize repository management. LDAP is one of the most common protocols used to integrate \n",
       "third-party software with large company user directories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise \n",
       "Managed Users\\nManage the lifecycle and authentication of users on GitHub Enterprise Cloud from your identity \n",
       "provider (IdP).\\nLearn more\\nRequires GitHub Enterprise\\nBring your own identity provider for Enterprise Managed \n",
       "Users\\nUse the SSO and SCIM providers of your choice for Enterprise Managed Users, separate from one another, for a\n",
       "more flexible approach to user lifecycle management.\\nLearn more\\nGitHub Sponsors\\nFinancially support the open \n",
       "source projects your code depends on. Sponsor a contributor, maintainer, or project with one time or recurring \n",
       "contributions.\\nLearn more\\nGitHub Skills\\nLearn new skills by completing tasks and projects directly within \n",
       "GitHub, guided by our friendly bot.\\nLearn more\\nElectron\\nWrite cross-platform desktop applications using \n",
       "JavaScript, HTML, and CSS with the Electron framework, based on Node.js and Chromium.\\nLearn \n",
       "more\\nEducation\\nGitHub Education is a commitment to bringing tech and open source collaboration to students and \n",
       "educators across the globe.\\nLearn more\\nReady to get started?\\nExplore all the plans to find the solution that \n",
       "fits your needs.\\nView pricing plans\\nYou can’t perform that action at this time.\", 'metadata': {'route-pattern': \n",
       "'/features(.:format)', 'route-controller': 'site_features', 'route-action': 'index', \n",
       "'current-catalog-service-hash': '79cf51f992068789f17556b35146105313c98e5893e538d4903986cbf7e2509a', 'request-id': \n",
       "'8831:2297B9:415D13:5722F9:67C8D60C', 'html-safe-nonce': \n",
       "'c11b035633246196fa625cd4002ab734c4d477bd0afe5db947fb9ce3fa58b52a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODMxOjIyOTdCOTo0MTVEMTM6NTcyMkY5OjY3QzhENjBDIiwidmlzaXRvcl9pZCI6IjkxNDU3OD\n",
       "A4ODE3MDgzNDA3NDgiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'245b9f475903edc1d07278b47cc9a3b2e97b7adb56ecd6b5d65188ae69d51324', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/features', \n",
       "'twitter:image': 'https://github.githubassets.com/assets/features-launchpad-6c57787ff41d.png', 'twitter:site': \n",
       "'@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub Features', 'twitter:description': 'Get \n",
       "the right tools for the job. Automate your CI/CD and DevOps workflow with GitHub Actions, build securely, manage \n",
       "teams and projects, and review code in one place.', 'hostname': 'github.com', 'expected-hostname': 'github.com', \n",
       "'turbo-cache-control': 'no-cache', 'is_logged_out_page': 'true', 'octolytics-page-type': 'marketing', \n",
       "'turbo-body-classes': 'logged-out env-production page-responsive header-overlay', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.11251894384622574}, 'https://nepalprabin.github.io/posts/2023-05-15-gpt4-summary.html': \n",
       "{'title': 'Brief overview of GPT-4 – Prabin Nepal', 'text': 'Brief overview of GPT-4 – Prabin Nepal\\nSince the \n",
       "release of ChatGPT, there has been significant interest and discussion within the broader AI and natural language \n",
       "processing communities regarding its capabilities. In addition to this, ChatGPT has captured the attention of the \n",
       "internet at large due to its remarkable ability to generate fluent and natural-sounding responses across a wide \n",
       "range of prompts and language tasks. Due to this, it became fastest growing consumer application in the history, \n",
       "just two months after the launch. ChatGPT is fine-tuned from a model in the GPT-3.5 series and can write articles, \n",
       "jokes, poetrys in response to the prompt. Though powerful, there have also been concerns raised about the potential\n",
       "risks associated with it and other large language models (LLMs), particularly with respect to issues such as bias, \n",
       "and misinformation. One of the major concern for LLMs is that it suffers from\\nhallucination\\n.\\nHallucination \n",
       "refers to the phenomenon where the model generates responses that are not supported by the input or are \n",
       "inconsistent with reality. This can happen when the model generates text that appears to be coherent and relevant, \n",
       "but is not grounded in any factual or contextual information.\\nA year after releasing ChatGPT, OpenAI released \n",
       "GPT-4 (on 14th March, an improved version of GPT-3.5 model that supports multimodal data. It is capable of \n",
       "processing text and image data to generate textual data. It achieved human level performance on various \n",
       "professional and academic benchmarks. On a simulated bar exam, GPT-4 achieved a score that falls on the top 10% of \n",
       "the exam takes. In contrast, the score achieved by previous model GPT-3.5 fell on bottom 10%. This shows the level \n",
       "of improvement achieved by the latest version of GPT. It is also important to mention that the model was not \n",
       "specifically trained on these exams. A minority of problems were seen by model while training.\\nCapabilities of \n",
       "GPT-4\\nThough the report does not provide any details about architecture (including model size), hardware, training\n",
       "compute, dataset construction, or training method, a demo run by\\nGreg Brockman\\n(President and Co-founder, OpenAI)\n",
       "after the release of GPT-4 shows various capabilities of the model.\\nYou can watch the GPT-4 Developer Livestream \n",
       "replay here:\\n1. Supports longer context\\nGPT-4 is capable of handling over 25,000 words of text, that enables its \n",
       "usage in situations that require the creation of lengthy content, extended dialogues, or the exploration and \n",
       "analysis of extensive documents.\\n2. Hand-drawn pencil drawing turned into a fully functional website\\nGPT-4 is \n",
       "also capable of handling visual input, such as hand-drawn pencil drawings that looks like a mock design, and \n",
       "generating code to create a website. The generated output is mind blowing. Another important aspect is the accuracy\n",
       "by which the model is able to perform OCR task with such messy handwritings.\\nFig. Left is the mock design and \n",
       "right is the website created using the code generated from gpt4-model.\\nsource\\n3. GPT-4 can describe the \n",
       "image.\\nAs opposed to text on prompts (on previous GPT version), this model accepts inputs containing both text and\n",
       "images. It lets user specify any language or vision tasks. GPT-4 displays comparable skills on various types of \n",
       "content, such as documents containing both textual and visual elements like photographs, diagrams, or screenshots, \n",
       "as it does when dealing with text-only inputs.\\nExample prompt demonstrating GPT-4’s visual input capability. The \n",
       "prompt consists of a question about an image with multiple panels which GPT-4 is able to answer.\\nsource\\n4. Human \n",
       "level performance on professional and academic benchmarks\\nGPT outperforms the previous state-of-the-art models on \n",
       "various standardized exams, such as GRE, SAT, BAR, and APs, along with other research benchmarks like MMLU, \n",
       "HellaSWAG, and TextQA. GPT-4 outperforms the English language performance of GPT 3.5 and existing language models \n",
       "(\\nChinchilla\\nand\\nPaLM\\n), including low-resource languages such as Latvian, Welsh, and Swahili.\\nLimitations of \n",
       "GPT-4\\nThough there has been a tremendous improvement as compared to previous models, GPT-4 has similar limitations\n",
       "as earlier GPT models. It is not fully reliable and hallucinates.\\nSince GPT-4 is trained on the data available \n",
       "till September 2021, it lacks knowledge of the events occured after that time period.\\nRisks and mitigations\\nThe \n",
       "prompts entered by the users are not always safe. When providing unsafe inputs to the model, it may generate \n",
       "undesirable text like commiting crimes. To mitigate these risks, various approaches like Adversarial Testing, Model\n",
       "Assisted Safety Pipeline are carried out. Using domain experts and their findings, model is improved to refuse \n",
       "request for unsafe inputs like synthesizing dangerous chemicals.\\nExamples of how unsafe inputs are refused by the \n",
       "model\\nConclusion\\nThe recent advancements in GPT-4, have proven to outperform existing language models in a \n",
       "collection of NLP tasks. The improved capabilities of GPT-4 are not limited to the English language, as predictable\n",
       "scaling allows for accurate predictions in many different languages. However, the increased capabilities of GPT-4 \n",
       "also present new risks, which require significant work to understand and improve its safety and alignment. \n",
       "Nevertheless, GPT-4 marks a significant milestone towards the development of broadly useful and safely deployed AI \n",
       "systems.\\nReferences:\\nGPT-4 Technical Report\\nGPT-4 Blog Post\\nchat.openai.com\\nPS\\nWhile GPT-4 may have stolen \n",
       "the headlines, it was not the only new technology on display. AnthropicAI unveiled\\nClaude\\n, next gen AI assistant\n",
       "can help with use cases including summarization, search, creative and collaborative writing, Q&A, coding, and more.\n",
       "Meanwhile, Google AI released\\nPaLM\\n, an entry point for Google’s large language models with variety of \n",
       "applications. With these three new systems, the future of AI looks brighter than ever before.', 'metadata': \n",
       "{'generator': 'quarto-1.6.42', 'viewport': 'width=device-width, initial-scale=1.0, user-scalable=yes', \n",
       "'dcterms.date': '2023-03-15', 'quarto:offset': '../'}, 'depth': 1, 'relevance_score': 0.11177341639995575}, \n",
       "'https://github.com/collections': {'title': 'Collections · GitHub', 'text': \"Collections · GitHub\\nSkip to \n",
       "content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab\n",
       "or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh \n",
       "your session.\\nDismiss alert\\nCollections\\nCurated lists and insight into burgeoning industries, topics, and \n",
       "communities.\\n#\\nGame Engines\\nFrameworks for building games across multiple platforms.\\nLearn to Code\\nResources \n",
       "to help people learn to code\\nPixel Art Tools\\nCreating pixel art for fun or animated sprites for a game? The \n",
       "digital artist in you will love these apps and tools!\\n#\\nHow to choose (and contribute to) your first open source \n",
       "project\\nNew to open source? Here’s how to find projects that need help and start making impactful \n",
       "contributions.\\n#\\nClean code linters\\nMake sure your code matches your style guide with these essential code \n",
       "linters.\\n#\\nOpen journalism\\nSee how publications and data-driven journalists use open source to power their \n",
       "newsroom and ensure information is reported fairly and accurately.\\n#\\nDesign essentials\\nThis collection of design\n",
       "libraries are the best on the web, and will complete your toolset for designing stunning products.\\n#\\nMusic\\nDrop \n",
       "the code bass with these musically themed repositories.\\nGovernment apps\\nSites, apps, and tools built by \n",
       "governments across the world to make government work better, together. Read more at \n",
       "https://government.github.com\\n#\\nDevOps tools\\nThese tools help you manage servers and deploy happier and more \n",
       "often with more confidence.\\n#\\nFront-end JavaScript frameworks\\nWhile the number of ways to organize JavaScript is\n",
       "almost infinite, here are some tools that help you build single-page applications.\\n#\\nGitHub Browser \n",
       "Extensions\\nSome useful and fun browser extensions to personalize your GitHub browser experience.\\nGitHub Pages \n",
       "examples\\nFine examples of projects using GitHub Pages (https://pages.github.com).\\nHacking Minecraft\\nMinecraft is\n",
       "a game about building blocks, but it doesn’t end there. Take Minecraft further with some of the projects below, or \n",
       "dive into the code mines and hammer your own!\\n#\\nJavaScript Game Engines\\nLearn or level up your 1337 gamedev \n",
       "skills and build amazing games together for web, desktop, or mobile using these HTML5 / JavaScript game \n",
       "engines.\\nLearn to Code\\nResources to help people learn to code\\n#\\nGetting started with machine learning\\nToday, \n",
       "machine learning—the study of algorithms that make data-based predictions—has found a new audience and a new set of\n",
       "possibilities.\\nMade in Africa\\nDevelopers in Africa use open source technology to solve some of the world's most \n",
       "intractable problems and grow their business ecosystems. Here's a snapshot of local projects across the \n",
       "continent.\\nNet neutrality\\nSoftware, research, and organizations protecting the free and open internet.\\n#\\nOpen \n",
       "data\\nExamples of using GitHub to store, publish, and collaborate on open, machine-readable datasets\\nOpen source \n",
       "organizations\\nA showcase of organizations showcasing their open source projects.\\n#\\nPolicies\\nFrom federal \n",
       "governments to corporations to student clubs, groups of all sizes are using GitHub to share, discuss, and improve \n",
       "laws. *Ask not what the repository can do for you...*\\n#\\nSoftware productivity tools\\nBuild software faster with \n",
       "fewer headaches, using these tools and tricks.\\nLoad more…\\nYou can’t perform that action at this time.\", \n",
       "'metadata': {'route-pattern': '/collections(.:format)', 'route-controller': 'collections', 'route-action': 'index',\n",
       "'current-catalog-service-hash': '68905b05f2811955010ef44286a1edf6dad580d793d21bb719e7abcf48e7a0ae', 'request-id': \n",
       "'884C:1F90E5:457F11:5CDB64:67C8D626', 'html-safe-nonce': \n",
       "'6dec25dad345f21777f56f8108fb1fb97a169fa8ef8dc8450daf90735512020a', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODRDOjFGOTBFNTo0NTdGMTE6NUNEQjY0OjY3QzhENjI2IiwidmlzaXRvcl9pZCI6IjU0MDYwMT\n",
       "g2NTIyMzgwNDI2NjMiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'c7f2ee3f43777769145e652af2e60e77d1b3bac35e5b2a2c6765960ab1eba326', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/collections', \n",
       "'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': 'no-preview', \n",
       "'turbo-body-classes': 'logged-out env-production page-responsive', 'browser-stats-url': \n",
       "'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.10756564885377884}, 'https://github.com/features/code-review': {'title': 'GitHub Code \n",
       "Review · GitHub', 'text': 'GitHub Code Review · GitHub\\nSkip to content\\nGitHub Copilot is now available for \n",
       "free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in \n",
       "another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or \n",
       "window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCode Review\\nWrite better code\\nOn GitHub, lightweight \n",
       "code review tools are built into every pull request. Your team can create review processes that improve the quality\n",
       "of your code and fit neatly into your workflow.\\nGet started\\nContact sales\\nEvery change starts with a pull \n",
       "request.\\nLearn pull request fundamentals\\nStart a new feature or propose a change to existing code with a pull \n",
       "request\\n—a base for your team to coordinate details and refine your changes.\\nPull requests are fundamental to how\n",
       "teams review and improve code on GitHub\\n. Evolve projects, propose new features, and discuss implementation \n",
       "details before changing your source code.\\nDiffs\\nPreview changes in context with your code to see what is being \n",
       "proposed. Side-by-side Diffs highlight added, edited, and deleted code right next to the original file, so you can \n",
       "easily spot changes.\\nLearn more\\nHistory\\nBrowse commits, comments, and references related to your pull request in\n",
       "a timeline-style interface. Your pull request will also highlight what’s changed since you last checked.\\nLearn \n",
       "more\\nBlame\\nSee what a file looked like before a particular change. With blame view, you can see how any portion \n",
       "of your file has evolved over time without viewing the file’s full history.\\nLearn more\\nComments\\nOn GitHub, \n",
       "conversations happen alongside your code. Leave detailed comments on code syntax and ask questions about structure \n",
       "inline.\\nReview requests\\nIf you’re on the other side of the code, requesting peer reviews is easy. Add users to \n",
       "your pull request, and they’ll receive a notification letting them know you need their feedback.\\nReviews\\nSave \n",
       "your teammates a few notifications. Bundle your comments into one cohesive review, then specify whether comments \n",
       "are required changes or just suggestions.\\nResolve simple conflicts\\nYou can’t always avoid conflict. Merge pull \n",
       "requests faster by resolving simple merge conflicts on GitHub—no command line necessary.\\nLearn how to resolve \n",
       "merge conflicts\\nFast, relevant results\\nGive collaborators as much access as they need through your repository \n",
       "settings. You can extend access to a few teams and select which ones can read or write to your files. The options \n",
       "you have for permissions depend on your plan.\\nSee plan options\\nProtected branches\\nProtected Branches help you \n",
       "maintain the integrity of your code. Limit who can push to a branch, and disable force pushes to specific branches.\n",
       "Then scale your policies with the Protected Branches API.\\nLearn more\\nRequired status checks\\nCreate required \n",
       "status checks to add an extra layer of error prevention on branches. Use the Status API to enforce checks and \n",
       "disable the merge button until they pass. To err is human; to automate, divine!\\nStatus API doc\\nEvery change \n",
       "starts with a pull request.\\nGet started\\nContact sales\\nYou can’t perform that action at this time.', 'metadata': \n",
       "{'route-pattern': '/features/code-review(.:format)', 'route-controller': 'site_features_code_review', \n",
       "'route-action': 'index', 'current-catalog-service-hash': \n",
       "'79cf51f992068789f17556b35146105313c98e5893e538d4903986cbf7e2509a', 'request-id': \n",
       "'882E:366203:4623C7:5E4068:67C8D60A', 'html-safe-nonce': \n",
       "'5e1fd3cb165203bc3f236d66b1c7db1d9ddd07d91501b71cbabd02f9abdb3ae1', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODJFOjM2NjIwMzo0NjIzQzc6NUU0MDY4OjY3QzhENjBBIiwidmlzaXRvcl9pZCI6IjY0NDgzOD\n",
       "A5ODk5MDY5MzMyNTgiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'4d72ea962ca9e838546ea8cc4820c762485b5937011b853cee3f60be92abf9f7', 'github-keyboard-shortcuts': 'copilot', \n",
       "'google-site-verification': 'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': \n",
       "'https://collector.github.com/github/collect', 'viewport': 'width=device-width', 'description': 'GitHub is where \n",
       "people build software. More than 150 million people use GitHub to discover, fork, and contribute to over 420 \n",
       "million projects.', 'apple-itunes-app': 'app-id=1477376905, app-argument=https://github.com/features/code-review', \n",
       "'twitter:image': 'https://github.githubassets.com/assets/features-4761c659150b.png', 'twitter:site': '@github', \n",
       "'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub Code Review', 'twitter:description': 'Make code \n",
       "review seamless with GitHub. Request reviews, propose changes, keep track of versions, and protect branches on the \n",
       "path to better code with your team.', 'hostname': 'github.com', 'expected-hostname': 'github.com', \n",
       "'turbo-cache-control': 'no-cache', 'is_logged_out_page': 'true', 'octolytics-page-type': 'marketing', \n",
       "'octolytics-revenue-play': 'Platform', 'turbo-body-classes': 'logged-out env-production page-responsive \n",
       "header-dark', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', 'browser-errors-url': \n",
       "'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': 'light dark'}, 'depth':\n",
       "2, 'relevance_score': 0.10641869902610779}, 'https://github.com/nepalprabin/nepalprabin': {'title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'text': \"GitHub - nepalprabin/nepalprabin\\nSkip to content\\nYou signed in with another \n",
       "tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your\n",
       "session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss \n",
       "alert\\nnepalprabin\\n/\\nnepalprabin\\nPublic\\nNotifications\\nYou must be signed in to change notification \n",
       "settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed \n",
       "in to change notification settings\\nnepalprabin/nepalprabin\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and \n",
       "files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n14 \n",
       "Commits\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\nHi 👋, I'm Prabin Nepal\\nA passionate \n",
       "software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull \n",
       "Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nAbout\\nNo description, website, or\n",
       "topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport \n",
       "repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nYou can’t perform that action at \n",
       "this time.\", 'metadata': {'route-pattern': '/:user_id/:repository', 'route-controller': 'files', 'route-action': \n",
       "'disambiguate', 'current-catalog-service-hash': 'f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb',\n",
       "'request-id': '885D:148B86:468AB6:5EA3B6:67C8D639', 'html-safe-nonce': \n",
       "'2e85c74115beb5e1e134f0c55ba7d98d8191a15ecc34599c10cf561436845743', 'visitor-payload': \n",
       "'eyJyZWZlcnJlciI6IiIsInJlcXVlc3RfaWQiOiI4ODVEOjE0OEI4Njo0NjhBQjY6NUVBM0I2OjY3QzhENjM5IiwidmlzaXRvcl9pZCI6IjczODY4MD\n",
       "cyMDIwNzE3NjI0ODkiLCJyZWdpb25fZWRnZSI6ImlhZCIsInJlZ2lvbl9yZW5kZXIiOiJpYWQifQ==', 'visitor-hmac': \n",
       "'44b6648ccdfe752ed85305ebb06add2ba0881ec0366c36e35d31bdf78566a2aa', 'hovercard-subject-tag': \n",
       "'repository:278281752', 'github-keyboard-shortcuts': 'repository,copilot', 'google-site-verification': \n",
       "'Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I', 'octolytics-url': 'https://collector.github.com/github/collect', \n",
       "'analytics-location': '/<user-name>/<repo-name>', 'viewport': 'width=device-width', 'description': 'Contribute to \n",
       "nepalprabin/nepalprabin development by creating an account on GitHub.', 'apple-itunes-app': 'app-id=1477376905, \n",
       "app-argument=https://github.com/nepalprabin/nepalprabin', 'twitter:image': \n",
       "'https://opengraph.githubassets.com/938931e393aefe0802f7134e6271f2c2d66d2eacd02f8ab7f9f16dfbc37c3816/nepalprabin/ne\n",
       "palprabin', 'twitter:site': '@github', 'twitter:card': 'summary_large_image', 'twitter:title': 'GitHub - \n",
       "nepalprabin/nepalprabin', 'twitter:description': 'Contribute to nepalprabin/nepalprabin development by creating an \n",
       "account on GitHub.', 'hostname': 'github.com', 'expected-hostname': 'github.com', 'turbo-cache-control': \n",
       "'no-preview', 'go-import': 'github.com/nepalprabin/nepalprabin git https://github.com/nepalprabin/nepalprabin.git',\n",
       "'octolytics-dimension-user_id': '43682497', 'octolytics-dimension-user_login': 'nepalprabin', \n",
       "'octolytics-dimension-repository_id': '278281752', 'octolytics-dimension-repository_nwo': \n",
       "'nepalprabin/nepalprabin', 'octolytics-dimension-repository_public': 'true', \n",
       "'octolytics-dimension-repository_is_fork': 'false', 'octolytics-dimension-repository_network_root_id': '278281752',\n",
       "'octolytics-dimension-repository_network_root_nwo': 'nepalprabin/nepalprabin', 'turbo-body-classes': 'logged-out \n",
       "env-production page-responsive', 'browser-stats-url': 'https://api.github.com/_private/browser/stats', \n",
       "'browser-errors-url': 'https://api.github.com/_private/browser/errors', 'theme-color': '#1e2327', 'color-scheme': \n",
       "'light dark'}, 'depth': 2, 'relevance_score': 0.10383956879377365}}\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 16.46 seconds| Input tokens: 61,462 | Output tokens: 819]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 16.46 seconds| Input tokens: 61,462 | Output tokens: 819]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m5\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Synthesize the relevant content into a JSON document</span><span style=\"background-color: #272822\">                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">output_format </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"json\"</span><span style=\"background-color: #272822\">                                                                                         </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">synthesized_document </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> document_synthesizer_tool(relevant_content</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">relevant_content, prompt</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prompt, </span><span style=\"background-color: #272822\">            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">output_format</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">output_format)</span><span style=\"background-color: #272822\">                                                                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(synthesized_document)</span><span style=\"background-color: #272822\">                                                                             </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Synthesize the relevant content into a JSON document\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34moutput_format\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mjson\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34msynthesized_document\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdocument_synthesizer_tool\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_content\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrelevant_content\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprompt\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprompt\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34moutput_format\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moutput_format\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msynthesized_document\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: {'title': 'Information about: Extract all the blog contents based on this prompt', 'content': </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">'{\\n  \"title\": \"Information about: Extract all the blog contents based on this prompt\",\\n  \"prompt\": \"Extract all </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">the blog contents based on this prompt\",\\n  \"sources\": [\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/deeplearning-paper-implementation\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"http://3.14.28.154/\",\\n    \"https://nepalprabin.github.io/posts/2023-07-04-augmented-language-models.html\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/features/code-search\",\\n    \"https://github.com/customer-stories\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://nepalprabin.github.io/posts/2025-03-02-huggingface-smolagents-solutions.html\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/chat-with-nlp-book-gpt\",\\n    \"https://github.com/resources/articles/ai\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/contact/report-abuse?report=nepalprabin+%28user%29\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://docs.github.com/articles/reporting-abuse-or-spam\",\\n    \"https://github.com/nepalprabin?tab=followers\",\\n </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/features/discussions\",\\n    \"https://nepalprabin.github.io\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://nepalprabin.github.io/index.html\",\\n    \"https://github.blog\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?tab=following\",\\n    \"https://github.com/nepalprabin?tab=stars\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?tab=repositories\",\\n    \"https://github.com/resources/whitepapers\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://docs.github.com\",\\n    \"https://github.com/features/issues\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://nepalprabin.github.io/projects.html\",\\n    \"https://github.com/nepalprabin?tab=projects\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin\",\\n    \"https://github.com/nepalprabin?tab=packages\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E&amp;source=header\",\\n </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?tab=achievements\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?achievement=pair-extraordinaire&amp;tab=achievements\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?achievement=pull-shark&amp;tab=achievements\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin?achievement=arctic-code-vault-contributor&amp;tab=achievements\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/features\",\\n    \"https://nepalprabin.github.io/posts/2023-05-15-gpt4-summary.html\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/collections\",\\n    \"https://github.com/features/code-review\",\\n    </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/nepalprabin\"\\n  ],\\n  \"created_at\": \"2025-03-05T17:55:28.336760\",\\n  \"sections\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">[\\n    {\\n      \"title\": \"whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main \\\\u00b7 </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">nepalprabin/whisper-webapp \\\\u00b7 GitHub\",\\n      \"url\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip\",\\n      </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"relevance_score\": 0.24178938567638397,\\n      \"content\": [\\n        </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main \\\\u00b7 nepalprabin/whisper-webapp \\\\u00b7 </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">GitHub\\\\nSkip to content\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">signed out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched accounts on another tab or </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">window.\\\\nReload\\\\nto refresh your session.\\\\nDismiss </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">alert\\\\nnepalprabin\\\\n/\\\\nwhisper-webapp\\\\nPublic\\\\nNotifications\\\\nYou must be signed in to change notification </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">settings\\\\nFork\\\\n0\\\\nStar\\\\n0\\\\nFiles\\\\nmain\\\\n/\\\\nStanford_NLP_lecture_transcripts.zip\\\\nCopy path\\\\nLatest </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">commit\\\\nHistory\\\\nHistory\\\\n1.99 MB\\\\nmain\\\\n/\\\\nStanford_NLP_lecture_transcripts.zip\\\\nTop\\\\nFile metadata and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">controls\\\\nCode\\\\nBlame\\\\n1.99 MB\\\\nRaw\\\\nView raw\\\\nYou can\\\\u2019t perform that action at this time.\"\\n      ]\\n </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">},\\n    {\\n      \"title\": \"Text Summarization NLP \\\\u2013 Prabin Nepal\",\\n      \"url\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html\",\\n      \"relevance_score\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">0.23108184337615967,\\n      \"content\": [\\n        \"Text Summarization NLP \\\\u2013 Prabin Nepal\\\\nWhat is text </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">summarization?\\\\nText summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">shortened automatically while holding the same semantic meaning. Summarization process generates short, fluent and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">accurate summary of the long documents. The main idea of text summarization is to find the subset of the most </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">important information from the entire document and present it in a human readable format. Text summarization has </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">its application in other NLP tasks such as Question Answering (QA), Text Classification, Text Generation and other </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">fields.\\\\nTypes of summarization\\\\nBased on how the texts are extracted from the documents, the summarization </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">process can be divided into two types: extractive summarization and abstractive summarization.\\\\nExtractive </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Summarization\\\\nExtractive summarization picks up the most important sentences directly from the documents and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">forms a coherent summary. This is done using a scoring function. Extractive summarization takes a sentence as an </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">input and produces a probability vector as the output. This probability vector represents the probability of a </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sentence being included in the summary.\\\\nImplementing extractive summarization based on word frequency\\\\nWe can </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">implement extractive summarization using word frequency in five simple steps:\\\\na. Creating word frequency </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">table\\\\nWe count the frequency of the words present in the text and create a frequency table which is a dictionary </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">to store the count. While creating the frequency table, we do not account for the stop words present in the text </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and remove those words.\\\\ndef\\\\nfrequency_table(text):\\\\n# all unique stopwords of </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">english\\\\nstop_words\\\\n=\\\\nset\\\\n(stopwords.words(\\\\n\\\\\"english\\\\\"\\\\n))\\\\nwords\\\\n=\\\\nword_tokenize(text)\\\\nfreq_ta</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">ble\\\\n=\\\\ndict\\\\n()\\\\n# creating frequency table to keep the count of each </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">word\\\\nfor\\\\nword\\\\nin\\\\nwords:\\\\nword\\\\n=\\\\nword.lower()\\\\nif\\\\nword\\\\nin\\\\nstop_words:\\\\ncontinue\\\\nif\\\\nword\\\\ni</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">n\\\\nfreq_table:\\\\nfreq_table[word]\\\\n+=\\\\n1\\\\nelse\\\\n:\\\\nfreq_table[word]\\\\n=\\\\n1\\\\nreturn\\\\nfreq_table\\\\nb. </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Tokenizing the sentences\\\\nHere we tokenize the sentences using NLTK\\\\u2019s sent_tokenize() method. This separates</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">paragraphs into individual </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sentences.\\\\ndef\\\\ntokenize_sentence(text):\\\\nreturn\\\\nsent_tokenize(text)\\\\nc.\\\\u00a0Scoring the sentences using </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">term frequency\\\\nHere, we score a sentence by its words, by adding frequency of every word present in the sentence </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">excluding stop words. One downside of this approach is, if the sentence is long, the value of frequency </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">increases.\\\\ndef\\\\nterm_frequency_score(sentence, freq_table):\\\\n# dictionary to keep the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">score\\\\nsentence_value\\\\n=\\\\ndict\\\\n()\\\\nfor\\\\nsentence\\\\nin\\\\nsentences:\\\\nfor\\\\nword, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">freq\\\\nin\\\\nfreq_table.items():\\\\nif\\\\nword\\\\nin\\\\nsentence.lower():\\\\nif\\\\nsentence\\\\nin\\\\nsentence_value:\\\\nsente</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">nce_value[sentence]\\\\n+=\\\\nfreq\\\\nelse\\\\n:\\\\nsentence_value[sentence]\\\\n=\\\\nfreq\\\\nreturn\\\\nsentence_value\\\\nd.\\\\u0</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">0a0Finding the threshold score\\\\nAfter calculating the term frequency, we calculate the threshold </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">score.\\\\ndef\\\\ncalculate_average_score(sentence_value):\\\\n# To compare the sentences within the text, we assign a </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">score.\\\\nsum_values\\\\n=\\\\n0\\\\nfor\\\\nsentence\\\\nin\\\\nsentence_value:\\\\nsum_values\\\\n+=\\\\nsentence_value[sentence]\\\\n</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\"># Calculating average score of the sentence. This average score can be a good </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">threshold.\\\\naverage\\\\n=\\\\nint\\\\n(sum_values\\\\n/\\\\nlen\\\\n(sentence_value))\\\\nreturn\\\\naverage\\\\ne. Generating the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">summary based on the threshold value\\\\nBased on the threshold value, we generate the summary of the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">text.\\\\ndef\\\\ncreate_summary(sentences, sentence_value, threshold):\\\\n# Applying the threshold value and storing </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sentences in an order into the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">summary.\\\\nsummary\\\\n=\\\\n\\'\\'\\\\nfor\\\\nsentence\\\\nin\\\\nsentences:\\\\nif\\\\n(sentence\\\\nin\\\\nsentence_value)\\\\nand\\\\n(s</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">entence_value[sentence]\\\\n&gt;\\\\n(\\\\n1.2\\\\n*\\\\nthreshold)):\\\\nsummary\\\\n+=\\\\n\\\\\" </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\\\\\"\\\\n+\\\\nsentence\\\\nreturn\\\\nsummary\\\\nAbstractive Summarization\\\\nIn abstractive summarization, the model forms </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">its own phrases and sentences to provide a consistent summary. Abstractive summarization does not simply copy the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sentences to form the summary but create new phrases that are relevant to the original document. This summarization</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">technique uses deep learning techniques (like seq2seq) to paraphrase and shorten the original </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">document.\\\\nAbstractive Summarization using Transformers\\\\nTransformers is an architecture which uses attention </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">mechanisms to solve sequence to sequence problems while solving long term dependencies. Ever since it was </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">introduced in 2017, transformers have been widely used in various NLP tasks such as text generation, question </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">answering, text classification, language translation and so on. The transformer architecture consists of encoder </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and decoder parts. The encoder component consists of 6 encoders each of which consists of two sub layers: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">self-attention and feed forward networks. The input text is first converted into vectors using text embedding </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">methods. Then the vector is passed into the self attention layer and the output from the self attention layer is </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">passed through the feed forward network. The decoder also consists of both self attention and feed forward network </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">layer. An additional layer is present in between these components which is an attention layer that helps the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">decoder to focus on the relevant parts of the input sentence.\\\\nFig. Transformer architecture (from original </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">paper)\\\\nHuggingface Transformers provide various pre-trained models to perform NLP tasks. It provides APIs and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">tools to download and train state-of-the-art pre-trained models. Not only NLP, huggingface supports Computer Vision</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">tasks like image classification, object detection and segmentation, audio classification and recognition, and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">multimodal tasks like table question answering, optical character recognition, and many more.\\\\nBasic transformer </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">pipeline fo</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">..._This content has been truncated to stay below 20000 characters_...</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">rate predictions in many different languages. However, the increased capabilities of GPT-4 also present new risks, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">which require significant work to understand and improve its safety and alignment. Nevertheless, GPT-4 marks a </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">significant milestone towards the development of broadly useful and safely deployed AI </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">systems.\\\\nReferences:\\\\nGPT-4 Technical Report\\\\nGPT-4 Blog Post\\\\nchat.openai.com\\\\nPS\\\\nWhile GPT-4 may have </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">stolen the headlines, it was not the only new technology on display. AnthropicAI unveiled\\\\nClaude\\\\n, next gen AI </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">assistant can help with use cases including summarization, search, creative and collaborative writing, Q&amp;A, coding,</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and more. Meanwhile, Google AI released\\\\nPaLM\\\\n, an entry point for Google\\\\u2019s large language models with </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">variety of applications. With these three new systems, the future of AI looks brighter than ever before.\"\\n      </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">]\\n    },\\n    {\\n      \"title\": \"Collections \\\\u00b7 GitHub\",\\n      \"url\": \"https://github.com/collections\",\\n   </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"relevance_score\": 0.10756564885377884,\\n      \"content\": [\\n        \"Collections \\\\u00b7 GitHub\\\\nSkip to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">content\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou signed out in another</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched accounts on another tab or window.\\\\nReload\\\\nto </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">refresh your session.\\\\nDismiss alert\\\\nCollections\\\\nCurated lists and insight into burgeoning industries, topics,</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and communities.\\\\n#\\\\nGame Engines\\\\nFrameworks for building games across multiple platforms.\\\\nLearn to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Code\\\\nResources to help people learn to code\\\\nPixel Art Tools\\\\nCreating pixel art for fun or animated sprites </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">for a game? The digital artist in you will love these apps and tools!\\\\n#\\\\nHow to choose (and contribute to) your </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">first open source project\\\\nNew to open source? Here\\\\u2019s how to find projects that need help and start making </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">impactful contributions.\\\\n#\\\\nClean code linters\\\\nMake sure your code matches your style guide with these </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">essential code linters.\\\\n#\\\\nOpen journalism\\\\nSee how publications and data-driven journalists use open source to</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">power their newsroom and ensure information is reported fairly and accurately.\\\\n#\\\\nDesign essentials\\\\nThis </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">collection of design libraries are the best on the web, and will complete your toolset for designing stunning </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">products.\\\\n#\\\\nMusic\\\\nDrop the code bass with these musically themed repositories.\\\\nGovernment apps\\\\nSites, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">apps, and tools built by governments across the world to make government work better, together. Read more at </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">https://government.github.com\\\\n#\\\\nDevOps tools\\\\nThese tools help you manage servers and deploy happier and more </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">often with more confidence.\\\\n#\\\\nFront-end JavaScript frameworks\\\\nWhile the number of ways to organize JavaScript</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">is almost infinite, here are some tools that help you build single-page applications.\\\\n#\\\\nGitHub Browser </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Extensions\\\\nSome useful and fun browser extensions to personalize your GitHub browser experience.\\\\nGitHub Pages </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">examples\\\\nFine examples of projects using GitHub Pages (https://pages.github.com).\\\\nHacking Minecraft\\\\nMinecraft</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">is a game about building blocks, but it doesn\\\\u2019t end there. Take Minecraft further with some of the projects </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">below, or dive into the code mines and hammer your own!\\\\n#\\\\nJavaScript Game Engines\\\\nLearn or level up your 1337</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">gamedev skills and build amazing games together for web, desktop, or mobile using these HTML5 / JavaScript game </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">engines.\\\\nLearn to Code\\\\nResources to help people learn to code\\\\n#\\\\nGetting started with machine </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">learning\\\\nToday, machine learning\\\\u2014the study of algorithms that make data-based predictions\\\\u2014has found a</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">new audience and a new set of possibilities.\\\\nMade in Africa\\\\nDevelopers in Africa use open source technology to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">solve some of the world\\'s most intractable problems and grow their business ecosystems. Here\\'s a snapshot of </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">local projects across the continent.\\\\nNet neutrality\\\\nSoftware, research, and organizations protecting the free </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and open internet.\\\\n#\\\\nOpen data\\\\nExamples of using GitHub to store, publish, and collaborate on open, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">machine-readable datasets\\\\nOpen source organizations\\\\nA showcase of organizations showcasing their open source </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">projects.\\\\n#\\\\nPolicies\\\\nFrom federal governments to corporations to student clubs, groups of all sizes are using</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">GitHub to share, discuss, and improve laws. *Ask not what the repository can do for you...*\\\\n#\\\\nSoftware </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">productivity tools\\\\nBuild software faster with fewer headaches, using these tools and tricks.\\\\nLoad </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">more\\\\u2026\\\\nYou can\\\\u2019t perform that action at this time.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"GitHub </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Code Review \\\\u00b7 GitHub\",\\n      \"url\": \"https://github.com/features/code-review\",\\n      \"relevance_score\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">0.10641869902610779,\\n      \"content\": [\\n        \"GitHub Code Review \\\\u00b7 GitHub\\\\nSkip to content\\\\nGitHub </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Copilot is now available for free.\\\\nLearn more\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">your session.\\\\nYou signed out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">accounts on another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nDismiss alert\\\\nCode Review\\\\nWrite better</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">code\\\\nOn GitHub, lightweight code review tools are built into every pull request. Your team can create review </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">processes that improve the quality of your code and fit neatly into your workflow.\\\\nGet started\\\\nContact </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sales\\\\nEvery change starts with a pull request.\\\\nLearn pull request fundamentals\\\\nStart a new feature or propose</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">a change to existing code with a pull request\\\\n\\\\u2014a base for your team to coordinate details and refine your </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">changes.\\\\nPull requests are fundamental to how teams review and improve code on GitHub\\\\n. Evolve projects, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">propose new features, and discuss implementation details before changing your source code.\\\\nDiffs\\\\nPreview </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">changes in context with your code to see what is being proposed. Side-by-side Diffs highlight added, edited, and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">deleted code right next to the original file, so you can easily spot changes.\\\\nLearn more\\\\nHistory\\\\nBrowse </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">commits, comments, and references related to your pull request in a timeline-style interface. Your pull request </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">will also highlight what\\\\u2019s changed since you last checked.\\\\nLearn more\\\\nBlame\\\\nSee what a file looked like</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">before a particular change. With blame view, you can see how any portion of your file has evolved over time without</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">viewing the file\\\\u2019s full history.\\\\nLearn more\\\\nComments\\\\nOn GitHub, conversations happen alongside your </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">code. Leave detailed comments on code syntax and ask questions about structure inline.\\\\nReview requests\\\\nIf </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">you\\\\u2019re on the other side of the code, requesting peer reviews is easy. Add users to your pull request, and </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">they\\\\u2019ll receive a notification letting them know you need their feedback.\\\\nReviews\\\\nSave your teammates a </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">few notifications. Bundle your comments into one cohesive review, then specify whether comments are required </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">changes or just suggestions.\\\\nResolve simple conflicts\\\\nYou can\\\\u2019t always avoid conflict. Merge pull </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">requests faster by resolving simple merge conflicts on GitHub\\\\u2014no command line necessary.\\\\nLearn how to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">resolve merge conflicts\\\\nFast, relevant results\\\\nGive collaborators as much access as they need through your </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">repository settings. You can extend access to a few teams and select which ones can read or write to your files. </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">The options you have for permissions depend on your plan.\\\\nSee plan options\\\\nProtected branches\\\\nProtected </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Branches help you maintain the integrity of your code. Limit who can push to a branch, and disable force pushes to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">specific branches. Then scale your policies with the Protected Branches API.\\\\nLearn more\\\\nRequired status </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">checks\\\\nCreate required status checks to add an extra layer of error prevention on branches. Use the Status API to</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">enforce checks and disable the merge button until they pass. To err is human; to automate, divine!\\\\nStatus API </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">doc\\\\nEvery change starts with a pull request.\\\\nGet started\\\\nContact sales\\\\nYou can\\\\u2019t perform that action </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">at this time.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"GitHub - nepalprabin/nepalprabin\",\\n      \"url\": </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"https://github.com/nepalprabin/nepalprabin\",\\n      \"relevance_score\": 0.10383956879377365,\\n      \"content\": [\\n </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\"GitHub - nepalprabin/nepalprabin\\\\nSkip to content\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">refresh your session.\\\\nYou signed out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">accounts on another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nDismiss </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">alert\\\\nnepalprabin\\\\n/\\\\nnepalprabin\\\\nPublic\\\\nNotifications\\\\nYou must be signed in to change notification </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">settings\\\\nFork\\\\n0\\\\nStar\\\\n0\\\\n0\\\\nstars\\\\n0\\\\nforks\\\\nBranches\\\\nTags\\\\nActivity\\\\nStar\\\\nNotifications\\\\nYou </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">must be signed in to change notification settings\\\\nnepalprabin/nepalprabin\\\\nmaster\\\\nBranches\\\\nTags\\\\nGo to </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">file\\\\nCode\\\\nFolders and files\\\\nName\\\\nName\\\\nLast commit message\\\\nLast commit date\\\\nLatest </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">commit\\\\nHistory\\\\n14 Commits\\\\nREADME.md\\\\nREADME.md\\\\nView all files\\\\nRepository files navigation\\\\nHi </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">\\\\ud83d\\\\udc4b, I\\'m Prabin Nepal\\\\nA passionate software developer\\\\n\\\\ud83c\\\\udf31 I\\\\u2019m currently </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">learning\\\\nDeep Learning for Computer Vision and NLP\\\\n\\\\ud83d\\\\udcac Ask me about\\\\nFull Stack Development, Deep </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Learning\\\\n\\\\ud83d\\\\udceb How to reach me\\\\nprabinnepal1996@gmail.com\\\\nAbout\\\\nNo description, website, or topics </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">provided.\\\\nResources\\\\nReadme\\\\nActivity\\\\nStars\\\\n0\\\\nstars\\\\nWatchers\\\\n1\\\\nwatching\\\\nForks\\\\n0\\\\nforks\\\\nRepor</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">t repository\\\\nReleases\\\\nNo releases published\\\\nPackages\\\\n0\\\\nNo packages published\\\\nYou can\\\\u2019t perform </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">that action at this time.\"\\n      ]\\n    }\\n  ]\\n}', 'format': 'json', 'metadata': {'prompt': 'Extract all the blog</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">contents based on this prompt', 'sources': 38, 'created_at': '2025-03-05T17:55:28.338272'}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: {'title': 'Information about: Extract all the blog contents based on this prompt', 'content': \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m'{\\n  \"title\": \"Information about: Extract all the blog contents based on this prompt\",\\n  \"prompt\": \"Extract all \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mthe blog contents based on this prompt\",\\n  \"sources\": [\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/deeplearning-paper-implementation\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"http://3.14.28.154/\",\\n    \"https://nepalprabin.github.io/posts/2023-07-04-augmented-language-models.html\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/features/code-search\",\\n    \"https://github.com/customer-stories\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://nepalprabin.github.io/posts/2025-03-02-huggingface-smolagents-solutions.html\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/chat-with-nlp-book-gpt\",\\n    \"https://github.com/resources/articles/ai\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/contact/report-abuse?report=nepalprabin+%28user%29\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://docs.github.com/articles/reporting-abuse-or-spam\",\\n    \"https://github.com/nepalprabin?tab=followers\",\\n \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/features/discussions\",\\n    \"https://nepalprabin.github.io\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://nepalprabin.github.io/index.html\",\\n    \"https://github.blog\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?tab=following\",\\n    \"https://github.com/nepalprabin?tab=stars\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?tab=repositories\",\\n    \"https://github.com/resources/whitepapers\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://docs.github.com\",\\n    \"https://github.com/features/issues\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://nepalprabin.github.io/projects.html\",\\n    \"https://github.com/nepalprabin?tab=projects\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin\",\\n    \"https://github.com/nepalprabin?tab=packages\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E&source=header\",\\n \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?tab=achievements\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?achievement=pair-extraordinaire&tab=achievements\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?achievement=pull-shark&tab=achievements\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin?achievement=arctic-code-vault-contributor&tab=achievements\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/features\",\\n    \"https://nepalprabin.github.io/posts/2023-05-15-gpt4-summary.html\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/collections\",\\n    \"https://github.com/features/code-review\",\\n    \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/nepalprabin\"\\n  ],\\n  \"created_at\": \"2025-03-05T17:55:28.336760\",\\n  \"sections\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m[\\n    {\\n      \"title\": \"whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main \\\\u00b7 \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mnepalprabin/whisper-webapp \\\\u00b7 GitHub\",\\n      \"url\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip\",\\n      \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"relevance_score\": 0.24178938567638397,\\n      \"content\": [\\n        \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main \\\\u00b7 nepalprabin/whisper-webapp \\\\u00b7 \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mGitHub\\\\nSkip to content\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msigned out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched accounts on another tab or \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mwindow.\\\\nReload\\\\nto refresh your session.\\\\nDismiss \u001b[0m\n",
       "\u001b[1;38;2;212;183;2malert\\\\nnepalprabin\\\\n/\\\\nwhisper-webapp\\\\nPublic\\\\nNotifications\\\\nYou must be signed in to change notification \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msettings\\\\nFork\\\\n0\\\\nStar\\\\n0\\\\nFiles\\\\nmain\\\\n/\\\\nStanford_NLP_lecture_transcripts.zip\\\\nCopy path\\\\nLatest \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcommit\\\\nHistory\\\\nHistory\\\\n1.99 MB\\\\nmain\\\\n/\\\\nStanford_NLP_lecture_transcripts.zip\\\\nTop\\\\nFile metadata and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcontrols\\\\nCode\\\\nBlame\\\\n1.99 MB\\\\nRaw\\\\nView raw\\\\nYou can\\\\u2019t perform that action at this time.\"\\n      ]\\n \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m},\\n    {\\n      \"title\": \"Text Summarization NLP \\\\u2013 Prabin Nepal\",\\n      \"url\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html\",\\n      \"relevance_score\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m0.23108184337615967,\\n      \"content\": [\\n        \"Text Summarization NLP \\\\u2013 Prabin Nepal\\\\nWhat is text \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msummarization?\\\\nText summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mshortened automatically while holding the same semantic meaning. Summarization process generates short, fluent and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2maccurate summary of the long documents. The main idea of text summarization is to find the subset of the most \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mimportant information from the entire document and present it in a human readable format. Text summarization has \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mits application in other NLP tasks such as Question Answering (QA), Text Classification, Text Generation and other \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfields.\\\\nTypes of summarization\\\\nBased on how the texts are extracted from the documents, the summarization \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mprocess can be divided into two types: extractive summarization and abstractive summarization.\\\\nExtractive \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mSummarization\\\\nExtractive summarization picks up the most important sentences directly from the documents and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mforms a coherent summary. This is done using a scoring function. Extractive summarization takes a sentence as an \u001b[0m\n",
       "\u001b[1;38;2;212;183;2minput and produces a probability vector as the output. This probability vector represents the probability of a \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msentence being included in the summary.\\\\nImplementing extractive summarization based on word frequency\\\\nWe can \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mimplement extractive summarization using word frequency in five simple steps:\\\\na. Creating word frequency \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtable\\\\nWe count the frequency of the words present in the text and create a frequency table which is a dictionary \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mto store the count. While creating the frequency table, we do not account for the stop words present in the text \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand remove those words.\\\\ndef\\\\nfrequency_table(text):\\\\n# all unique stopwords of \u001b[0m\n",
       "\u001b[1;38;2;212;183;2menglish\\\\nstop_words\\\\n=\\\\nset\\\\n(stopwords.words(\\\\n\\\\\"english\\\\\"\\\\n))\\\\nwords\\\\n=\\\\nword_tokenize(text)\\\\nfreq_ta\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mble\\\\n=\\\\ndict\\\\n()\\\\n# creating frequency table to keep the count of each \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mword\\\\nfor\\\\nword\\\\nin\\\\nwords:\\\\nword\\\\n=\\\\nword.lower()\\\\nif\\\\nword\\\\nin\\\\nstop_words:\\\\ncontinue\\\\nif\\\\nword\\\\ni\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mn\\\\nfreq_table:\\\\nfreq_table[word]\\\\n+=\\\\n1\\\\nelse\\\\n:\\\\nfreq_table[word]\\\\n=\\\\n1\\\\nreturn\\\\nfreq_table\\\\nb. \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mTokenizing the sentences\\\\nHere we tokenize the sentences using NLTK\\\\u2019s sent_tokenize() method. This separates\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mparagraphs into individual \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msentences.\\\\ndef\\\\ntokenize_sentence(text):\\\\nreturn\\\\nsent_tokenize(text)\\\\nc.\\\\u00a0Scoring the sentences using \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mterm frequency\\\\nHere, we score a sentence by its words, by adding frequency of every word present in the sentence \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mexcluding stop words. One downside of this approach is, if the sentence is long, the value of frequency \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mincreases.\\\\ndef\\\\nterm_frequency_score(sentence, freq_table):\\\\n# dictionary to keep the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mscore\\\\nsentence_value\\\\n=\\\\ndict\\\\n()\\\\nfor\\\\nsentence\\\\nin\\\\nsentences:\\\\nfor\\\\nword, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfreq\\\\nin\\\\nfreq_table.items():\\\\nif\\\\nword\\\\nin\\\\nsentence.lower():\\\\nif\\\\nsentence\\\\nin\\\\nsentence_value:\\\\nsente\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mnce_value[sentence]\\\\n+=\\\\nfreq\\\\nelse\\\\n:\\\\nsentence_value[sentence]\\\\n=\\\\nfreq\\\\nreturn\\\\nsentence_value\\\\nd.\\\\u0\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m0a0Finding the threshold score\\\\nAfter calculating the term frequency, we calculate the threshold \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mscore.\\\\ndef\\\\ncalculate_average_score(sentence_value):\\\\n# To compare the sentences within the text, we assign a \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mscore.\\\\nsum_values\\\\n=\\\\n0\\\\nfor\\\\nsentence\\\\nin\\\\nsentence_value:\\\\nsum_values\\\\n+=\\\\nsentence_value[sentence]\\\\n\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m# Calculating average score of the sentence. This average score can be a good \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mthreshold.\\\\naverage\\\\n=\\\\nint\\\\n(sum_values\\\\n/\\\\nlen\\\\n(sentence_value))\\\\nreturn\\\\naverage\\\\ne. Generating the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msummary based on the threshold value\\\\nBased on the threshold value, we generate the summary of the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtext.\\\\ndef\\\\ncreate_summary(sentences, sentence_value, threshold):\\\\n# Applying the threshold value and storing \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msentences in an order into the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msummary.\\\\nsummary\\\\n=\\\\n\\'\\'\\\\nfor\\\\nsentence\\\\nin\\\\nsentences:\\\\nif\\\\n(sentence\\\\nin\\\\nsentence_value)\\\\nand\\\\n(s\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mentence_value[sentence]\\\\n>\\\\n(\\\\n1.2\\\\n*\\\\nthreshold)):\\\\nsummary\\\\n+=\\\\n\\\\\" \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\\\\\"\\\\n+\\\\nsentence\\\\nreturn\\\\nsummary\\\\nAbstractive Summarization\\\\nIn abstractive summarization, the model forms \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mits own phrases and sentences to provide a consistent summary. Abstractive summarization does not simply copy the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msentences to form the summary but create new phrases that are relevant to the original document. This summarization\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtechnique uses deep learning techniques (like seq2seq) to paraphrase and shorten the original \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdocument.\\\\nAbstractive Summarization using Transformers\\\\nTransformers is an architecture which uses attention \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmechanisms to solve sequence to sequence problems while solving long term dependencies. Ever since it was \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mintroduced in 2017, transformers have been widely used in various NLP tasks such as text generation, question \u001b[0m\n",
       "\u001b[1;38;2;212;183;2manswering, text classification, language translation and so on. The transformer architecture consists of encoder \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand decoder parts. The encoder component consists of 6 encoders each of which consists of two sub layers: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mself-attention and feed forward networks. The input text is first converted into vectors using text embedding \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmethods. Then the vector is passed into the self attention layer and the output from the self attention layer is \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mpassed through the feed forward network. The decoder also consists of both self attention and feed forward network \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlayer. An additional layer is present in between these components which is an attention layer that helps the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdecoder to focus on the relevant parts of the input sentence.\\\\nFig. Transformer architecture (from original \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mpaper)\\\\nHuggingface Transformers provide various pre-trained models to perform NLP tasks. It provides APIs and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtools to download and train state-of-the-art pre-trained models. Not only NLP, huggingface supports Computer Vision\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtasks like image classification, object detection and segmentation, audio classification and recognition, and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmultimodal tasks like table question answering, optical character recognition, and many more.\\\\nBasic transformer \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mpipeline fo\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m..._This content has been truncated to stay below 20000 characters_...\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mrate predictions in many different languages. However, the increased capabilities of GPT-4 also present new risks, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mwhich require significant work to understand and improve its safety and alignment. Nevertheless, GPT-4 marks a \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msignificant milestone towards the development of broadly useful and safely deployed AI \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msystems.\\\\nReferences:\\\\nGPT-4 Technical Report\\\\nGPT-4 Blog Post\\\\nchat.openai.com\\\\nPS\\\\nWhile GPT-4 may have \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mstolen the headlines, it was not the only new technology on display. AnthropicAI unveiled\\\\nClaude\\\\n, next gen AI \u001b[0m\n",
       "\u001b[1;38;2;212;183;2massistant can help with use cases including summarization, search, creative and collaborative writing, Q&A, coding,\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand more. Meanwhile, Google AI released\\\\nPaLM\\\\n, an entry point for Google\\\\u2019s large language models with \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mvariety of applications. With these three new systems, the future of AI looks brighter than ever before.\"\\n      \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m]\\n    },\\n    {\\n      \"title\": \"Collections \\\\u00b7 GitHub\",\\n      \"url\": \"https://github.com/collections\",\\n   \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"relevance_score\": 0.10756564885377884,\\n      \"content\": [\\n        \"Collections \\\\u00b7 GitHub\\\\nSkip to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcontent\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou signed out in another\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched accounts on another tab or window.\\\\nReload\\\\nto \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mrefresh your session.\\\\nDismiss alert\\\\nCollections\\\\nCurated lists and insight into burgeoning industries, topics,\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand communities.\\\\n#\\\\nGame Engines\\\\nFrameworks for building games across multiple platforms.\\\\nLearn to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mCode\\\\nResources to help people learn to code\\\\nPixel Art Tools\\\\nCreating pixel art for fun or animated sprites \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfor a game? The digital artist in you will love these apps and tools!\\\\n#\\\\nHow to choose (and contribute to) your \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfirst open source project\\\\nNew to open source? Here\\\\u2019s how to find projects that need help and start making \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mimpactful contributions.\\\\n#\\\\nClean code linters\\\\nMake sure your code matches your style guide with these \u001b[0m\n",
       "\u001b[1;38;2;212;183;2messential code linters.\\\\n#\\\\nOpen journalism\\\\nSee how publications and data-driven journalists use open source to\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mpower their newsroom and ensure information is reported fairly and accurately.\\\\n#\\\\nDesign essentials\\\\nThis \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcollection of design libraries are the best on the web, and will complete your toolset for designing stunning \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mproducts.\\\\n#\\\\nMusic\\\\nDrop the code bass with these musically themed repositories.\\\\nGovernment apps\\\\nSites, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mapps, and tools built by governments across the world to make government work better, together. Read more at \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mhttps://government.github.com\\\\n#\\\\nDevOps tools\\\\nThese tools help you manage servers and deploy happier and more \u001b[0m\n",
       "\u001b[1;38;2;212;183;2moften with more confidence.\\\\n#\\\\nFront-end JavaScript frameworks\\\\nWhile the number of ways to organize JavaScript\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mis almost infinite, here are some tools that help you build single-page applications.\\\\n#\\\\nGitHub Browser \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mExtensions\\\\nSome useful and fun browser extensions to personalize your GitHub browser experience.\\\\nGitHub Pages \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mexamples\\\\nFine examples of projects using GitHub Pages (https://pages.github.com).\\\\nHacking Minecraft\\\\nMinecraft\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mis a game about building blocks, but it doesn\\\\u2019t end there. Take Minecraft further with some of the projects \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mbelow, or dive into the code mines and hammer your own!\\\\n#\\\\nJavaScript Game Engines\\\\nLearn or level up your 1337\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mgamedev skills and build amazing games together for web, desktop, or mobile using these HTML5 / JavaScript game \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mengines.\\\\nLearn to Code\\\\nResources to help people learn to code\\\\n#\\\\nGetting started with machine \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlearning\\\\nToday, machine learning\\\\u2014the study of algorithms that make data-based predictions\\\\u2014has found a\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mnew audience and a new set of possibilities.\\\\nMade in Africa\\\\nDevelopers in Africa use open source technology to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msolve some of the world\\'s most intractable problems and grow their business ecosystems. Here\\'s a snapshot of \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlocal projects across the continent.\\\\nNet neutrality\\\\nSoftware, research, and organizations protecting the free \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand open internet.\\\\n#\\\\nOpen data\\\\nExamples of using GitHub to store, publish, and collaborate on open, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmachine-readable datasets\\\\nOpen source organizations\\\\nA showcase of organizations showcasing their open source \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mprojects.\\\\n#\\\\nPolicies\\\\nFrom federal governments to corporations to student clubs, groups of all sizes are using\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mGitHub to share, discuss, and improve laws. *Ask not what the repository can do for you...*\\\\n#\\\\nSoftware \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mproductivity tools\\\\nBuild software faster with fewer headaches, using these tools and tricks.\\\\nLoad \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmore\\\\u2026\\\\nYou can\\\\u2019t perform that action at this time.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"GitHub \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mCode Review \\\\u00b7 GitHub\",\\n      \"url\": \"https://github.com/features/code-review\",\\n      \"relevance_score\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m0.10641869902610779,\\n      \"content\": [\\n        \"GitHub Code Review \\\\u00b7 GitHub\\\\nSkip to content\\\\nGitHub \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mCopilot is now available for free.\\\\nLearn more\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto refresh \u001b[0m\n",
       "\u001b[1;38;2;212;183;2myour session.\\\\nYou signed out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched \u001b[0m\n",
       "\u001b[1;38;2;212;183;2maccounts on another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nDismiss alert\\\\nCode Review\\\\nWrite better\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcode\\\\nOn GitHub, lightweight code review tools are built into every pull request. Your team can create review \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mprocesses that improve the quality of your code and fit neatly into your workflow.\\\\nGet started\\\\nContact \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msales\\\\nEvery change starts with a pull request.\\\\nLearn pull request fundamentals\\\\nStart a new feature or propose\u001b[0m\n",
       "\u001b[1;38;2;212;183;2ma change to existing code with a pull request\\\\n\\\\u2014a base for your team to coordinate details and refine your \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mchanges.\\\\nPull requests are fundamental to how teams review and improve code on GitHub\\\\n. Evolve projects, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mpropose new features, and discuss implementation details before changing your source code.\\\\nDiffs\\\\nPreview \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mchanges in context with your code to see what is being proposed. Side-by-side Diffs highlight added, edited, and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdeleted code right next to the original file, so you can easily spot changes.\\\\nLearn more\\\\nHistory\\\\nBrowse \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcommits, comments, and references related to your pull request in a timeline-style interface. Your pull request \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mwill also highlight what\\\\u2019s changed since you last checked.\\\\nLearn more\\\\nBlame\\\\nSee what a file looked like\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mbefore a particular change. With blame view, you can see how any portion of your file has evolved over time without\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mviewing the file\\\\u2019s full history.\\\\nLearn more\\\\nComments\\\\nOn GitHub, conversations happen alongside your \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcode. Leave detailed comments on code syntax and ask questions about structure inline.\\\\nReview requests\\\\nIf \u001b[0m\n",
       "\u001b[1;38;2;212;183;2myou\\\\u2019re on the other side of the code, requesting peer reviews is easy. Add users to your pull request, and \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mthey\\\\u2019ll receive a notification letting them know you need their feedback.\\\\nReviews\\\\nSave your teammates a \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfew notifications. Bundle your comments into one cohesive review, then specify whether comments are required \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mchanges or just suggestions.\\\\nResolve simple conflicts\\\\nYou can\\\\u2019t always avoid conflict. Merge pull \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mrequests faster by resolving simple merge conflicts on GitHub\\\\u2014no command line necessary.\\\\nLearn how to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mresolve merge conflicts\\\\nFast, relevant results\\\\nGive collaborators as much access as they need through your \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mrepository settings. You can extend access to a few teams and select which ones can read or write to your files. \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mThe options you have for permissions depend on your plan.\\\\nSee plan options\\\\nProtected branches\\\\nProtected \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mBranches help you maintain the integrity of your code. Limit who can push to a branch, and disable force pushes to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mspecific branches. Then scale your policies with the Protected Branches API.\\\\nLearn more\\\\nRequired status \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mchecks\\\\nCreate required status checks to add an extra layer of error prevention on branches. Use the Status API to\u001b[0m\n",
       "\u001b[1;38;2;212;183;2menforce checks and disable the merge button until they pass. To err is human; to automate, divine!\\\\nStatus API \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdoc\\\\nEvery change starts with a pull request.\\\\nGet started\\\\nContact sales\\\\nYou can\\\\u2019t perform that action \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mat this time.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"GitHub - nepalprabin/nepalprabin\",\\n      \"url\": \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"https://github.com/nepalprabin/nepalprabin\",\\n      \"relevance_score\": 0.10383956879377365,\\n      \"content\": [\\n \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\"GitHub - nepalprabin/nepalprabin\\\\nSkip to content\\\\nYou signed in with another tab or window.\\\\nReload\\\\nto \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mrefresh your session.\\\\nYou signed out in another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nYou switched\u001b[0m\n",
       "\u001b[1;38;2;212;183;2maccounts on another tab or window.\\\\nReload\\\\nto refresh your session.\\\\nDismiss \u001b[0m\n",
       "\u001b[1;38;2;212;183;2malert\\\\nnepalprabin\\\\n/\\\\nnepalprabin\\\\nPublic\\\\nNotifications\\\\nYou must be signed in to change notification \u001b[0m\n",
       "\u001b[1;38;2;212;183;2msettings\\\\nFork\\\\n0\\\\nStar\\\\n0\\\\n0\\\\nstars\\\\n0\\\\nforks\\\\nBranches\\\\nTags\\\\nActivity\\\\nStar\\\\nNotifications\\\\nYou \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mmust be signed in to change notification settings\\\\nnepalprabin/nepalprabin\\\\nmaster\\\\nBranches\\\\nTags\\\\nGo to \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfile\\\\nCode\\\\nFolders and files\\\\nName\\\\nName\\\\nLast commit message\\\\nLast commit date\\\\nLatest \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcommit\\\\nHistory\\\\n14 Commits\\\\nREADME.md\\\\nREADME.md\\\\nView all files\\\\nRepository files navigation\\\\nHi \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m\\\\ud83d\\\\udc4b, I\\'m Prabin Nepal\\\\nA passionate software developer\\\\n\\\\ud83c\\\\udf31 I\\\\u2019m currently \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlearning\\\\nDeep Learning for Computer Vision and NLP\\\\n\\\\ud83d\\\\udcac Ask me about\\\\nFull Stack Development, Deep \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mLearning\\\\n\\\\ud83d\\\\udceb How to reach me\\\\nprabinnepal1996@gmail.com\\\\nAbout\\\\nNo description, website, or topics \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mprovided.\\\\nResources\\\\nReadme\\\\nActivity\\\\nStars\\\\n0\\\\nstars\\\\nWatchers\\\\n1\\\\nwatching\\\\nForks\\\\n0\\\\nforks\\\\nRepor\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mt repository\\\\nReleases\\\\nNo releases published\\\\nPackages\\\\n0\\\\nNo packages published\\\\nYou can\\\\u2019t perform \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mthat action at this time.\"\\n      ]\\n    }\\n  ]\\n}', 'format': 'json', 'metadata': {'prompt': 'Extract all the blog\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcontents based on this prompt', 'sources': 38, 'created_at': '2025-03-05T17:55:28.338272'}}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 5: Duration 8.04 seconds| Input tokens: 109,917 | Output tokens: 963]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 5: Duration 8.04 seconds| Input tokens: 109,917 | Output tokens: 963]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instructions = \"Extract all the blog contents\"\n",
    "documents = client.scrape(instructions, \"https://nepalprabin.github.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub', 'url': 'https://github.com/nepalprabin/whisper-webapp/blob/main/Stanford_NLP_lecture_transcripts.zip', 'relevance_score': 0.24178938567638397, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='whisper-webapp/Stanford_NLP_lecture_transcripts.zip at main · nepalprabin/whisper-webapp · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\n/\\nwhisper-webapp\\nPublic\\nNotifications\\nYou must be signed in to change notification settings\\nFork\\n0\\nStar\\n0\\nFiles\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nCopy path\\nLatest commit\\nHistory\\nHistory\\n1.99 MB\\nmain\\n/\\nStanford_NLP_lecture_transcripts.zip\\nTop\\nFile metadata and controls\\nCode\\nBlame\\n1.99 MB\\nRaw\\nView raw\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Text Summarization NLP – Prabin Nepal', 'url': 'https://nepalprabin.github.io/posts/2022-10-19-text-summarization-nlp.html', 'relevance_score': 0.23108184337615967, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Text Summarization NLP – Prabin Nepal\\nWhat is text summarization?\\nText summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened automatically while holding the same semantic meaning. Summarization process generates short, fluent and accurate summary of the long documents. The main idea of text summarization is to find the subset of the most important information from the entire document and present it in a human readable format. Text summarization has its application in other NLP tasks such as Question Answering (QA), Text Classification, Text Generation and other fields.\\nTypes of summarization\\nBased on how the texts are extracted from the documents, the summarization process can be divided into two types: extractive summarization and abstractive summarization.\\nExtractive Summarization\\nExtractive summarization picks up the most important sentences directly from the documents and forms a coherent summary. This is done using a scoring function. Extractive summarization takes a sentence as an input and produces a probability vector as the output. This probability vector represents the probability of a sentence being included in the summary.\\nImplementing extractive summarization based on word frequency\\nWe can implement extractive summarization using word frequency in five simple steps:\\na. Creating word frequency table\\nWe count the frequency of the words present in the text and create a frequency table which is a dictionary to store the count. While creating the frequency table, we do not account for the stop words present in the text and remove those words.\\ndef\\nfrequency_table(text):\\n# all unique stopwords of english\\nstop_words\\n=\\nset\\n(stopwords.words(\\n\"english\"\\n))\\nwords\\n=\\nword_tokenize(text)\\nfreq_table\\n=\\ndict\\n()\\n# creating frequency table to keep the count of each word\\nfor\\nword\\nin\\nwords:\\nword\\n=\\nword.lower()\\nif\\nword\\nin\\nstop_words:\\ncontinue\\nif\\nword\\nin\\nfreq_table:\\nfreq_table[word]\\n+=\\n1\\nelse\\n:\\nfreq_table[word]\\n=\\n1\\nreturn\\nfreq_table\\nb. Tokenizing the sentences\\nHere we tokenize the sentences using NLTK’s sent_tokenize() method. This separates paragraphs into individual sentences.\\ndef\\ntokenize_sentence(text):\\nreturn\\nsent_tokenize(text)\\nc.\\xa0Scoring the sentences using term frequency\\nHere, we score a sentence by its words, by adding frequency of every word present in the sentence excluding stop words. One downside of this approach is, if the sentence is long, the value of frequency increases.\\ndef\\nterm_frequency_score(sentence, freq_table):\\n# dictionary to keep the score\\nsentence_value\\n=\\ndict\\n()\\nfor\\nsentence\\nin\\nsentences:\\nfor\\nword, freq\\nin\\nfreq_table.items():\\nif\\nword\\nin\\nsentence.lower():\\nif\\nsentence\\nin\\nsentence_value:\\nsentence_value[sentence]\\n+=\\nfreq\\nelse\\n:\\nsentence_value[sentence]\\n=\\nfreq\\nreturn\\nsentence_value\\nd.\\xa0Finding the threshold score\\nAfter calculating the term frequency, we calculate the threshold score.\\ndef\\ncalculate_average_score(sentence_value):\\n# To compare the sentences within the text, we assign a score.\\nsum_values\\n=\\n0\\nfor\\nsentence\\nin\\nsentence_value:\\nsum_values\\n+=\\nsentence_value[sentence]\\n# Calculating average score of the sentence. This average score can be a good threshold.\\naverage\\n=\\nint\\n(sum_values\\n/\\nlen\\n(sentence_value))\\nreturn\\naverage\\ne. Generating the summary based on the threshold value\\nBased on the threshold value, we generate the summary of the text.\\ndef\\ncreate_summary(sentences, sentence_value, threshold):\\n# Applying the threshold value and storing sentences in an order into the summary.\\nsummary\\n=\\n\\'\\'\\nfor\\nsentence\\nin\\nsentences:\\nif\\n(sentence\\nin\\nsentence_value)\\nand\\n(sentence_value[sentence]\\n>\\n(\\n1.2\\n*\\nthreshold)):\\nsummary\\n+=\\n\" \"\\n+\\nsentence\\nreturn\\nsummary\\nAbstractive Summarization\\nIn abstractive summarization, the model forms its own phrases and sentences to provide a consistent summary. Abstractive summarization does not simply copy the sentences to form the summary but create new phrases that are relevant to the original document. This summarization technique uses deep learning techniques (like seq2seq) to paraphrase and shorten the original document.\\nAbstractive Summarization using Transformers\\nTransformers is an architecture which uses attention mechanisms to solve sequence to sequence problems while solving long term dependencies. Ever since it was introduced in 2017, transformers have been widely used in various NLP tasks such as text generation, question answering, text classification, language translation and so on. The transformer architecture consists of encoder and decoder parts. The encoder component consists of 6 encoders each of which consists of two sub layers: self-attention and feed forward networks. The input text is first converted into vectors using text embedding methods. Then the vector is passed into the self attention layer and the output from the self attention layer is passed through the feed forward network. The decoder also consists of both self attention and feed forward network layer. An additional layer is present in between these components which is an attention layer that helps the decoder to focus on the relevant parts of the input sentence.\\nFig. Transformer architecture (from original paper)\\nHuggingface Transformers provide various pre-trained models to perform NLP tasks. It provides APIs and tools to download and train state-of-the-art pre-trained models. Not only NLP, huggingface supports Computer Vision tasks like image classification, object detection and segmentation, audio classification and recognition, and multimodal tasks like table question answering, optical character recognition, and many more.\\nBasic transformer pipeline for summarization\\nHuggingface transformers provide an easy to use model for inference using pipeline. These pipelines are the objects that hide complex code and provide a simple API to perform various tasks.\\nfrom\\ntransformers\\nimport\\npipeline\\nclassifier\\n=\\npipeline(\\n\"summarization\"\\n)\\ntext\\n=\\n\"\"\"Acnesol Gel is an antibiotic that fights bacteria. It is used to treat acne, which appears as spots or pimples on your face, chest or back. This medicine works by attacking the bacteria that cause these pimples.Acnesol Gel is only meant for external use and should be used as advised by your doctor. You should normally wash and dry the affected area before applying a thin layer of the medicine. It should not be applied to broken or damaged skin.  Avoid any contact with your eyes, nose, or mouth. Rinse it off with water if you accidentally get it in these areas. It may take several weeks for your symptoms to improve, but you should keep using this medicine regularly. Do not stop using it as soon as your acne starts to get better. Ask your doctor when you should stop treatment. Common side effects like minor itching, burning, or redness of the skin and oily skin may be seen in some people. These are usually temporary and resolve on their own. Consult your doctor if they bother you or do not go away.It is a safe medicine, but you should inform your doctor if you have any problems with your bowels (intestines). Also, inform the doctor if you have ever had bloody diarrhea caused by taking antibiotics or if you are using any other medicines to treat skin conditions. Consult your doctor about using this medicine if you are pregnant or breastfeeding.\"\"\"\\nclassifier(text)\\nResult:\\n[{\\n\\'summary_text\\'\\n:\\n\\' Acnesol Gel is an antibiotic that fights bacteria that causes pimples . It is used to treat acne, which appears as spots or pimples on your face, chest or back . The medicine is only meant for external use and should be used as advised by your doctor .\\'\\n}]\\nThe\\npipeline()\\ntakes the name of the task to be performed (if we want to perform a question-answering task, then we can simply pass “question-answering” into the pipeline() and it automatically loads the model to perform the specific task.\\nFine-tuning summarization model for medical dataset\\nSummarization using abstractive technique is hard as compared to extractive summarization as we need to generate new text as the output. Different architectures like GTP, T5, BART are used to perform summarization tasks. We will be using the PubMed dataset. It contains datasets of long and structured documents obtained from PubMed OpenAccess repositories. from datasets import load_dataset\\npubmed\\n=\\nload_dataset(\\n\"ccdv/pubmed-summarization\"\\n)\\nThe PubMed dataset contains article, abstract and section_names as columns. The first step after loading the dataset is tokenizing the training data. Tokenization is the process of splitting paragraphs, sentences into smaller units called tokens. tokenizer = AutoTokenizer.from_pretrained(‘facebook/bart-large-cnn’)\\nThe next step is to preprocess the data. Before training the data, we need to convert our data into expected model input format.\\ndef\\npreprocess_function(examples):\\ninputs\\n=\\n[doc\\nfor\\ndoc\\nin\\nexamples[\\n\"article\"\\n]]\\nmodel_inputs\\n=\\ntokenizer(inputs, max_length\\n=\\n1024\\n, truncation\\n=\\nTrue\\n)\\nlabels\\n=\\ntokenizer(examples[\\n\"abstract\"\\n], max_length\\n=\\n128\\n, truncation\\n=\\nTrue\\n, padding\\n=\\nTrue\\n)\\nmodel_inputs[\\n\"labels\"\\n]\\n=\\nlabels[\\n\"input_ids\"\\n]\\nreturn\\nmodel_inputs\\nWe need to apply the processing function over the entire dataset. Setting flag\\nbatched=True\\nhelps to speed up the processing of multiple elements of the dataset at once.\\ntokenized_pubmed\\n=\\npubmed.\\nmap\\n(preprocess_function, batched\\n=\\nTrue\\n)\\nNext, we need to create a batch for all the examples. Huggingface provides a data collator to create a batch for the examples.\\ntokenized_datasets\\n=\\ntokenized_pubmed.remove_columns(pubmed[\\n\"train\"\\n].column_names)\\ndata_collator\\n=\\nDataCollatorForSeq2Seq(tokenizer\\n=\\ntokenizer, model\\n=\\n\"facebook/bart-large-cnn\"\\n)\\nHuggingface provides various pre-trained models that we can leverage to perform a variety of machine learning tasks.\\nmodel\\n=\\nAutoModelForSeq2SeqLM.from_pretrained(model)\\nBefore training the model, we need to define our training hyperparamaters using training arguments. Since text summarization is a sequence to sequence tasks, we are using Seq2SeqTrainingArguments. And, we need to define our trainer by passing training and test dataset along with training arguments.\\n# training arguments\\ntraining_arguments\\n=\\nSeq2SeqTrainingArguments(\\noutput_dir\\n=\\n\\'./results\\'\\n,\\nevaluation_strategy\\n=\\n\\'epoch\\'\\n,\\nlearning_rate\\n=\\n2e-5\\n,\\nper_device_train_batch_size\\n=\\n8\\n,\\nper_device_eval_batch_size\\n=\\n8\\n,\\nweight_decay\\n=\\n0.01\\n,\\nsave_total_limit\\n=\\n3\\n,\\nnum_train_epochs\\n=\\n3\\n,\\n# remove_unused_columns=False,\\n# fp16=True,\\n)\\ntrainer\\n=\\nSeq2SeqTrainer(\\nmodel\\n=\\nmodel,\\nargs\\n=\\ntraining_arguments,\\ntrain_dataset\\n=\\ntokenized_pubmed[\\n\\'train\\'\\n],\\neval_dataset\\n=\\ntokenized_pubmed[\\n\\'validation\\'\\n],\\ntokenizer\\n=\\ntokenizer,\\ndata_collator\\n=\\ndata_collator\\n)\\nThe last step is to call\\ntrain()\\nto fine-tune our model.\\ntrainer.train()\\nConclusion\\nSummarization helps to generalize the long documents by paraphrasing the important sentences from the whole document. It is very helpful in various applications like summarizing legal contracts, medical documents, news information and many more.'),\n",
       " Document(metadata={'title': 'GitHub - nepalprabin/deeplearning-paper-implementation', 'url': 'https://github.com/nepalprabin/deeplearning-paper-implementation', 'relevance_score': 0.2060489058494568, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub - nepalprabin/deeplearning-paper-implementation\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\n/\\ndeeplearning-paper-implementation\\nPublic\\nNotifications\\nYou must be signed in to change notification settings\\nFork\\n1\\nStar\\n3\\n3\\nstars\\n1\\nfork\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed in to change notification settings\\nnepalprabin/deeplearning-paper-implementation\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n13 Commits\\nAlexNet\\nAlexNet\\nGoogLeNet\\nGoogLeNet\\nR-CNN\\nR-CNN\\nStyleTransfer\\nStyleTransfer\\nU-Net\\nU-Net\\nVGGNet\\nVGGNet\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\ndeeplearning-architecture\\nI am trying to keep record of research papers that I have read or trying to read so far.\\nResearch Papers\\nLink\\nImageNet Classification with Deep Convolutional Neural Networks (AlexNet)\\nhttps://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\\nVery Deep Convolutional Networks for Large-scale Image Recognition(VGGNet)\\nhttps://arxiv.org/pdf/1409.1556.pdf\\nGoing Deeper with Convolutions (GoogLeNet)\\nhttps://arxiv.org/abs/1409.4842\\nRich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)\\nhttps://arxiv.org/abs/1311.2524\\nU-Net: Convolutional Networks for Biomedical Image Segmentation\\nhttps://arxiv.org/abs/1505.04597\\nA Neural Algorithm of Artistic Style\\nhttps://arxiv.org/abs/1508.06576\\nGenerative Adversarial Networks\\nhttps://arxiv.org/abs/1406.2661\\nConditional Generative Adversarial Nets\\nhttps://arxiv.org/abs/1411.1784\\nUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)\\nhttps://arxiv.org/abs/1511.06434\\nImage-to-Image Translation with Conditional Adversarial Networks (pix2pix)\\nhttps://arxiv.org/abs/1611.07004\\nUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)\\nhttps://arxiv.org/abs/1703.10593\\nMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\\nhttps://arxiv.org/abs/1704.04861\\nAbout\\nNo description, website, or topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n3\\nstars\\nWatchers\\n2\\nwatching\\nForks\\n1\\nfork\\nReport repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nJupyter Notebook\\n100.0%\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Understanding GitHub Code Search syntax - GitHub Docs', 'url': 'https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax', 'relevance_score': 0.20305627584457397, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Understanding GitHub Code Search syntax - GitHub Docs\\nSkip to main content\\nUnderstanding GitHub Code Search syntax\\nYou can build search queries for the results you want with specialized code qualifiers, regular expressions, and boolean operations.\\nIn this article\\nAbout code search query structure\\nThe search syntax in this article only applies to searching code with GitHub code search. Note that the syntax and qualifiers for searching for non-code content, such as issues, users, and discussions, is not the same as the syntax for code search. For more information on non-code search, see\\nAbout searching on GitHub\\nand\\nSearching on GitHub\\n.\\nSearch queries consist of search terms, comprising text you want to search for, and qualifiers, which narrow down the search.\\nA bare term with no qualifiers will match either the content of a file or the file\\'s path.\\nFor example, the following query:\\nhttp-push\\nThe above query will match the file\\ndocs/http-push.txt\\n, even if it doesn\\'t contain the term\\nhttp-push\\n. It will also match a file called\\nexample.txt\\nif it contains the term\\nhttp-push\\n.\\nYou can enter multiple terms separated by whitespace to search for documents that satisfy both terms.\\nFor example, the following query:\\nsparse index\\nThe search results would include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order. As examples, it would match a file containing\\nSparseIndexVector\\n, a file with the phrase\\nindex for sparse trees\\n, and even a file named\\nindex.txt\\nthat contains the term\\nsparse\\n.\\nSearching for multiple terms separated by whitespace is the equivalent to the search\\nhello AND world\\n. Other boolean operations, such as\\nhello OR world\\n, are also supported. For more information about boolean operations, see\\nUsing boolean operations\\n.\\nCode search also supports searching for an exact string, including whitespace. For more information, see\\nQuery for an exact match\\n.\\nYou can narrow your code search with specialized qualifiers, such as\\nrepo:\\n,\\nlanguage:\\nand\\npath:\\n. For more information on the qualifiers you can use in code search, see\\nUsing qualifiers\\n.\\nYou can also use regular expressions in your searches by surrounding the expression in slashes. For more information on using regular expressions, see\\nUsing regular expressions\\n.\\nQuery for an exact match\\nTo search for an exact string, including whitespace, you can surround the string in quotes. For example:\\n\"sparse index\"\\nYou can also use quoted strings in qualifiers, for example:\\npath:git language:\"protocol buffers\"\\nSearching for quotes and backslashes\\nTo search for code containing a quotation mark, you can escape the quotation mark using a backslash. For example, to find the exact string\\nname = \"tensorflow\"\\n, you can search:\\n\"name = \\\\\"tensorflow\\\\\"\"\\nTo search for code containing a backslash,\\n\\\\\\n, use a double backslash,\\n\\\\\\\\\\n.\\nThe two escape sequences\\n\\\\\\\\\\nand\\n\\\\\"\\ncan be used outside of quotes as well. No other escape sequences are recognized, though. A backslash that isn\\'t followed by either\\n\"\\nor\\n\\\\\\nis included in the search, unchanged.\\nAdditional escape sequences, such as\\n\\\\n\\nto match a newline character, are supported in regular expressions. See\\nUsing regular expressions\\n.\\nUsing boolean operations\\nCode search supports boolean expressions. You can use the operators\\nAND\\n,\\nOR\\n, and\\nNOT\\nto combine search terms.\\nBy default, adjacent terms separated by whitespace are equivalent to using the\\nAND\\noperator. For example, the search query\\nsparse index\\nis the same as\\nsparse AND index\\n, meaning that the search results will include all documents containing both the terms\\nsparse\\nand\\nindex\\n, in any order.\\nTo search for documents containing either one term or the other, you can use the\\nOR\\noperator. For example, the following query will match documents containing either\\nsparse\\nor\\nindex\\n:\\nsparse OR index\\nTo exclude files from your search results, you can use the\\nNOT\\noperator. For example, to exclude files in the\\n__testing__\\ndirectory, you can search:\\n\"fatal error\" NOT path:__testing__\\nYou can use parentheses to express more complicated boolean expressions. For example:\\n(language:ruby OR language:python) AND NOT path:\"/tests/\"\\nUsing qualifiers\\nYou can use specialized keywords to qualify your search.\\nRepository qualifier\\nOrganization and user qualifiers\\nLanguage qualifier\\nPath qualifier\\nSymbol qualifier\\nContent qualifier\\nIs qualifier\\nRepository qualifier\\nTo search within a repository, use the\\nrepo:\\nqualifier. You must provide the full repository name, including the owner. For example:\\nrepo:github-linguist/linguist\\nTo search within a set of repositories, you can combine multiple\\nrepo:\\nqualifiers with the boolean operator\\nOR\\n. For example:\\nrepo:github-linguist/linguist OR repo:tree-sitter/tree-sitter\\nNote\\nCode search does not currently support regular expressions or partial matching for repository names, so you will have to type the entire repository name (including the user prefix) for the\\nrepo:\\nqualifier to work.\\nOrganization and user qualifiers\\nTo search for files within an organization, use the\\norg:\\nqualifier. For example:\\norg:github\\nTo search for files within a personal account, use the\\nuser:\\nqualifier. For example:\\nuser:octocat\\nNote\\nCode search does not currently support regular expressions or partial matching for organization or user names, so you will have to type the entire organization or user name for the qualifier to work.\\nLanguage qualifier\\nTo narrow down to a specific languages, use the\\nlanguage:\\nqualifier. For example:\\nlanguage:ruby OR language:cpp OR language:csharp\\nFor a complete list of supported language names, see\\nlanguages.yaml\\nin\\ngithub-linguist/linguist\\n. If your preferred language is not on the list, you can open a pull request to add it.\\nPath qualifier\\nTo search within file paths, use the\\npath:\\nqualifier. This will match files containing the term anywhere in their file path. For example, to find files containing the term\\nunit_tests\\nin their path, use:\\npath:unit_tests\\nThe above query will match both\\nsrc/unit_tests/my_test.py\\nand\\nsrc/docs/unit_tests.md\\nsince they both contain\\nunit_test\\nsomewhere in their path.\\nTo match only a specific filename (and not part of the path), you could use a regular expression:\\npath:/(^|\\\\/)README\\\\.md$/\\nNote that the\\n.\\nin the filename is escaped, since\\n.\\nhas special meaning for regular expressions. For more information about using regular expressions, see\\nUsing regular expressions\\n.\\nYou can also use some limited glob expressions in the\\npath:\\nqualifier.\\nFor example, to search for files with the extension\\ntxt\\n, you can use:\\npath:*.txt\\nTo search for JavaScript files within a `src` directory, you could use:\\npath:src/*.js\\nBy default, glob expressions are not anchored to the start of the path, so the above expression would still match a path like\\napp/src/main.js\\n. But if you prefix the expression with\\n/\\n, it will anchor to the start. For example:\\npath:/src/*.js\\nNote that\\n*\\ndoesn\\'t match the\\n/\\ncharacter, so for the above example, all results will be direct descendants of the\\nsrc\\ndirectory. To match within subdirectories, so that results include deeply nested files such as\\n/src/app/testing/utils/example.js\\n, you can use\\n**\\n. For example:\\npath:/src/**/*.js\\nYou can also use the\\n?\\nglobal character. For example, to match the path\\nfile.aac\\nor\\nfile.abc\\n, you can use:\\npath:*.a?c\\nTo search for a filename which contains a special character like `*` or `?`, just use a quoted string:\\npath:\"file?\"\\nGlob expressions are disabled for quoted strings, so the above query will only match paths containing the literal string\\nfile?\\n.\\nSymbol qualifier\\nYou can search for symbol definitions in code, such as function or class definitions, using the\\nsymbol:\\nqualifier. Symbol search is based on parsing your code using the open source\\nTree-sitter\\nparser ecosystem, so no extra setup or build tool integration is required.\\nFor example, to search for a symbol called\\nWithContext\\n:\\nlanguage:go symbol:WithContext\\nIn some languages, you can search for symbols using a prefix (e.g. a prefix of their class name). For example, for a method\\ndeleteRows\\non a struct\\nMaint\\n, you could search\\nsymbol:Maint.deleteRows\\nif you are using Go, or\\nsymbol:Maint::deleteRows\\nin Rust.\\nYou can also use regular expressions with the symbol qualifier. For example, the following query would find conversions people have implemented in Rust for the\\nString\\ntype:\\nlanguage:rust symbol:/^String::to_.*/\\nNote that this qualifier only searches for definitions and not references, and not all symbol types or languages are fully supported yet. Symbol extraction is supported for the following languages:\\nBash\\nC\\nC#\\nC++\\nCodeQL\\nElixir\\nGo\\nJSX\\nJava\\nJavaScript\\nLua\\nPHP\\nProtocol Buffers\\nPython\\nR\\nRuby\\nRust\\nScala\\nStarlark\\nSwift\\nTypescript\\nWe are working on adding support for more languages. If you would like to help contribute to this effort, you can add support for your language in the open source\\nTree-sitter\\nparser ecosystem, upon which symbol search is based.\\nContent qualifier\\nBy default, bare terms search both paths and file content. To restrict a search to strictly match the content of a file and not file paths, use the\\ncontent:\\nqualifier. For example:\\ncontent:README.md\\nThis query would only match files containing the term\\nREADME.md\\n, rather than matching files named\\nREADME.md\\n.\\nIs qualifier\\nTo filter based on repository properties, you can use the\\nis:\\nqualifier.\\nis:\\nsupports the following values:\\narchived\\n: restricts the search to archived repositories.\\nfork\\n: restricts the search to forked repositories.\\nvendored\\n: restricts the search to content detected as vendored.\\ngenerated\\n: restricts the search to content detected as generated.\\nFor example:\\npath:/^MIT.txt$/ is:archived\\nNote that the\\nis:\\nqualifier can be inverted with the\\nNOT\\noperator. To search for non-archived repositories, you can search:\\nlog4j NOT is:archived\\nTo exclude forks from your results, you can search:\\nlog4j NOT is:fork\\nUsing regular expressions\\nCode search supports regular expressions to search for patterns in your code. You can use regular expressions in bare search terms as well as within many qualifiers, by surrounding the regex in slashes.\\nFor example, to search for the regular expression\\nsparse.*index\\n, you would use:\\n/sparse.*index/\\nNote that you\\'ll have to escape any forward slashes within the regular expression. For example, to search for files within the\\nApp/src\\ndirectory, you would use:\\n/^App\\\\/src\\\\//\\nInside a regular expression,\\n\\\\n\\nstands for a newline character,\\n\\\\t\\nstands for a tab, and\\n\\\\x{hhhh}\\ncan be used to escape any Unicode character. This means you can use regular expressions to search for exact strings that contain characters that you can\\'t type into the search bar.\\nMost common regular expressions features work in code search. However, \"look-around\" assertions are not supported.\\nSeparating search terms\\nAll parts of a search, such as search terms, exact strings, regular expressions, qualifiers, parentheses, and the boolean keywords\\nAND\\n,\\nOR\\n, and\\nNOT\\n, must be separated from one another with spaces. The one exception is that items inside parentheses,\\n(\\n)\\n, don\\'t need to be separated from the parentheses.\\nIf your search contains multiple components that aren\\'t separated by spaces, or other text that does not follow the rules listed above, code search will try to guess what you mean. It often falls back on treating that component of your query as the exact text to search for. For example, the following query:\\nprintf(\"hello world\\\\n\");\\nCode search will give up on interpreting the parentheses and quotes as special characters and will instead search for files containing that exact code.\\nIf code search guesses wrong, you can always get the search you wanted by using quotes and spaces to make the meaning clear.\\nCase sensitivity\\nBy default, code search is case-insensitive, and results will include both uppercase and lowercase results. You can do case-sensitive searches by using a regular expression with case insensitivity turned off. For example, to search for the string \"True\", you would use:\\n/(?-i)True/'),\n",
       " Document(metadata={'title': 'FlaskBlog', 'url': 'http://3.14.28.154/', 'relevance_score': 0.19343659281730652, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"FlaskBlog\\nStanford NLP Lectures transcription using Whisper\\nThese are transcripts for Stanford NLP Lectures from\\nthis\\nplaylist. The transcripts are generated using OpenAI's\\nwhisper\\nLectures\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 9 - Self- Attention and Transformers\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 17 - Model Analysis and Explanation\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Spring 2022 ｜ Guest Lecture：  Scaling Language Models\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 13 - Coreference Resolution\\nLink\\n:\\nStanford CS224N - NLP w⧸ DL ｜ Winter 2021 ｜ Lecture 4 - Syntactic Structure and Dependency Parsing\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 10 - Transformers and Pretraining\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 11 - Question Answering\\nLink\\n:\\nStanford CS224N： NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 1 - Intro _ Word Vectors\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 7 - Translation, Seq2Seq, Attention\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 6 - Simple and LSTM RNNs\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 2 - Neural Classifiers\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 16 - Social _ Ethical Considerations\\nLink\\n:\\nStanford CS224N： NLP with Deep Learning ｜ Winter 2020 ｜ Low Resource Machine Translation\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 8 - Final Projects_ Practical Tips\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 14 - T5 and Large Language Models\\nLink\\n:\\nStanford CS224N -  NLP w⧸ DL ｜ Winter 2021 ｜ Lecture 5 - Recurrent Neural networks (RNNs)\\nLink\\n:\\nStanford CS224N： NLP with Deep Learning ｜ Winter 2020 ｜ BERT and Other Pre-trained Language Models\\nLink\\n:\\nStanford CS224N I NLP with Deep Learning ｜ Spring 2022 ｜ Socially Intelligent NLP Systems\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 15 - Add Knowledge to Language Models\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜Spring 2022｜Guest Lecture： Building Knowledge Representation\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 3 - Backprop and Neural Networks\\nLink\\n:\\nStanford CS224N NLP with Deep Learning ｜ Winter 2021 ｜ Lecture 12 - Natural Language Generation\"),\n",
       " Document(metadata={'title': 'Augmenting Large Language Models: Expanding Context and Enhancing Relevance – Prabin Nepal', 'url': 'https://nepalprabin.github.io/posts/2023-07-04-augmented-language-models.html', 'relevance_score': 0.1907445639371872, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Augmenting Large Language Models: Expanding Context and Enhancing Relevance – Prabin Nepal\\nWith the rise of ChatGPT and other large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both fascination and concern. While LLMs excel at understanding language, following instructions, and reasoning, they often fall short when it comes to performing specific tasks. Simply inputting a prompt into ChatGPT may result in answers that are unrelated or out of context, a phenomenon known as “hallucination.” To obtain relevant information, it is crucial to provide the model with the appropriate context. However, the size of the context window is limited, posing a challenge in capturing all necessary information. Although the context size has increased over time, storing extensive information within a fixed context window remains impractical and expensive. This is where the augmentation of language models comes into play.\\nAugmenting large language models involves three primary approaches:\\nretrieval,\\nchains, and\\ntools.\\nThese methods aim to enhance the capabilities of LLMs by providing them with additional resources and functionalities.\\nRetrieval Augmentation:\\nRetrieval augmentation involves leveraging an external corpus of data for the language model to search through. Traditionally, retrieval algorithms employ queries to rank relevant objects in a collection, which can include images, texts, documents, or other types of data. To enable efficient searching, the documents and their corresponding features are organized within an index. This index maps each feature to the documents containing it, facilitating quick retrieval. Boolean search determines the relevance of documents based on the query, while ranking is typically performed using algorithms like BM25 (Best Match 25).\\nBM25 (Best Match 25) is a ranking function commonly used in information retrieval to measure the relevance of a document to a given query. It is a probabilistic retrieval model that enhances the vector space model by incorporating document length normalization and term frequency saturation.\\nIn BM25, the indexing process involves tokenizing each document in the collection into terms and calculating term statistics such as document frequency (df) and inverse document frequency (idf). Document frequency represents the number of documents in the collection containing a particular term, while inverse document frequency measures the rarity of the term across the collection.\\nDuring the querying phase, the query is tokenized into terms, and term statistics, including query term frequency (qtf) and query term inverse document frequency (qidf), are computed. These statistics capture the occurrence and relevance of terms in the query.\\nWhile traditional retrieval methods primarily rely on keyword matching and statistical techniques, modern approaches leverage AI-centric retrieval methods that utilize embeddings. These methods offer improved search capabilities and help retrieve contextually relevant information.\\nChains\\nChains involve using the output of one language model as the input for another. By cascading multiple models together, the output of each model becomes the input for the subsequent one. This chaining process allows the models to build upon each other’s knowledge and reasoning abilities, potentially leading to more accurate and contextually appropriate responses.\\nThe sequential arrangement of models in a chain creates a pipeline of of interconnected language models, where the output of one model serves as the input for the next. This pipeline allows for a cascading flow of information and reasoning, enabling the models to collectively enhance their understanding and generate more accurate responses. By leveraging a chain of language models, each model can contribute its specialized knowledge and capabilities to the overall task. For example, one model may excel at language comprehension, while another may possess domain-specific knowledge.\\nAs the input passes through the chain, each model can refine and expand upon the information, leading to a more comprehensive and contextually relevant output. The chaining process in language models has the potential to address the limitations of individual models, such as hallucination or generating irrelevant responses. By combining the strengths of multiple models, the pipeline can help mitigate these issues and produce more reliable and accurate results.\\nFurthermore, the pipeline can be customized and tailored to specific use cases or tasks. Different models can be integrated into the chain based on their strengths and compatibility with the desired objectives. This flexibility allows for the creation of powerful and specialized systems that leverage the collective intelligence of multiple language models.\\nLangchain\\nLangchain\\nhas emerged as an immensely popular tool for constructing chains of language models, making it one of the fastest-growing open-source projects in this domain. With support for both Python and JavaScript, it provides a versatile platform for building applications and can be seamlessly integrated into production environments. Langchain serves as the fastest way to kickstart development and offers a wide range of pre-built chains tailored for various tasks. Many developers find inspiration from Langchain and end up creating their own customized chaining solutions. One of the key strengths of Lang chain lies in its extensive repository, which houses numerous examples of different chaining patterns. These examples not only facilitate idea generation but also serve as valuable resources for learning and gaining insights into effective chaining techniques. Whether for rapid prototyping or constructing production-grade systems, Lang chain strikes a balance between ease of use and flexibility, empowering developers to effortlessly create their own chaining systems when needed.\\nThe building block of Langchain are chains. Chains can be simple/generic or specialized. One simple chain is a generic chain that contains a single LLM. Generic chain takes a prompt and uses LLM for text generation based on the prompt. Let’s see how to achieve a simple chain using OpenAI’s gpt-3.5 turbo model.\\nimport\\nos\\nos.environ[\\n\"OPENAI_API_KEY\"\\n]\\n=\\n\"...\"\\nfrom\\nlangchain.prompts\\nimport\\nPromptTemplate\\ntemplate\\n=\\n\"\"\"\\nWho won the oscar for the best actor in  a leading role on\\n{year}\\n?\\n\"\"\"\\nprompt\\n=\\nPromptTemplate(\\ninput_variables\\n=\\n[\\n\"year\"\\n],\\ntemplate\\n=\\ntemplate,\\n)\\nprint\\n(prompt.\\nformat\\n(year\\n=\\n2012\\n))\\nOutput: Who won the oscar\\nfor\\nthe best actor\\nin\\na leading role on\\n2012\\n?\\nPromptTemplate\\nhelps to design prompt for your tasks and you can provide input variables if you want like below:\\ntemplate\\n=\\n\"\"\"\\nWho won the oscar for the best\\n{role}\\non\\n{year}\\n?\\n\"\"\"\\nWhile creating a prompt template for multiple variables, you need to pass all those variables in\\ninput_variables\\nargument\\nprompt\\n=\\nPromptTemplate(\\ninput_variables\\n=\\n[\\n\"role\"\\n,\\n\"year\"\\n],\\ntemplate\\n=\\ntemplate,\\n)\\nTools\\nThe another way to give LLMs access to outside world is to let them use tools.\\nUsing Tools in Langchain\\nTools are the flexible way to augment language model with external data. There are two ways to build tools into language models. First way is to manually create chains whereas the later one is the use of plugins and letting the model figure it out. Some example tools that can be use includes Arxiv, Bash, Bing Search, Google, etc.\\nTools can be used in langchain using following code snippet (in Python):\\nfrom\\nlangchain.agents\\nimport\\nload_tools\\ntool_names\\n=\\n[...]\\ntools\\n=\\nload_tools(tool_names)\\ntools\\nYou can name the tools that you are going to use and load them using load_tools methods\\nLet’s use Python’s requests module as a tool to extract data from the web\\nfrom\\nlangchain.agents\\nimport\\nload_tools\\ntool_names\\n=\\n[\\n\\'requests_all\\'\\n]\\nrequests_tools\\n=\\nload_tools(tool_names)\\nrequests_tools\\nOutput:\\n[\\nRequestsGetTool(name\\n=\\n\\'requests_get\\'\\n, description\\n=\\n\\'A portal to the internet. Use this when you need to get specific content from a website. Input should be a  url (i.e. https://www.google.com). The output will be the text response of the GET request.\\'\\n, args_schema\\n=\\nNone\\n, return_direct\\n=\\nFalse\\n, verbose\\n=\\nFalse\\n, callbacks\\n=\\nNone\\n, callback_manager\\n=\\nNone\\n, handle_tool_error\\n=\\nFalse\\n, requests_wrapper\\n=\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n)),\\nRequestsPostTool(name\\n=\\n\\'requests_post\\'\\n, description\\n=\\n\\'Use this when you want to POST to a website.\\n\\\\n\\nInput should be a json string with two keys: \"url\" and \"data\".\\n\\\\n\\nThe value of \"url\" should be a string, and the value of \"data\" should be a dictionary of\\n\\\\n\\nkey-value pairs you want to POST to the url.\\n\\\\n\\nBe careful to always use double quotes for strings in the json string\\n\\\\n\\nThe output will be the text response of the POST request.\\n\\\\n\\n\\'\\n, args_schema\\n=\\nNone\\n, return_direct\\n=\\nFalse\\n, verbose\\n=\\nFalse\\n, callbacks\\n=\\nNone\\n, callback_manager\\n=\\nNone\\n, handle_tool_error\\n=\\nFalse\\n, requests_wrapper\\n=\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n)),\\nRequestsPatchTool(name\\n=\\n\\'requests_patch\\'\\n, description\\n=\\n\\'Use this when you want to PATCH to a website.\\n\\\\n\\nInput should be a json string with two keys: \"url\" and \"data\".\\n\\\\n\\nThe value of \"url\" should be a string, and the value of \"data\" should be a dictionary of\\n\\\\n\\nkey-value pairs you want to PATCH to the url.\\n\\\\n\\nBe careful to always use double quotes for strings in the json string\\n\\\\n\\nThe output will be the text response of the PATCH request.\\n\\\\n\\n\\'\\n, args_schema\\n=\\nNone\\n, return_direct\\n=\\nFalse\\n, verbose\\n=\\nFalse\\n, callbacks\\n=\\nNone\\n, callback_manager\\n=\\nNone\\n, handle_tool_error\\n=\\nFalse\\n, requests_wrapper\\n=\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n)),\\nRequestsPutTool(name\\n=\\n\\'requests_put\\'\\n, description\\n=\\n\\'Use this when you want to PUT to a website.\\n\\\\n\\nInput should be a json string with two keys: \"url\" and \"data\".\\n\\\\n\\nThe value of \"url\" should be a string, and the value of \"data\" should be a dictionary of\\n\\\\n\\nkey-value pairs you want to PUT to the url.\\n\\\\n\\nBe careful to always use double quotes for strings in the json string.\\n\\\\n\\nThe output will be the text response of the PUT request.\\n\\\\n\\n\\'\\n, args_schema\\n=\\nNone\\n, return_direct\\n=\\nFalse\\n, verbose\\n=\\nFalse\\n, callbacks\\n=\\nNone\\n, callback_manager\\n=\\nNone\\n, handle_tool_error\\n=\\nFalse\\n, requests_wrapper\\n=\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n)),\\nRequestsDeleteTool(name\\n=\\n\\'requests_delete\\'\\n, description\\n=\\n\\'A portal to the internet. Use this when you need to make a DELETE request to a URL. Input should be a specific url, and the output will be the text response of the DELETE request.\\'\\n, args_schema\\n=\\nNone\\n, return_direct\\n=\\nFalse\\n, verbose\\n=\\nFalse\\n, callbacks\\n=\\nNone\\n, callback_manager\\n=\\nNone\\n, handle_tool_error\\n=\\nFalse\\n, requests_wrapper\\n=\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n))\\n]\\nEach tool inside the\\nrequest_all\\ntool contains a request wapper. We can directly work with these wrappers as below:\\nrequests_tools[\\n0\\n].requests_wrapper\\nOutput:\\nTextRequestsWrapper(headers\\n=\\nNone\\n, aiosession\\n=\\nNone\\n)\\nWe can use\\nTextRequestsWrapper\\nto create a request object and use the object to extract data from the web.\\nfrom\\nlangchain.utilities\\nimport\\nTextRequestsWrapper\\nrequests\\n=\\nTextRequestsWrapper()\\nrequests.get(\\n\"https://reqres.in/api/users?page=2\"\\n)\\nOutput:\\n\\'{\"page\":2,\"per_page\":6,\"total\":12,\"total_pages\":2,\"data\":[{\"id\":7,\"email\":\"michael.lawson@reqres.in\",\"first_name\":\"Michael\",\"last_name\":\"Lawson\",\"avatar\":\"https://reqres.in/img/faces/7-image.jpg\"},{\"id\":8,\"email\":\"lindsay.ferguson@reqres.in\",\"first_name\":\"Lindsay\",\"last_name\":\"Ferguson\",\"avatar\":\"https://reqres.in/img/faces/8-image.jpg\"},{\"id\":9,\"email\":\"tobias.funke@reqres.in\",\"first_name\":\"Tobias\",\"last_name\":\"Funke\",\"avatar\":\"https://reqres.in/img/faces/9-image.jpg\"},{\"id\":10,\"email\":\"byron.fields@reqres.in\",\"first_name\":\"Byron\",\"last_name\":\"Fields\",\"avatar\":\"https://reqres.in/img/faces/10-image.jpg\"},{\"id\":11,\"email\":\"george.edwards@reqres.in\",\"first_name\":\"George\",\"last_name\":\"Edwards\",\"avatar\":\"https://reqres.in/img/faces/11-image.jpg\"},{\"id\":12,\"email\":\"rachel.howell@reqres.in\",\"first_name\":\"Rachel\",\"last_name\":\"Howell\",\"avatar\":\"https://reqres.in/img/faces/12-image.jpg\"}],\"support\":{\"url\":\"https://reqres.in/#support-heading\",\"text\":\"To keep ReqRes free, contributions towards server costs are appreciated!\"}}\\'\\nReferences\\nFull Stack Deep Learning (LLM Bootcamp)\\nLangchain'),\n",
       " Document(metadata={'title': 'GitHub Code Search · GitHub', 'url': 'https://github.com/features/code-search', 'relevance_score': 0.18761542439460754, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub Code Search · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCode Search\\nExactly what you’re\\nlooking for\\nWith GitHub code search, your code—and the world’s—is at your fingertips.\\nTry now\\nContact sales\\nFast, relevant results\\nCode search understands your code—and brings you relevant results with incredible speed.\\nA power userʼs dream\\nSearch using regular expressions, boolean operations, keyboard shortcuts, and more.\\nMore than just search\\nDig deeper with the all-new code view—tightly integrating browsing and code navigation.\\nSuggestions, completions, and more.\\nUse the new search input to find symbols and files—and jump right to them.\\nPowerful search syntax.\\nKnow exactly what you’re looking for? Express it with our powerful search operators.\\nCode navigation.\\nInstantly jump to definitions in over 10 languages. No setup required.\\nFile browser.\\nKeep all your code in context and instantly switch files with the new file tree pane.\\n“\\nKeith Smiley\\nSoftware Engineer\\n“\\nMarco Montagna\\nPlatform Engineer\\nFind more, search less\\nTry now\\nContact sales\\nFrequently asked questions\\nDo I need to set up my repositories to support code navigation?\\nNo, code navigation works out of the box, with zero configuration required.\\nWho can search my code?\\nPublic code is searchable by anyone, but private code can only be searched by users who have access to it.\\nHow much does the new code search and code view cost?\\nThe new code search and code view are free for users of GitHub.com.\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Customer stories · GitHub', 'url': 'https://github.com/customer-stories', 'relevance_score': 0.18213847279548645, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"Customer stories · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCustomer Stories\\nEnterprise\\nTeam\\nAll stories\\nStart a free trial\\nMeet the companies who build with GitHub\\nSee all stories\\nWith 12,000 developers using GitHub Copilot, Accenture doubles down on GitHub’s platform.\\nRead the story\\nPhilips builds and deploys digital health technology faster with innersource on GitHub.\\nRead the story\\nCarlsberg unifies development on GitHub Enterprise and accelerates innovation with Copilot.\\nRead the story\\nThe world's largest developer platform\\nLeading organizations choose GitHub to plan, build, secure and ship software.\\n100M+\\nDevelopers\\n90%\\nFortune 100\\n4M+\\nOrganizations\\nBusinesses that utilize GitHub Enterprise:\\nGitHub Enterprise provides an end-to-end developer platform to accelerate businesses.\\nIndustry\\nAll\\nAdvertising & Marketing\\nAutomotive\\nEducation\\nEnergy & Utilities\\nFinancial services\\nFood & Beverage\\nGovernment\\nHealthcare & Life Sciences\\nManufacturing\\nMedia & Entertainment\\nNonprofit\\nProfessional services\\nReal Estate\\nRetail & ecommerce\\nSocial & Messaging\\nSoftware, Hardware & Technology\\nTelecommunications\\nTransportation & Logistics\\nTravel & Hospitality\\nFeature\\nAll\\nGitHub Actions\\nGitHub Advanced Security\\nGitHub Codespaces\\nGitHub Copilot\\nGitHub Discussions\\nGitHub Enterprise\\nGitHub Expert Services\\nGitHub Issues\\nGitHub Packages\\nGitHub Team\\nRegion\\nAll\\nAmericas\\nAsia Pacific\\nEurope\\nMiddle East & Africa\\nSize\\nStartup\\nGrowth\\nEnterprise\\nLearn more about Enterprise\\nView Enterprise stories\\nRead more about Pinterest's customer story\\nPinterest\\nA fixture in the open source community, Pinterest has relied on GitHub from the start.\\nRead story\\nRead more about SPH Media's customer story\\nSPH Media\\nSPH Media tames tool sprawl and secures code with GitHub.\\nRead story\\nRead more about DAZN's customer story\\nDAZN\\nFrom DevOps to recruitment, GitHub supports DAZN’s fast-growing enterprise.\\nRead story\\nRead more about Media Assembly's customer story\\nMedia Assembly\\nDiscover how every team at Media Assembly is adopting open source ideology and social sharing with GitHub.\\nRead story\\nRead more about Meta's customer story\\nMeta\\nMeta finds its community in GitHub and open source.\\nRead story\\nRead more about The New York Times's customer story\\nThe New York Times\\nThe New York Times uses GitHub to keep developers focused on code, not checklists.\\nRead story\\nGitHub Enterprise\\nDuolingo empowers its engineers to be force multipliers for expertise with GitHub Copilot.\\nRead more about Duolingo and GitHub's story\\nRead story\\n25%\\nincrease in developer speed with GitHub Copilot\\n1m\\nset-up time for largest repo with Codespaces\\n67%\\ndecrease in median code review turnaround time\\n70%\\nincrease in pull requests\\nProblem\\nInconsistent standards and workflows limited developer mobility and efficiency, limiting Duolingo’s ability to expand its content and deliver on its core mission.\\nSolution\\nGitHub Copilot, Codespaces, and custom API integrations enforce code consistency, accelerate developer speed, and remove the barriers to using engineering as a force multiplier for expertise.\\nProducts\\nGitHub Enterprise\\nGitHub Codespaces\\nGitHub Copilot\\nDiscover how high-growth companies innovate faster with GitHub Team.\\nIndustry\\nAll\\nAdvertising & Marketing\\nAutomotive\\nEducation\\nEnergy & Utilities\\nFinancial services\\nFood & Beverage\\nGovernment\\nHealthcare & Life Sciences\\nManufacturing\\nMedia & Entertainment\\nNonprofit\\nProfessional services\\nReal Estate\\nRetail & ecommerce\\nSocial & Messaging\\nSoftware, Hardware & Technology\\nTelecommunications\\nTransportation & Logistics\\nTravel & Hospitality\\nFeature\\nAll\\nGitHub Actions\\nGitHub Advanced Security\\nGitHub Codespaces\\nGitHub Copilot\\nGitHub Discussions\\nGitHub Enterprise\\nGitHub Expert Services\\nGitHub Issues\\nGitHub Packages\\nGitHub Team\\nRegion\\nAll\\nAmericas\\nAsia Pacific\\nEurope\\nMiddle East & Africa\\nSize\\nStartup\\nGrowth\\nEnterprise\\nLearn more about Team\\nView Team stories\\nRead more about Trustpilot's customer story\\nTrustpilot\\nGlobal review platform Trustpilot uses GitHub Team to build a better product, faster, with 300 releases per week.\\nRead story\\nRead more about Buffer's customer story\\nBuffer\\nBuffer goes from siloed to synced for better production releases.\\nRead story\\nRead more about Cesium's customer story\\nCesium\\nCesium leverages an open source community to support the development of 3D geospatial applications.\\nRead story\\nRead more about Knock's customer story\\nKnock\\nKnock pivots to new products, with the help of GitHub’s fast, flexible developer workflows.\\nRead story\\nRead more about Tray.io's customer story\\nTray.io\\nGitHub Team helps the general automation platform build, package, and deploy code faster than ever.\\nRead story\\nRead more about Sketch's customer story\\nSketch\\nSketch streamlines their workflows to provide teams with a comprehensive digital design editor.\\nRead story\\nHere's what software leaders have to say about GitHub\\nTestimonials from our developers.\\n1 / 4\\n1 of 4\\n“\\nAt Uber, we continuously strive to improve our developer experience. We migrated code hosting and review to GitHub and are adopting GitHub Copilot to boost overall developer productivity.\\nAli-Reza Adl-Tabatabai\\nSenior Director of Engineering\\n@ Uber\\n“\\nGitHub's endless plug-ins, beautiful UI, and optimized workflows make devs happy. Happy and empowered engineers write the best code, make better decisions, and have more time to innovate.\\nJen Peck\\nSenior Director of Engineering\\n@ Redfin\\n“\\nGitHub Copilot will bring huge benefits to our engineering teams by reducing the amount of time spent on boilerplate code, keeping the teams in their flow state, allowing them to ship high-quality products to market faster.\\nSantosh Lolyeker\\nVP, Engineering Fellow\\n@ Veritas\\n“\\nWith GitHub Enterprise, we have alleviated engineering overhead at Costco, enabling our engineers to focus on innovating.\\nAvdesh Rai\\nEnterprise Solutions Engineer\\n@ Costco\\nWhat will your story be?\\nStart collaborating with your team on GitHub\\nFree\\nThe basics for individuals and organizations\\n$0 USD\\nper month\\nCreate a free organization\\nTeam\\nAdvanced collaboration for individuals and organizations\\n$4 USD\\nper month\\nContinue with Team\\nEnterprise\\nSecurity, compliance, and flexible deployment\\n$21 USD\\nper month\\nEnterprise\\nWant to use GitHub on your own?\\nCheck out our plans for individuals\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'Huggingface AI Agents Quiz Solutions – Prabin Nepal', 'url': 'https://nepalprabin.github.io/posts/2025-03-02-huggingface-smolagents-solutions.html', 'relevance_score': 0.1676510125398636, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Huggingface AI Agents Quiz Solutions – Prabin Nepal\\nI have been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of how to build and deploy AI agents using the\\nsmolagents\\nlibrary. In this blog, I’ll share insights from the course (Unit 2) and provide code snippets to illustrate key concepts.\\nNote\\nHere is the course link if anyone is interested.\\nAI Agents Course\\nCreate a Basic Code Agent with Web Search Capability\\nOne of the foundational exercises involves creating a CodeAgent equipped with web search capabilities. This agent leverages the DuckDuckGoSearchTool to perform web searches, enabling it to fetch real-time information. Here’s how you can set it up:\\n# Create a CodeAgent with DuckDuckGo search capability\\nfrom\\nsmolagents\\nimport\\nCodeAgent, DuckDuckGoSearchTool, HfApiModel\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\n# Add search tool here\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Add model here\\n)\\nIn this snippet, we initialize a CodeAgent with the DuckDuckGoSearchTool, allowing the agent to perform web searches to answer queries.\\nSet Up a Multi-Agent System with Manager and Web Search Agents\\nMulti-Agent systems are the agents that are specialized on complex tasks with more scalable and robust nature. In\\nsmolagents\\n, various agents can be integrated to produce Python code, invoke external tools, conduct web searches, and more. By coordinating these agents, it’s possible to develop robust workflows. A typical multi-agent system includes:\\n- A manager Agent\\n- A code interpreter Agent\\n- A web Search Agent\\nMulti-agent system allows to separate memories between different sub-tasks and provide great benefits. Firstly, each agent are more focused on its core taks and secondly, separating memories reduces the count of input tokens resulting in reducing latency and cost. Below is the multi-agent system when\\nweb_agent\\nperforms search and\\nmanager_agent\\ngives data analysis capabilities. Also, we can import dependencies (like python libraries) that helps to perform the tasks.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, HfApiModel, VisitWebpageTool\\nweb_agent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool(), VisitWebpageTool()],\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nmax_steps\\n=\\n10\\n,\\nname\\n=\\n\"search\"\\n,\\ndescription\\n=\\n\"Agent to perform web searches and visit webpages.\"\\n)\\nmanager_agent\\n=\\nCodeAgent(\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nmanaged_agents\\n=\\n[web_agent],\\nadditional_authorized_imports\\n=\\n[\\n\"pandas\"\\n,\\n\"time\"\\n,\\n\"numpy\"\\n]\\n# Corrected imports\\n)\\nConfigure Agent Security Settings\\nSecurity is a crucial aspect when deploying AI agents, especially when they execute code. Below code snippet uses E2B to run code in a sandboxed environment. It is a remote execution that run the code in a isolated container.\\nfrom\\nsmolagents\\nimport\\nCodeAgent, HfApiModel\\nfrom\\nsmolagents.sandbox\\nimport\\nE2BSandbox\\nmodel\\n=\\nHfApiModel(\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\nagent\\n=\\nCodeAgent(\\ntools\\n=\\n[],\\nmodel\\n=\\nmodel,\\nsandbox\\n=\\nE2BSandbox(),\\n# Configure the sandbox\\nadditional_authorized_imports\\n=\\n[\\n\"numpy\"\\n],\\n# Authorize numpy import\\n)\\nImplement a Tool-Calling Agent\\nSimilar to\\nCodeAgent\\n,\\nToolCallingAgent\\nis another type of agent available in smolagent library. CodeAgent uses Python code snippets whereas ToolCallingAgent use built-in tool-calling capabilities of LLM providers and generate JSON structures.\\nfrom\\nsmolagents\\nimport\\nToolCallingAgent, HfApiModel, DuckDuckGoSearchTool\\nagent\\n=\\nToolCallingAgent(\\ntools\\n=\\n[DuckDuckGoSearchTool()],\\nmodel\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n),\\nname\\n=\\n\"SearchAgent\"\\n,\\ndescription\\n=\\n\"An agent that uses DuckDuckGo to search the web.\"\\n,\\nmax_steps\\n=\\n5\\n,\\n)\\nSet Up Model Integration\\nLLM models are the most important aspect when creating AI agents. There are many model availables for various tasks and domains. So we can easily integrate models that is required for our task. Below code snippet switches between two different models providers.\\nfrom\\nsmolagents\\nimport\\nHfApiModel, LiteLLMModel\\n# Initialize Hugging Face model\\nhf_model\\n=\\nHfApiModel(model_id\\n=\\n\"Qwen/Qwen2.5-Coder-32B-Instruct\"\\n)\\n# Initialize LiteLLM model as an alternative model\\nother_model\\n=\\nLiteLLMModel(model_id\\n=\\n\"anthropic/claude-3-sonnet\"\\n)\\n# Set the model to hf_model or alternative model\\nmodel\\n=\\nhf_model\\n# Alternatively, you can switch this to `other_model`'),\n",
       " Document(metadata={'title': 'GitHub - nepalprabin/chat-with-nlp-book-gpt', 'url': 'https://github.com/nepalprabin/chat-with-nlp-book-gpt', 'relevance_score': 0.15969358384609222, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub - nepalprabin/chat-with-nlp-book-gpt\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\n/\\nchat-with-nlp-book-gpt\\nPublic\\nNotifications\\nYou must be signed in to change notification settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed in to change notification settings\\nnepalprabin/chat-with-nlp-book-gpt\\nmain\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n21 Commits\\ndata\\ndata\\nutils\\nutils\\n.gitignore\\n.gitignore\\n__init__.py\\n__init__.py\\ndocs.index\\ndocs.index\\nfaiss_store.pkl\\nfaiss_store.pkl\\ningest.py\\ningest.py\\nmain.py\\nmain.py\\nrequirements.txt\\nrequirements.txt\\nView all files\\nAbout\\nNo description, website, or topics provided.\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nLanguages\\nPython\\n100.0%\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'AI · GitHub', 'url': 'https://github.com/resources/articles/ai', 'relevance_score': 0.15629224479198456, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='AI · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nAI\\nTopics\\nEnhancing software development with retrieval-augmented generation\\nLearn how Retrieval Augmented Generation (RAG) improves coding, debugging, and code reviews.\\nLearn more\\nNatural language processing (NLP) in software development\\nLearn why natural language processing (NLP) is becoming an indispensable tool for developers.\\nLearn more\\nWhat are AI agents?\\nDiscover how AI agents transform software development by automating workflows and enhancing security. Explore the different types of AI agents, learn how they integrate into development environments, and see real-world examples of their impact. Learn best practices for using AI agents and get a glimpse into the future of AI in development and security.\\nLearn more\\nWhat is AI code generation?\\nAI code generation uses machine learning models to provide context-based code suggestions.\\nLearn more\\nAI coding tools for beginner and expert coders\\nHow beginner and expert coders use AI coding tools to code faster and ship great software.\\nLearn more\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Sign in for Software Support and Product Help - GitHub Support', 'url': 'https://github.com/contact/report-abuse?report=nepalprabin+%28user%29', 'relevance_score': 0.15008088946342468, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Sign in for Software Support and Product Help - GitHub Support\\nSkip to content\\nLoading'),\n",
       " Document(metadata={'title': 'Reporting abuse or spam - GitHub Docs', 'url': 'https://docs.github.com/articles/reporting-abuse-or-spam', 'relevance_score': 0.14758272469043732, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Reporting abuse or spam - GitHub Docs\\nSkip to main content\\nReporting abuse or spam\\nYou can report behavior and content that violates community guidelines and terms.\\nWho can use this feature?\\nOwners, collaborators, prior contributors, and people with write access can report issues, pull requests, discussions, and comments on issues, pull requests, discussions, and commits. Anyone can report apps in GitHub Marketplace.\\nIn this article\\nAbout reporting abuse or spam\\nGitHub provides a baseline code of conduct for everyone who uses GitHub. For more information, see\\nGitHub Terms of Service\\nand\\nGitHub Community Guidelines\\n.\\nYou can report users that have violated GitHub\\'s Community Guidelines or Terms of Service. You can also report issues, pull requests, or comments on issues, pull requests, and commits.\\nIf reported content is enabled for a public repository, you can also report content directly to repository maintainers.\\nReporting a user\\nVisit the user\\'s profile page.\\nIn the left sidebar, below the user\\'s profile information, click\\nBlock or Report\\n.\\nClick\\nReport abuse\\n.\\nComplete the contact form to tell GitHub Support about the user\\'s behavior, then click\\nSubmit\\n.\\nReporting an organization\\nOn GitHub, navigate to the main page of the organization.\\nIn the right sidebar, under the \"Top languages\" section, click\\nReport abuse\\n.\\nComplete the contact form to tell GitHub Support about the organization\\'s behavior, then click\\nSubmit\\n.\\nReporting a repository\\nOn GitHub, navigate to the main page of the repository.\\nIn the right sidebar, under the \"About\" section, click\\nReport repository\\n.\\nComplete the contact form to tell GitHub Support about the repository\\'s behavior, then click\\nSubmit\\n.\\nReporting an issue or pull request\\nNavigate to the issue or pull request you\\'d like to report.\\nIn the upper-right corner of the issue or pull request, click\\n, then click\\nReport content\\n.\\nYou may see options to\\nReport to repository admins\\nor\\nReport abuse to GitHub Support\\n. If not, skip to the next step.\\nTo report the content to GitHub Support, click\\nReport abuse to GitHub Support\\n.\\nTo report the content to repository maintainers, use the\\nChoose a reason\\ndropdown to select a reason, then click\\nReport to repository admins\\n. Your report has been submitted.\\nComplete the \"Report content\" form, then click\\nSend request\\n.\\nReporting a discussion\\nNavigate to the discussion you\\'d like to report.\\nIn the upper-right corner of the discussion, click\\n, then click\\nReport content\\n.\\nSelect an email address and a category, then click\\nSend request\\n.\\nReporting a comment\\nNavigate to the comment you\\'d like to report.\\nIn the upper-right corner of the comment, click\\n, then click\\nReport content\\n.\\nYou may see options to\\nReport to repository admins\\nor\\nReport abuse to GitHub Support\\n. If not, skip to the next step.\\nTo report the content to GitHub Support, click\\nReport abuse to GitHub Support\\n.\\nTo report the content to repository maintainers, use the\\nChoose a reason\\ndropdown to select a reason, then click\\nReport to repository admins\\n. Your report has been submitted.\\nComplete the \"Report content\" form, then click\\nSend request\\n.\\nReporting an app in GitHub Marketplace\\nTo open GitHub Marketplace, in the top-left corner of GitHub, select\\n, then click\\nMarketplace\\n.\\nBrowse to the app you\\'d like to report.\\nIn the left sidebar, under the \"Developer links\" section, click\\nReport abuse\\n.\\nComplete the contact form to tell GitHub Support about the app\\'s behavior, then click\\nSend request\\n.\\nReporting contact link abuse in the template chooser\\nNavigate to the repository that contains the contact link you\\'d like to report.\\nUnder the repository name, click\\nIssues\\n.\\nIn the lower-right corner of the template chooser, click\\nReport abuse\\n.\\nComplete the contact form to tell GitHub Support about the contact link\\'s behavior, then click\\nSend request\\n.\\nNote\\nIn order to get accurate information about the abuse, the abuse report form will direct you to use the in-product abuse report links. If an in-product link is not available, contact us through the\\nGitHub Support portal\\nto report abuse or report content.\\nUsers in India can contact GitHub\\'s Grievance Officer for India through\\nsupport.github.com/contact/india-grievance-officer\\n.\\nFurther reading\\nSetting up your project for healthy contributions\\nUsing templates to encourage useful issues and pull requests\\nManaging disruptive comments\\nLimiting interactions in your repository\\nTracking changes in a comment'),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Followers · GitHub', 'url': 'https://github.com/nepalprabin?tab=followers', 'relevance_score': 0.1454327553510666, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) / Followers · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nSumit Adhikari\\nsumitjee\\nLearning\\nFollow\\nAnne Thorpe\\nmissAnneThorpe\\nFollow\\nPrashant Nepal\\nprashant074\\nLearning\\nKathmandu\\nPradip Thapa\\nPradipCodes\\nHi , I am on my journey to become a full stack developer.\\nUniversity of South Dakota\\nPlano, TX, US\\nFollow\\nranjan435\\nFollow\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'GitHub Discussions · Developer Collaboration & Communication Tool · GitHub', 'url': 'https://github.com/features/discussions', 'relevance_score': 0.13276390731334686, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub Discussions · Developer Collaboration & Communication Tool · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nGitHub Discussions\\nThe home for\\ndeveloper communities\\nAsk questions, share ideas, and build connections with each other—all right next to your code. GitHub Discussions enables healthy and productive software collaboration.\\nTry now\\nContact sales\\nScreenshot of a GitHub Discussions page for the ’octoinvaders’ project, showing categorized discussion threads with tags like ’answered’ and ’Long term.’ The interface features playful elements like a mona emjoi and a rocket icon, highlighting community interaction.\\nMark what’s most helpful.\\nHighlight quality responses and make the best answer more discoverable for future community members to find.\\nThread conversations.\\nKeep context in-tact and conversations on track with threaded comments.\\nAsk your community with polls.\\nGauge interest in a feature, vote on a meetup time, or learn more about your community with custom polls.\\nLeverage GraphQL API and webhooks.\\nDecrease maintainer burden by integrating your workflows where your teams already are.\\nGive your open ended conversations the room they need outside of issues.\\nConvert discussions into issues when you’re ready to scope out work.\\nCustomize\\nPersonalize for your community and team with any ways to make your space unique for you and your collaborators.\\nCustom categories\\nCreate discussion categories that fit your communityʼs needs.\\nLabel and organize\\nMake announcements and the most important discussions more visible for contributors.\\nPin discussions\\nMake announcements and the most important discussions more visible for contributors.\\nContribution activity\\nCount of total contribution activity to Discussions, Issues, and PRs.\\nDiscussions page views\\nTotal page views to Discussions segmented by logged in vs anonymous users.\\nDiscussions daily contributors\\nCount of unique users who have reacted, upvoted, marked an answer, commented, or posted in the selected period.\\nNext.js\\n10k+ discussions\\nTailwindCSS\\n3k+ discussions\\nHomebrew\\n4k+ discussions\\nBootstrap\\n600+ discussions\\nLaravel\\n1.6k+ discussions\\nD3.js\\n30k+ discussions\\nSymfony\\n700+ discussions\\nVueJS\\n50+ discussions\\nStart the conversation with your community\\nTry now\\nContact sales\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Prabin Nepal', 'url': 'https://nepalprabin.github.io', 'relevance_score': 0.13116760551929474, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Prabin Nepal\\nCategories\\nAll\\n(16)\\nLLM\\n(1)\\nNLP\\n(4)\\nagents\\n(1)\\ncomputer-vision\\n(6)\\ndeep-learning\\n(12)\\nllms\\n(1)\\nmachine-learning\\n(2)\\nself-supervised-learning\\n(1)\\nHuggingface AI Agents Quiz Solutions\\nllms\\nagents\\nI have been diving into AI agents through Huggingface’s AI Agents Course. This course offers a comprehensive understanding of how to build and deploy AI agents using the\\nsmol…\\nMar 2, 2025\\nAugmenting Large Language Models: Expanding Context and Enhancing Relevance\\nmachine-learning\\nNLP\\ndeep-learning\\nLLM\\nWith the rise of ChatGPT and other large language models (LLMs), the potential for AI to surpass human capabilities has become a topic of both fascination and concern. While…\\nJul 4, 2023\\nBrief overview of GPT-4\\nmachine-learning\\nNLP\\ndeep-learning\\nSince the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural language processing communities regarding its…\\nMar 15, 2023\\nText Summarization NLP\\nNLP\\ndeep-learning\\nText summarization is one of the Natural Language Processing (NLP) tasks where documents/texts are shortened automatically while holding the same semantic meaning.…\\nOct 19, 2022\\nAutocorrect and Minimum Edit Distance\\nNLP\\ndeep-learning\\nThis is my brief note from\\nDeepLearning.AI’s\\nNLP Specialization Course.\\nOct 25, 2021\\nIllustrated Vision Transformers\\ncomputer-vision\\ndeep-learning\\nEver since Transformer was introduced in 2017, there has been a huge success in the field of Natural Language Processing (NLP). Almost all NLP tasks use Transformers and…\\nJul 27, 2021\\nPaper Explanation: A Simple Framework for Contrastive Learning of Visual Representations (simCLR)\\nVarious self-supervised learning methods have been proposed in recent years for learning image representations. Though a lot of methods have been proposed, the performance…\\nMar 26, 2021\\nDeep Residual Learning for Image Recognition (ResNet paper explained)\\nDeep Neural Networks tend to provide more accuracy as the number of layers increases. But, as we go more deeper in the network, the accuracy of the network decreases instead…\\nJan 1, 2021\\nSelf-supervised Learning\\ndeep-learning\\nself-supervised-learning\\nI have been exploring self-supervised learning and been through papers and blogs to understand it. Self-supervised learning is considered the next big thing in deep learning…\\nDec 8, 2020\\nMobileNet Architecture Explained\\ndeep-learning\\nIn this blog post, I will try to write about the MobileNets and its architecture. MobileNet uses depthwise separable convolutions instead of standard convolution to reduce…\\nSep 21, 2020\\nNeural style transfer and its working\\nHave you ever used an app called Prisma that styles your image using popular paintings and turns your photo stunning? If that’s the case then, the app you are using is the…\\nAug 23, 2020\\nDeep Convolutional Generative Adversarial Networks (DCGANs)\\ncomputer-vision\\ndeep-learning\\nDCGAN (Deep Convolutional General Adversarial Networks) uses convolutional layers in its design.\\nAug 15, 2020\\nGeneral Adversarial Networks (GANs)\\ncomputer-vision\\ndeep-learning\\n“\\nGeneral Adversarial Nets\\nis the most interesting idea in the last 10 years in machine learning”. This was the statement from Yann LeCun regarding GANs when Ian Goodfellow…\\nAug 4, 2020\\nPaper Explanation: Going deeper with Convolutions (GoogLeNet)\\ncomputer-vision\\ndeep-learning\\nGoogle proposed a deep Convolution Neural Network named inception that achieved top results for classification and detection in ILSVRC 2014.\\nJun 5, 2020\\nVGGNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nVGGNet is a Convolutional Neural Network architecture proposed by Karen Simonyan and Andrew Zisserman of University of Oxford in 2014. This paper mailny focuses in the…\\nMay 9, 2020\\nAlexNet Architecture Explained\\ncomputer-vision\\ndeep-learning\\nAlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large margin (15.3% vs 26.2%(second place) error rates). Here is the link to original paper.\\nApr 24, 2020\\nNo matching items'),\n",
       " Document(metadata={'title': 'Prabin Nepal', 'url': 'https://nepalprabin.github.io/index.html', 'relevance_score': 0.13116760551929474, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=''),\n",
       " Document(metadata={'title': 'Home - The GitHub Blog', 'url': 'https://github.blog', 'relevance_score': 0.13050417602062225, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"Home - The GitHub Blog\\nThe GitHub Blog\\nDeveloper skills\\nVideo: How to run dependency audits with GitHub Copilot\\nLearn to automate dependency management using GitHub Copilot, GitHub Actions, and Dependabot to eliminate manual checks, improve security, and save time for what really matters.\\nAI & ML\\nNot just for developers: How product and security teams can use GitHub Copilot\\nGitHub Copilot isn’t just for developers! Discover how product managers, security professionals, scrum masters, and more use GitHub Copilot to streamline tasks, automate workflows, and boost productivity across teams.\\nEngineering\\nFinding leaked passwords with AI: How we built Copilot secret scanning\\nPasswords are notoriously difficult to detect with conventional programming approaches. AI can help us find passwords better because it understands context. This blog post will explore the technical challenges we faced with building the feature and the novel and creative ways we solved them.\\nAI & ML\\nGitHub for Beginners: How to get started with GitHub Copilot\\nGet started with GitHub Copilot and navigate features like Copilot Chat in this installment of the GitHub for Beginners series.\\nWe do newsletters, too\\nDiscover tips, technical guides, and best practices in our biweekly newsletter just for devs.\\nYour email address\\nSubscribe\\nYes please, I’d like GitHub and affiliates to use my information for personalized communications, targeted advertising and campaign effectiveness. See the\\nGitHub Privacy Statement\\nfor more details.\\nSubscribe\\nOpen Source\\nCommunity managers in action: Leading a developer community for good\\nGitHub’s Digital Public Goods Open Source Community Manager Program just wrapped up a second successful year, helping Community Managers gain experience in using open source for good.\\nAI & ML\\nHow to debug code with GitHub Copilot\\nGitHub Copilot can streamline your debugging process by troubleshooting in your IDE, analyzing pull requests, and more, helping you tackle issues faster and more robustly.\\nPolicy\\nEngaging with the developer community on our approach to content moderation\\nWe share the full year 2024 data update on our Transparency Center and highlight how developers can engage with us on our site policies and content moderation.\\nView all\\nShowing popular posts from: All categories\\nEngineering\\nFinding leaked passwords with AI: How we built Copilot secret scanning\\nPasswords are notoriously difficult to detect with conventional programming approaches. AI can help us find passwords better because it understands context. This blog post will explore the technical challenges we faced with building the feature and the novel and creative ways we solved them.\\nNews & insights\\nGitHub Copilot: The agent awakens\\nIntroducing agent mode for GitHub Copilot in VS Code, announcing the general availability of Copilot Edits, and providing a first look at our SWE agent.\\nNews & insights\\nOctoverse: AI leads Python to top language as the number of global developers surges\\nIn this year’s Octoverse report, we study how public and open source activity on GitHub shows how AI is expanding as the global developer community surges in size.\\nChangelog\\nView all changes\\nDelegated alert dismissal for code scanning and secret scanning now available in public preview\\nMarch 5, 2025\\nIntroducing GitHub Secret Protection and GitHub Code Security\\nMarch 4, 2025\\nFind secrets in your organization with the secret risk assessment\\nMarch 4, 2025\\nImproved pull request merge experience is now generally available\\nMarch 4, 2025\\nView all changes\\nHow GitHub uses CodeQL to secure GitHub\\nHow GitHub’s Product Security Engineering team manages our CodeQL implementation at scale and how you can, too.\\nConsiderations for making a tree view component accessible\\nA deep dive on the work that went into making the component that powers repository and pull request file trees.\\nBreaking down CPU speed: How utilization impacts performance\\nThe Performance Engineering team at GitHub assessed how CPU performance degrades as utilization increases and how this relates to capacity.\\nHow to make Storybook Interactions respect user motion preferences\\nWith this custom addon, you can ensure your workplace remains accessible to users with motion sensitivities while benefiting from Storybook’s Interactions.\\nGitHub Enterprise Cloud with data residency: How we built the next evolution of GitHub Enterprise using GitHub\\nHow we used GitHub to build GitHub Enterprise Cloud with data residency.\\nMore Engineering articles\\nUsing GitHub Copilot Free: What to know\\nFind out what you can do with the free tier of GitHub Copilot, the AI editor for everyone, and start building what’s next today.\\nInside GitHub: A sneak peak into the world of GitHub stickers\\nGo behind the scenes with Christina Warren (@filmgirl) as she uncovers the fascinating story of our beloved Octocat stickers. 🎉\\nOctoverse 2024: The rise of Python and AI\\nFind out how AI and a rapidly growing global developer community defined this past year on GitHub across public and open source projects.\\nView GitHub on YouTube\\nStep inside GitHub Universe 2024\\nLearn about GitHub Copilot\\nStay informed with The Download\\nExplore GitHub for Beginners\\nView all playlists\\nGitHub Availability Report: January 2025\\nIn January, we experienced two incidents that resulted in degraded performance across GitHub services.\\nThat’s a wrap: GitHub Innovation Graph in 2024\\nDiscover the latest trends and insights on public software development activity on GitHub with the release of Q2 & Q3 2024 data for the Innovation Graph.\\nSeven years of open source: A more secure and diverse ecosystem\\nExplore insights into open source community growth, innovation, and inclusivity with an updated survey dataset.\\nGitHub Availability Report: December 2024\\nIn December, we experienced two incidents that resulted in degraded performance across GitHub services.\\nInside the research: How GitHub Copilot impacts the nature of work for open source maintainers\\nAn interview with economic researchers analyzing the causal effect of GitHub Copilot on how open source maintainers work.\\nOpenAI’s latest o1 model now available in GitHub Copilot and GitHub Models\\nThe December 17 release of OpenAI’s o1 model is now available in GitHub Copilot and GitHub Models, bringing advanced coding capabilities to your workflows.\\nMore News & insights articles\\nThe world's largest developer platform\\nDocs\\nEverything you need to master GitHub, all in one place.\\nGo to Docs\\nGitHub\\nBuild what’s next on GitHub, the place for anyone from anywhere to build anything.\\nStart building\\nCustomer stories\\nMeet the companies and engineering teams that build with GitHub.\\nLearn more\\nWork at GitHub!\\nCheck out our current job openings.\\nApply now\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Following · GitHub', 'url': 'https://github.com/nepalprabin?tab=following', 'relevance_score': 0.12874208390712738, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) / Following · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nTF\\narita37\\nGorakh Raj Joshi\\ngorakhjoshi\\nFullstack Software Engineer\\nTakeo\\nNew York, United States\\nFollow\\nAndrej\\nkarpathy\\nI like to train Deep Neural Nets on large datasets.\\nStanford\\nFollow\\nWill Vincent\\nwsvincent\\nDeveloper Advocate at JetBrains. Creator of LearnDjango.com.\\nJetBrains, Django\\nBoston, MA\\nFollow\\nJoseph Redmon\\npjreddie\\nFollow\\nTrung Tran\\nChunML\\nCreator of AnnoMachine. Focusing on bringing AI to life.\\nBlogging on blog.erico.vn.\\nTokyo, Japan\\nFollow\\nChris\\nChristosChristofidis\\nFollow\\nJake Vanderplas\\njakevdp\\nPython ML & Data Science\\nGoogle\\nOakland CA\\nFollow\\nDenny Britz\\ndennybritz\\nHigh-school dropout. Ex Google Brain, Stanford, Berkeley. Into Startups, Deep Learning. Writing at wildml.com  and dennybritz.com\\nTokyo, Japan\\nFollow\\nSiraj Raval\\nllSourcell\\nsubscribe to my youtube channel!\\nwww.youtube.com/c/sirajraval\\nSan Francisco, CA\\nFollow\\nMike Bostock\\nmbostock\\nBuilding a better computational medium. Co-founder\\n@observablehq\\n. Creator\\n@d3\\n. Former\\n@nytgraphics\\n. Pronounced BOSS-tock.\\n@observablehq\\nSan Francisco, CA\\nFollow\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Starred · GitHub', 'url': 'https://github.com/nepalprabin?tab=stars', 'relevance_score': 0.12811793386936188, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='nepalprabin (Prabin Nepal) / Starred · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don\\'t include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nStars\\nSearch\\nSearch\\nType: All\\nAll\\nSources\\nForks\\nCan be sponsored\\nMirrors\\nTemplates\\nLanguage\\nAll languages\\nJupyter Notebook\\nPython\\nSort by: Recently starred\\nRecently starred\\nRecently active\\nMost stars\\nShowing results\\nmarqo-ai /\\nmarqo\\nUnified embedding generation and search engine. Also available on cloud - cloud.marqo.ai\\nPython\\n4,788\\n198\\nUpdated\\nMar 5, 2025\\nfirstcontributions /\\nfirst-contributions\\n🚀✨ Help beginners to contribute to open source projects\\n47,164\\n83,578\\nUpdated\\nMar 5, 2025\\nifzhang /\\nFairMOT\\n[IJCV-2021] FairMOT: On the Fairness of Detection and Re-Identification in Multi-Object Tracking\\nPython\\n4,083\\n931\\nUpdated\\nSep 19, 2023\\nisaacmg /\\nhealthcare_ml\\nA curated list of ML|NLP resources for healthcare.\\n460\\n121\\nUpdated\\nMar 26, 2023\\nmakcedward /\\nnlp\\n📝 This repository recorded my NLP journey.\\nPython\\n1,077\\n326\\nUpdated\\nAug 29, 2020\\namitness /\\nml-datasets\\nMachine Learning datasets for Nepal\\n188\\n68\\nUpdated\\nMay 13, 2023\\nfloodsung /\\nDeep-Learning-Papers-Reading-Roadmap\\nDeep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!\\nPython\\n38,815\\n7,350\\nUpdated\\nNov 27, 2022\\nAakashKumarNain /\\nannotated_research_papers\\nThis repo contains annotated research papers that I found really good and useful\\n2,721\\n266\\nUpdated\\nFeb 26, 2025\\nGokuMohandas /\\nMade-With-ML\\nLearn how to design, develop, deploy and iterate on production-grade ML applications.\\nJupyter Notebook\\n38,266\\n6,061\\nUpdated\\nAug 18, 2024\\nmuellerzr /\\nPractical-Deep-Learning-for-Coders-2.0\\nNotebooks for the \"A walk with fastai2\" Study Group and Lecture Series\\nJupyter Notebook\\n746\\n166\\nUpdated\\nNov 13, 2021\\nnepalprabin /\\ndeeplearning-models\\nForked from\\nrasbt/deeplearning-models\\nA collection of various deep learning architectures, models, and tips\\nJupyter Notebook\\n1\\nUpdated\\nMay 2, 2020\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'nepalprabin (nepalprabin) / Repositories · GitHub', 'url': 'https://github.com/nepalprabin?tab=repositories', 'relevance_score': 0.12772580981254578, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (nepalprabin) / Repositories · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nType\\nAll\\nAll\\nSources\\nForks\\nArchived\\nCan be sponsored\\nMirrors\\nTemplates\\nLanguage\\nAll\\nAll\\nPython\\nTeX\\nTypeScript\\nJupyter Notebook\\nGo\\nHCL\\nMakefile\\nJavaScript\\nCSS\\nHTML\\nJava\\nSort\\nLast updated\\nLast updated\\nName\\nStars\\nrufus\\nPublic\\nPython\\nApache License 2.0\\nUpdated\\nMar 5, 2025\\nnepalprabin.github.io\\nPublic\\nTeX\\nUpdated\\nMar 2, 2025\\nblog_chatbot\\nPublic\\nPython\\nApache License 2.0\\nUpdated\\nMar 2, 2025\\nnestjs\\nPublic\\nTypeScript\\nUpdated\\nFeb 12, 2025\\nsmol-course\\nPublic\\nForked from\\nhuggingface/smol-course\\nA course on aligning smol models.\\nJupyter Notebook\\nApache License 2.0\\nUpdated\\nDec 15, 2024\\nmy-resume\\nPublic\\nTeX\\nMIT License\\nUpdated\\nSep 27, 2024\\nlearn-go\\nPublic\\nGo\\nMIT License\\nUpdated\\nSep 25, 2024\\niac-terraform\\nPublic\\nHCL\\nUpdated\\nMay 12, 2024\\nfullstackopen\\nPublic\\nLearnings from fullstackopen course\\nTypeScript\\nUpdated\\nJan 23, 2024\\nlearn_rust\\nPublic\\nMakefile\\nUpdated\\nJan 19, 2024\\nchatflowjs\\nPublic\\nTypeScript\\nUpdated\\nNov 9, 2023\\noswrite\\nPublic\\nPython\\n2\\nUpdated\\nNov 7, 2023\\nlangchain\\nPublic\\nForked from\\nlangchain-ai/langchain\\n⚡ Building applications with LLMs through composability ⚡\\nPython\\nMIT License\\nUpdated\\nOct 31, 2023\\ndistill\\nPublic\\nPython\\nUpdated\\nOct 20, 2023\\nSaas-AI\\nPublic\\nTypeScript\\nUpdated\\nSep 28, 2023\\nisolution_api\\nPublic\\nPython\\nUpdated\\nJul 26, 2023\\nnepalprabin\\nPublic\\nUpdated\\nJul 25, 2023\\nchat-with-nlp-book-gpt\\nPublic\\nPython\\nUpdated\\nJun 5, 2023\\npromptify\\nPublic\\nJavaScript\\nUpdated\\nJun 3, 2023\\ntypescript_fullstack\\nPublic\\nTypeScript\\nUpdated\\nMay 14, 2023\\nchatapp-langchain\\nPublic\\nTypeScript\\nMIT License\\nUpdated\\nApr 11, 2023\\nbankapp\\nPublic\\nGo\\nUpdated\\nMar 29, 2023\\nlangchain_QA\\nPublic\\nPython\\n1\\n1\\nUpdated\\nMar 19, 2023\\nclinical_ner\\nPublic\\nJupyter Notebook\\nUpdated\\nMar 8, 2023\\ndigit-classifier\\nPublic\\nPython\\nUpdated\\nFeb 2, 2023\\nreact_ecommerce\\nPublic\\nJavaScript\\nUpdated\\nJan 11, 2023\\nlearning_react\\nPublic\\nCSS\\nUpdated\\nJan 10, 2023\\nOpen-Assistant\\nPublic\\nForked from\\nLAION-AI/Open-Assistant\\nJupyter Notebook\\nApache License 2.0\\nUpdated\\nJan 1, 2023\\nnepalprabin.github.io_\\nPublic\\nHTML\\nUpdated\\nDec 28, 2022\\nreact-birthday-remainder\\nPublic\\nCSS\\nUpdated\\nDec 26, 2022\\nPrevious\\nNext\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'Ebooks & Whitepapers · GitHub', 'url': 'https://github.com/resources/whitepapers', 'relevance_score': 0.12531015276908875, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"Ebooks & Whitepapers · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nEbooks & Whitepapers\\nBrowse our collection of Ebooks and Whitepapers for valuable industry knowledge, trends, and strategies to help you stay ahead and make informed decisions.\\nFilters\\nOpen\\nFilters\\nContent Type\\nContent Type\\nWhitepapers\\nEbooks\\nCategory\\nCategory\\nAI\\nCloud\\nDevOps\\nGitHub Actions\\nGitHub Advanced Security\\nGitHub Enterprise\\nInnersource\\nOpen Source\\nSecurity\\nSoftware Development\\nClear all\\nApply\\n6 common pitfalls for DevOps teams and how to avoid them\\nEbook\\nDevOps is a transformative practice—and not only because it helps to build better software. It also aligns teams, from IT to engineering to security, removing siloed workstreams and promoting collaboration. As great as this sounds, pulling together your DevOps processes and tools requires some practice to make your strategy perfect.\\nLearn more\\nThe engineering leader’s guide to AI\\nEbook\\nAI coding is here. Developers have embraced it and already use various tools for AI code generation to augment their coding capabilities and offload some of their more mundane tasks.\\nLearn more\\nDetecting and Preventing Secret Leaks in Code\\nEbook\\nIn today’s interconnected digital landscape, safeguarding access to systems and sensitive data is more critical—and more challenging—than ever. With the increasing footprint of code and rapid software development cycles, malicious actors have an expanding array of opportunities to exploit vulnerabilities.\\nLearn more\\nGitHub case study: Enhancing customer support with AI\\nEbook\\nGitHub Copilot empowers engineers to help their organizations achieve better business outcomes for their customers. But AI doesn't simply help engineers do the same work more quickly; it can help them get to places they haven't been able to get to before! We're excited to share how our GitHub customer success team has been using AI to better serve our customers.\\nLearn more\\nWhat AI Means for the Future of DevOps\\nEbook\\nHarnessing AI's full potential isn't just about boosting productivity in isolated phases—it's about driving real organizational value across the entire software development lifecycle.\\nLearn more\\nGo beyond code scanning with AI-powered AppSec\\nWhitepaper\\nUnder pressure to ship and meet business demands, development teams often introduce more security vulnerabilities to code than they fix. In other words, they're racking up security and technical debt. It's a difficult cycle to break.\\nLearn more\\nTaking GitHub Copilot to the stars, not just the skies\\nEbook\\nEmbarking on a successful GitHub Copilot launch requires meticulous planning and execution.\\nLearn more\\nAt the forefront of DevOps innovation and excellence\\nWhitepaper\\nBuild and innovate with a Leader in the Gartner® Magic Quadrant™ for DevOps Platforms\\nLearn more\\n5 DevOps tips to help teams deliver software at scale\\nEbook\\nThere are real-world challenges for organizations seeking success in DevOps. In this info sheet, explore 5 DevOps tips to help teams deliver software at scale.\\nLearn more\\nAI Will Not Replace Software Engineers (and May, in Fact, Require More)\\nWhitepaper\\nExplore the current and future impact of AI on developers and see why humans will always be essential to delivering innovative software in this report.\\nLearn more\\nModernizing COBOL with GitHub Copilot\\nEbook\\nExplore how GitHub Copilot can transform your legacy systems. Discover the best practices we've developed to help leading organizations achieve smoother migrations and revitalize their COBOL codebase.\\nLearn more\\nLeading with AI: How the C-Suite can drive innovation with GitHub Copilot\\nWhitepaper\\nIn the age of AI, organisations have the potential to fuel growth, drive innovation and stay ahead of the competition faster than ever.\\nLearn more\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'GitHub Docs', 'url': 'https://docs.github.com', 'relevance_score': 0.12530089914798737, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"GitHub Docs\\nSkip to main content\\nGitHub Docs\\nHelp for wherever you are on your GitHub journey.\\nGet started\\nGet started\\nMigrations\\nAccount and profile\\nAuthentication\\nBilling and payments\\nSite policy\\nCollaborative coding\\nCodespaces\\nRepositories\\nPull requests\\nGitHub Discussions\\nGitHub Copilot\\nGitHub Copilot\\nGet code suggestions\\nPrompt engineering\\nChat in GitHub\\nCopilot Chat Cookbook\\nExtensions quickstart\\nCI/CD and DevOps\\nGitHub Actions\\nGitHub Packages\\nGitHub Pages\\nSecurity\\nCode security\\nSupply chain security\\nSecurity advisories\\nDependabot\\nCode scanning\\nSecret scanning\\nClient apps\\nGitHub CLI\\nGitHub Mobile\\nGitHub Desktop\\nProject management\\nGitHub Issues\\nProjects\\nSearch on GitHub\\nEnterprise and Teams\\nOrganizations\\nSecure your organization\\nEnterprise onboarding\\nEnterprise administrators\\nGitHub Well-Architected\\nDevelopers\\nApps\\nREST API\\nGraphQL API\\nWebhooks\\nBuild Copilot Extensions\\nGitHub Models\\nCommunity\\nBuilding communities\\nGitHub Sponsors\\nGitHub Education\\nGitHub Support\\nContribute to GitHub Docs\\nMore docs\\nCodeQL query writing\\nElectron\\nnpm\\nGetting started\\nSet up Git\\nAt the heart of GitHub is an open-source version control system (VCS) called Git. Git is responsible for everything GitHub-related that happens locally on your computer.\\nConnecting to GitHub with SSH\\nYou can connect to GitHub using the Secure Shell Protocol (SSH), which provides a secure channel over an unsecured network.\\nCreating and managing repositories\\nYou can create a repository on GitHub to store and collaborate on your project's files, then manage the repository's name and location.\\nBasic writing and formatting syntax\\nCreate sophisticated formatting for your prose and code on GitHub with simple syntax.\\nPopular\\nAbout pull requests\\nLearn about pull requests and draft pull requests on GitHub. Pull requests communicate changes to a branch in a repository. Once a pull request is opened, you can review changes with collaborators and add follow-up commits.\\nAuthentication documentation\\nKeep your account and data secure with features like two-factor authentication, SSH, and commit signature verification.\\nGetting code suggestions in your IDE with GitHub Copilot\\nUse GitHub Copilot to get code suggestions in your editor.\\nManaging remote repositories\\nLearn to work with your local repositories on your computer and remote repositories hosted on GitHub.\"),\n",
       " Document(metadata={'title': 'GitHub Issues · Project planning for developers · GitHub', 'url': 'https://github.com/features/issues', 'relevance_score': 0.12363589555025101, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub Issues · Project planning for developers · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nGitHub Issues\\nProject planning\\nfor developers\\nCreate issues, break them into tasks, track relationships, add custom fields, and have conversations. Visualize large projects as tables, boards, or roadmaps, and automate everything with code.\\nGet started\\nContact sales\\nFeatured logos\\nBreak issues into\\nactionable tasks\\nTackle complex issues with task lists and track their status with new progress indicators. Convert tasks into their own issues and navigate your work hierarchy.\\nMove conversations forward\\nExpress ideas with GitHub Flavored Markdown, mention contributors, react with emoji, clarify with attachments, and see references from commits, pull requests, releases, and deploys. Coordinate by assigning contributors and teams, or by adding them to milestones and projects. All in a single timeline.\\nUpload and attach videos to comments\\nDive into work faster with issue forms and templates\\nFeatures\\nBored of boards?\\nSwitch to tables and roadmaps. Create views for how you work.\\nSave views for sprints, backlogs, teams, or releases.\\nRank, group, sort, slice and filter to suit the occasion. Create swimlanes, share templates and set work in progress limits.\\nNo mouse? No problem.\\nEvery action you can take with the mouse has a keyboard shortcut or command. Filter, sort, group, and assign issues. Your hands never leave the keyboard.\\nExtend issues with\\ncustom fields\\nTrack metadata like iterations, priority, story points, dates, notes, and links. Add custom fields to projects and edit from the issue sidebar.\\nTrack progress with\\nproject insights\\nTrack the health of your current iteration cycle, milestone, or any other custom field you create with new project insights. Identify bottlenecks and issues blocking the team from making progress with the new burn up chart.\\nShare best practices with\\nproject templates\\nCreate templates to share and reuse when getting started with a new project. Share inspiration across teams and get started with a single click.\\nManage work automatically\\nAccelerate your project planning with workflows. Automatically triage issues, set values for custom fields, and auto add or archive issues.\\nGitHub CLI\\nView, update, and create issues without ever leaving your terminal.\\nLearn more\\nGitHub Mobile\\nCreate and manage issues on the go with our native iOS and Android mobile apps.\\nLearn more\\n“\\nThe new planning and tracking functionality keeps my project management close to my code. I no longer find myself needing to reach for spreadsheets or 3P tools which go stale instantly.\\nDan Godfrey\\nDevelopment Manager\\nFlexible project planning for developers\\nGet started\\nContact sales\\nFrequently asked questions\\nWhat is GitHub Issues?\\nWe all need a way to plan our work, track issues, and discuss the things we build. Our answer to this universal question is GitHub Issues, and it’s built-in to every repository. GitHub’s issue tracking is unique because of our focus on simplicity, references, and elegant formatting.\\nWith GitHub Issues, you can express ideas with GitHub Flavored Markdown, assign and mention contributors, react with emojis, clarify with attachments and videos, plus reference code like commits, pull requests, and deploys. With task lists, you can break big issues into tasks, further organize your work with milestones and labels, and track relationships and dependencies.\\nWe built GitHub Issues for developers. It is simple, adaptable, and powerful.\\nWhat are Projects?\\nAs teams and projects grow, how we work evolves. Tools that hard-code a methodology are too specific and rigid to adapt to any moment. Often, we find ourselves creating a spreadsheet or pulling out a notepad to have the space to think. Then our planning is disconnected from where the work happens.\\nThe new Projects connect your planning directly to the work your teams are doing and flexibly adapt to whatever your team needs at any point. Built like a spreadsheet, project tables give you a live canvas to filter, sort, and group issues and pull requests. You can use it, or the accompanying project board, along with custom fields, to track a sprint, plan a feature, or manage a large-scale release.\\nCan I update existing Projects to use the new capabilities?\\nYes. You can migrate your existing Projects (classic) to the new GitHub Projects through a new feature preview.\\nHow it works:\\nWe’ll create a new project and copy all of the data from your existing project (classic) board to the new one.\\nOnce the data is copied, you can use the new project with all the new capabilities.\\nOnce the new project is ready, we will prompt you to close your “old” project, as the old project is not kept in sync.\\nWhat plans have access to Projects?\\nAll users have access to the free tier of GitHub Issues and Projects. For more information about paid tiers, see our pricing page.\\nHistorical charts are available for all Enterprise organizations and are currently in Preview for organizations on Team plans.**\\n**Subject to change as we add future capabilities.\\nWill the new Projects experience be available in GitHub Enterprise Server?\\nYes! GitHub Enterprise Server (GHES) support follows our regular cadence of one to two quarters before enabling the on-premises functionality.\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'Projects – Prabin Nepal', 'url': 'https://nepalprabin.github.io/projects.html', 'relevance_score': 0.123223215341568, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Projects – Prabin Nepal\\n1.\\nStanford NLP Lecture Transcription using OpenAI’s Whisper\\nWhisper is an automatic speech recognition (ASR) model trained on hours of multilingual and multitask supervised data. It is implemented as an encoder-decoder transformer architecture where audio are splitted into 30 seconds of chunks, converted into a log-Mel spectrogram, and then passed into an encoder. The decoder is trained to predict the corresponding text caption, intermixed with special tokens that direct the single model to perform tasks such as language identification, phrase-level timestamps, multilingual speech transcription, and to-English speech translation. For more info about whisper, read\\nhere\\n.\\nI used whisper model to transcribe Stanford NLP lectures into corresponding text captions.\\nHere\\nis the result of the transcribed lectures. This web app is build using Flask and deployed on AWS EC2 instance. You can find transcribed audio file in the form of text\\nhere\\n.\\n2.\\nCustom Named Entity Recognizer for clinical data\\nNamed Entity Recognition (NER) is a subtask of Natural Language Processing (NLP) that involves identifying and categorizing named entities in text.\\nI have developed a custom named entity recognition (NER) model for clinical data using the spacy framework and deployed it using Streamlit. The model is capable of identifying various entities such as diseases, treatments, medications, and anatomical locations from clinical text data. The model classifies entities based on three classes:\\n‘MEDICINE’\\n,\\n“MEDICALCONDITION”\\n, and\\n“PATHOGEN”\\n. The dataset was used from\\nkaggle\\n. You can try the application on this\\nlink\\n3.\\nQuestion Answering using Langchain and OpenAI\\nThis application provides a simple example of how to build a question-answering system using Langchain and pre-trained language models from OpenAI and Streamlit.\\nLangchain helps to build Large Language Models (LLMs) through composability. It helps to combine large language models with other sources of computation.\\nI developed a question answering system using Langchain with OpenAI embeddings. Since, LLMs tends to have fixed context length, Langchain helps to eliminate this issue by introducing chains, where we can break the document into different chunks and run the chain on the whole document. In this application, when a user uploads a file, the contents are converted into embeddings using OpenAI embeddings and stored in Pinecone vector database. Storing embeddings this way, helps for faster retrieval of the embeddings. When a user enters the query, similarity search is conducted to retrieve the similar embeddings from the vector store and the langchain chain passes the formatted response to the LLM.'),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Projects · GitHub', 'url': 'https://github.com/nepalprabin?tab=projects', 'relevance_score': 0.12279811501502991, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) / Projects · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nSearch results\\n0 open and 0 closed projects found.\\nThere aren't any projects yet\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) · GitHub', 'url': 'https://github.com/nepalprabin', 'relevance_score': 0.12260046601295471, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\n/\\nREADME\\n.md\\nHi 👋, I'm Prabin Nepal\\nA passionate software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nPinned\\nLoading\\noswrite\\noswrite\\nPublic\\nPython\\n2\\nbasic-deeplearning-notebooks\\nbasic-deeplearning-notebooks\\nPublic\\nJupyter Notebook\\ndeeplearning-paper-implementation\\ndeeplearning-paper-implementation\\nPublic\\nJupyter Notebook\\n3\\n1\\nwhisper-webapp\\nwhisper-webapp\\nPublic\\nJupyter Notebook\\nSomething went wrong, please refresh the page to try again.\\nIf the problem persists, check the\\nGitHub status page\\nor\\ncontact support\\n.\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Packages · GitHub', 'url': 'https://github.com/nepalprabin?tab=packages', 'relevance_score': 0.122083880007267, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) / Packages · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nGitHub Package Registry Icon\\nGet started with GitHub Packages\\nSafely publish packages, store your packages alongside your code, and share your packages privately with your team.\\nChoose a registry\\nApache Maven\\nA default package manager used for the Java programming language and the Java runtime environment.\\nLearn more\\nNuGet\\nA free and open source package manager used for the Microsoft development platforms including .NET.\\nLearn more\\nRubyGems\\nA standard format for distributing Ruby programs and libraries used for the Ruby programming language.\\nLearn more\\nnpm\\nA package manager for JavaScript, included with Node.js. npm makes it easy for developers to share and reuse code.\\nLearn more\\nContainers\\nA single place for your team to manage Docker images and decide who can see and access your images.\\nLearn more\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'Sign up to GitHub · GitHub', 'url': 'https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E&source=header', 'relevance_score': 0.12103845179080963, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"Sign up to GitHub · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCreate your free account\\nExplore GitHub's core features for individuals and organizations.\\nSee what's included\\nAccess to GitHub Copilot\\nIncrease your productivity and accelerate software development.\\nUnlimited repositories\\nCollaborate securely on public and private projects.\\nIntegrated code reviews\\nBoost code quality with built-in review tools.\\nAutomated workflows\\nSave time with CI/CD integrations and GitHub Actions.\\nCommunity support\\nConnect with developers worldwide for instant feedback and insights.\\nSign up to GitHub\\nGitHub requires JavaScript to proceed with the sign up process. Please enable JavaScript.\\nEmail\\n*\\nPassword\\n*\\nPassword should be at least 15 characters OR at least 8 characters including a number and a lowercase letter.\\nUsername\\n*\\nUsername may only contain alphanumeric characters or single hyphens, and cannot begin or end with a hyphen.\\nContinue\\nVerify your account\\nCreate account\\nBy creating an account, you agree to the\\nTerms of Service\\n.\\nFor more information about GitHub's privacy practices, see the\\nGitHub Privacy Statement\\n.\\nWe'll occasionally send you account-related emails.\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Achievements · GitHub', 'url': 'https://github.com/nepalprabin?tab=achievements', 'relevance_score': 0.11583806574344635, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"nepalprabin (Prabin Nepal) / Achievements · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\nFollow\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nnepalprabin\\nFollow\\n🎯\\nFocusing\\nPrabin Nepal\\nnepalprabin\\n🎯\\nFocusing\\nFollow\\nSoftware Developer. AI enthusiast\\n5\\nfollowers\\n·\\n11\\nfollowing\\nUSA\\nAchievements\\nx2\\nAchievements\\nx2\\nBlock or Report\\nBlock or report nepalprabin\\nBlock user\\nPrevent this user from interacting with your repositories and sending you notifications.\\nLearn more about\\nblocking users\\n.\\nYou must be logged in to block users.\\nAdd an optional note:\\nPlease don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you.\\nBlock user\\nReport abuse\\nContact GitHub support about this user’s behavior.\\nLearn more about\\nreporting abuse\\n.\\nReport abuse\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nStars\\nEarned achievements\\nYOLO\\nLoading\\nPair Extraordinaire\\nLoading\\nPull Shark\\nx2\\nLoading\\nArctic Code Vault Contributor\\nLoading\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Achievements · GitHub', 'url': 'https://github.com/nepalprabin?achievement=pair-extraordinaire&tab=achievements', 'relevance_score': 0.11583806574344635, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=''),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Achievements · GitHub', 'url': 'https://github.com/nepalprabin?achievement=pull-shark&tab=achievements', 'relevance_score': 0.11583806574344635, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=''),\n",
       " Document(metadata={'title': 'nepalprabin (Prabin Nepal) / Achievements · GitHub', 'url': 'https://github.com/nepalprabin?achievement=arctic-code-vault-contributor&tab=achievements', 'relevance_score': 0.11583806574344635, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=''),\n",
       " Document(metadata={'title': 'GitHub Features · GitHub', 'url': 'https://github.com/features', 'relevance_score': 0.11251894384622574, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"GitHub Features · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nThe tools you need to build\\nwhat you want\\nExperience AI with Copilot Chat\\nLearn more\\nThe latest GitHub previews\\nLearn more\\nInnovate faster\\nwith\\nseamless collaboration.\\nSee the changes\\nyou care about.\\nBuild community\\naround your code.\\nGitHub Codespaces\\nSpin up fully configured dev environments in the cloud with the full power of your favorite editor.\\nLearn more\\nGitHub Copilot\\nGet suggestions for whole lines of code or entire functions right inside your editor.\\nLearn more\\nPull requests\\nReceive notifications of contributor changes to a repository, with specified access limits, and seamlessly merge accepted updates.\\nLearn more\\nDiscussions\\nDedicated space for your community to come together, ask and answer questions, and have open-ended conversations.\\nLearn more\\nCode search & code view\\nRapidly search, navigate, and understand code right from GitHub.com with our powerful new tools.\\nLearn more\\nCode review\\nReview new code, visualize changes, and merge confidently with automated status checks.\\nLearn more\\nDraft pull requests\\nCollaborate and discuss changes without a formal review or the risk of unwanted merges.\\nLearn more\\nProtected branches\\nEnforce branch merge restrictions by requiring reviews or limiting access to specific contributors.\\nLearn more\\nAutomate everything:\\nCI/CD, testing, planning, project management, issue labeling, approvals, onboarding, and more.\\nStandardize and scale\\nbest practices, security, and compliance across your organization.\\nGet started quickly with thousands of actions\\nfrom partners and the community.\\nGitHub Actions\\nAutomate your software workflows by writing tasks and combining them to build, test, and deploy faster from GitHub.\\nLearn more\\nGitHub Packages\\nHost your own software packages or use them as dependencies in other projects, with both private and public hosting available.\\nLearn more\\nAPIs\\nCreate calls to get all the data and events you need within GitHub, and automatically kick off and advance your software workflows.\\nLearn more\\nGitHub Marketplace\\nLeverage thousands of actions and applications from our community to help build, improve, and accelerate your workflows.\\nLearn more\\nWebhooks\\nDozens of events and a webhooks API help you integrate with and automate work for your repository, organization, or application.\\nLearn more\\nGitHub-hosted runners\\nMove automation to the cloud with on-demand Linux, macOS, Windows, ARM, and GPU environments for your workflow runs, all hosted by GitHub.\\nLearn more\\nSelf-hosted runners\\nGain more environments and fuller control with labels, groups, and policies to manage runs on your own machines, plus an open source runner application.\\nLearn more\\nWorkflow visualization\\nMap workflows, track their progression in real time, understand complex workflows, and communicate status with the rest of the team.\\nLearn more\\nWorkflow templates\\nStandardize and scale best practices and processes with preconfigured workflow templates shared across your organization.\\nLearn more\\nApplication security where found means fixed.\\nPowered by GitHub Copilot Autofix.\\nExplore GitHub Advanced Security\\nPrevent, find, and fix\\napplication vulnerabilities and leaked secrets.\\nTarget historical alerts\\nto reduce security debt at scale.\\nBuilt into the GitHub platform\\nthat developers know and love.\\nCode scanning\\nFind vulnerabilities in custom code using static analysis. Prevent new vulnerabilities from being introduced by scanning every pull request.\\nLearn more\\nGitHub Copilot Autofix\\nGet notified of vulnerabilities, understand their impact, and receive code suggestions to fix them immediately.\\nLearn more\\nSecurity campaigns\\nSolve your backlog of application security debt with security campaigns that target and generate autofixes for up to 1,000 alerts at a time, rapidly reducing the risk of vulnerabilities and zero-day attacks.\\nLearn more\\nSecret scanning\\nDetect hard-coded secrets in your public and private repositories, and revoke them to secure access to your services.\\nLearn more\\nGitHub Copilot secret scanning\\nAdditional AI capabilities to detect elusive secrets like passwords and personally identifying information.\\nLearn more\\nDependency graph\\nView the packages your project relies on, the repositories that depend on them, and any vulnerabilities detected in their dependencies.\\nLearn more\\nDependabot alerts\\nReceive alerts when new vulnerabilities affect your repositories, with GitHub detecting and notifying you of vulnerable dependencies in both public and private repositories.\\nLearn more\\nDependabot security and version updates\\nKeep your supply chain secure by automatically opening pull requests that update vulnerable or out-of-date dependencies.\\nLearn more\\nDependency review\\nAssess the security impact of new dependencies in pull requests before merging.\\nLearn more\\nGitHub security advisories\\nPrivately report, discuss, fix, and publish information about security vulnerabilities found in open source repositories.\\nLearn more\\nPrivate vulnerability reporting\\nEnable your public repository to privately receive vulnerability reports from the community and collaborate on solutions.\\nLearn more\\nGitHub Advisory Database\\nBrowse or search GitHub's database of known vulnerabilities, featuring curated CVEs and security advisories linked to the GitHub dependency graph.\\nLearn more\\nAccess GitHub anywhere:\\nOn Desktop, Mobile, and Command Line.\\nAccessible anywhere.\\nUse GitHub on macOS, Windows, mobile, or tablet with native apps.\\nEfficient management.\\nHandle pull requests, issues, and tasks swiftly with GitHub CLI or mobile.\\nStreamlined development.\\nVisualize and commit changes easily with GitHub Desktop.\\nGitHub Mobile\\nTake your projects, ideas, and code to go with fully native mobile and tablet experiences.\\nLearn more\\nGitHub CLI\\nManage issues and pull requests from the terminal, where you're already working with Git and your code.\\nLearn more\\nGitHub Desktop\\nSimplify your development workflow with a GUI to visualize, commit, and push changes—no command line needed.\\nLearn more\\nKeep feature requests, bugs, and more organized.\\nCoordinate initiatives big and small\\nwith project tables, boards, and task lists.\\nEngineered for software teams.\\nTrack what you deliver down to the commit.\\nGitHub Projects\\nCreate a customized view of your issues and pull requests to plan and track your work.\\nLearn more\\nGitHub Issues\\nTrack bugs, enhancements, and other requests, prioritize work, and communicate with stakeholders as changes are proposed and merged.\\nLearn more\\nMilestones\\nTrack progress on groups of issues or pull requests in a repository, and map groups to overall project goals.\\nLearn more\\nCharts and insights\\nLeverage insights to visualize your projects by creating and sharing charts built from your project's data.\\nLearn more\\nOrg dependency insights\\nView vulnerabilities, licenses, and other important information for the open source projects your organization depends on.\\nLearn more\\nRepository insights\\nUse data about activity, trends, and contributions within your repositories, to make data-driven improvements to your development cycle.\\nLearn more\\nWikis\\nHost project documentation in a wiki within your repository, allowing contributors to easily edit it on the web or locally.\\nLearn more\\nSimplify access and permissions management\\nacross your projects and teams.\\nUpdate permissions, add new users as you grow,\\nand assign everyone the exact permissions they need.\\nSync with Okta and Entra ID.\\nOrganizations\\nCreate groups of user accounts that own repositories and manage access on a team-by-team or individual user basis.\\nLearn more\\nTeams\\nOrganize your members to mirror your company's structure, with cascading access to permissions and mentions.\\nLearn more\\nTeam sync\\nEnable team synchronization between your identity provider and your organization on GitHub, including Entra ID and Okta.\\nLearn more\\nCustom roles\\nDefine users' access level to your code, data, and settings based on their role in your organization.\\nLearn more\\nCustom repository roles\\nEnsure members have only the permissions they need by creating custom roles with fine-grained permission settings.\\nLearn more\\nDomain verification\\nVerify your organization's identity on GitHub and display that verification through a profile badge.\\nLearn more\\nCompliance reports\\nTake care of your security assessment and certification needs by accessing GitHub’s cloud compliance reports, such as our SOC reports and Cloud Security Alliance CAIQ self-assessments (CSA CAIQ).\\nLearn more\\nAudit log\\nQuickly review the actions performed by members of your organization. Monitor access, permission changes, user changes, and other events.\\nLearn more\\nRepository rules\\nEnhance your organization's security with scalable source code protections, and use rule insights to easily review how and why code changes occurred in your repositories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise accounts\\nEnable collaboration between your organization and GitHub environments with a single point of visibility and management via an enterprise account.\\nLearn more\\nRequires GitHub Enterprise\\nGitHub Connect\\nShare features and workflows between your GitHub Enterprise Server instance and GitHub Enterprise Cloud.\\nLearn more\\nRequires GitHub Enterprise\\nSAML\\nSecurely control access to organization resources like repositories, issues, and pull requests with SAML, while allowing users to authenticate with their GitHub usernames.\\nLearn more\\nRequires GitHub Enterprise\\nLDAP\\nCentralize repository management. LDAP is one of the most common protocols used to integrate third-party software with large company user directories.\\nLearn more\\nRequires GitHub Enterprise\\nEnterprise Managed Users\\nManage the lifecycle and authentication of users on GitHub Enterprise Cloud from your identity provider (IdP).\\nLearn more\\nRequires GitHub Enterprise\\nBring your own identity provider for Enterprise Managed Users\\nUse the SSO and SCIM providers of your choice for Enterprise Managed Users, separate from one another, for a more flexible approach to user lifecycle management.\\nLearn more\\nGitHub Sponsors\\nFinancially support the open source projects your code depends on. Sponsor a contributor, maintainer, or project with one time or recurring contributions.\\nLearn more\\nGitHub Skills\\nLearn new skills by completing tasks and projects directly within GitHub, guided by our friendly bot.\\nLearn more\\nElectron\\nWrite cross-platform desktop applications using JavaScript, HTML, and CSS with the Electron framework, based on Node.js and Chromium.\\nLearn more\\nEducation\\nGitHub Education is a commitment to bringing tech and open source collaboration to students and educators across the globe.\\nLearn more\\nReady to get started?\\nExplore all the plans to find the solution that fits your needs.\\nView pricing plans\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'Brief overview of GPT-4 – Prabin Nepal', 'url': 'https://nepalprabin.github.io/posts/2023-05-15-gpt4-summary.html', 'relevance_score': 0.11177341639995575, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='Brief overview of GPT-4 – Prabin Nepal\\nSince the release of ChatGPT, there has been significant interest and discussion within the broader AI and natural language processing communities regarding its capabilities. In addition to this, ChatGPT has captured the attention of the internet at large due to its remarkable ability to generate fluent and natural-sounding responses across a wide range of prompts and language tasks. Due to this, it became fastest growing consumer application in the history, just two months after the launch. ChatGPT is fine-tuned from a model in the GPT-3.5 series and can write articles, jokes, poetrys in response to the prompt. Though powerful, there have also been concerns raised about the potential risks associated with it and other large language models (LLMs), particularly with respect to issues such as bias, and misinformation. One of the major concern for LLMs is that it suffers from\\nhallucination\\n.\\nHallucination refers to the phenomenon where the model generates responses that are not supported by the input or are inconsistent with reality. This can happen when the model generates text that appears to be coherent and relevant, but is not grounded in any factual or contextual information.\\nA year after releasing ChatGPT, OpenAI released GPT-4 (on 14th March, an improved version of GPT-3.5 model that supports multimodal data. It is capable of processing text and image data to generate textual data. It achieved human level performance on various professional and academic benchmarks. On a simulated bar exam, GPT-4 achieved a score that falls on the top 10% of the exam takes. In contrast, the score achieved by previous model GPT-3.5 fell on bottom 10%. This shows the level of improvement achieved by the latest version of GPT. It is also important to mention that the model was not specifically trained on these exams. A minority of problems were seen by model while training.\\nCapabilities of GPT-4\\nThough the report does not provide any details about architecture (including model size), hardware, training compute, dataset construction, or training method, a demo run by\\nGreg Brockman\\n(President and Co-founder, OpenAI) after the release of GPT-4 shows various capabilities of the model.\\nYou can watch the GPT-4 Developer Livestream replay here:\\n1. Supports longer context\\nGPT-4 is capable of handling over 25,000 words of text, that enables its usage in situations that require the creation of lengthy content, extended dialogues, or the exploration and analysis of extensive documents.\\n2. Hand-drawn pencil drawing turned into a fully functional website\\nGPT-4 is also capable of handling visual input, such as hand-drawn pencil drawings that looks like a mock design, and generating code to create a website. The generated output is mind blowing. Another important aspect is the accuracy by which the model is able to perform OCR task with such messy handwritings.\\nFig. Left is the mock design and right is the website created using the code generated from gpt4-model.\\nsource\\n3. GPT-4 can describe the image.\\nAs opposed to text on prompts (on previous GPT version), this model accepts inputs containing both text and images. It lets user specify any language or vision tasks. GPT-4 displays comparable skills on various types of content, such as documents containing both textual and visual elements like photographs, diagrams, or screenshots, as it does when dealing with text-only inputs.\\nExample prompt demonstrating GPT-4’s visual input capability. The prompt consists of a question about an image with multiple panels which GPT-4 is able to answer.\\nsource\\n4. Human level performance on professional and academic benchmarks\\nGPT outperforms the previous state-of-the-art models on various standardized exams, such as GRE, SAT, BAR, and APs, along with other research benchmarks like MMLU, HellaSWAG, and TextQA. GPT-4 outperforms the English language performance of GPT 3.5 and existing language models (\\nChinchilla\\nand\\nPaLM\\n), including low-resource languages such as Latvian, Welsh, and Swahili.\\nLimitations of GPT-4\\nThough there has been a tremendous improvement as compared to previous models, GPT-4 has similar limitations as earlier GPT models. It is not fully reliable and hallucinates.\\nSince GPT-4 is trained on the data available till September 2021, it lacks knowledge of the events occured after that time period.\\nRisks and mitigations\\nThe prompts entered by the users are not always safe. When providing unsafe inputs to the model, it may generate undesirable text like commiting crimes. To mitigate these risks, various approaches like Adversarial Testing, Model Assisted Safety Pipeline are carried out. Using domain experts and their findings, model is improved to refuse request for unsafe inputs like synthesizing dangerous chemicals.\\nExamples of how unsafe inputs are refused by the model\\nConclusion\\nThe recent advancements in GPT-4, have proven to outperform existing language models in a collection of NLP tasks. The improved capabilities of GPT-4 are not limited to the English language, as predictable scaling allows for accurate predictions in many different languages. However, the increased capabilities of GPT-4 also present new risks, which require significant work to understand and improve its safety and alignment. Nevertheless, GPT-4 marks a significant milestone towards the development of broadly useful and safely deployed AI systems.\\nReferences:\\nGPT-4 Technical Report\\nGPT-4 Blog Post\\nchat.openai.com\\nPS\\nWhile GPT-4 may have stolen the headlines, it was not the only new technology on display. AnthropicAI unveiled\\nClaude\\n, next gen AI assistant can help with use cases including summarization, search, creative and collaborative writing, Q&A, coding, and more. Meanwhile, Google AI released\\nPaLM\\n, an entry point for Google’s large language models with variety of applications. With these three new systems, the future of AI looks brighter than ever before.'),\n",
       " Document(metadata={'title': 'Collections · GitHub', 'url': 'https://github.com/collections', 'relevance_score': 0.10756564885377884, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"Collections · GitHub\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCollections\\nCurated lists and insight into burgeoning industries, topics, and communities.\\n#\\nGame Engines\\nFrameworks for building games across multiple platforms.\\nLearn to Code\\nResources to help people learn to code\\nPixel Art Tools\\nCreating pixel art for fun or animated sprites for a game? The digital artist in you will love these apps and tools!\\n#\\nHow to choose (and contribute to) your first open source project\\nNew to open source? Here’s how to find projects that need help and start making impactful contributions.\\n#\\nClean code linters\\nMake sure your code matches your style guide with these essential code linters.\\n#\\nOpen journalism\\nSee how publications and data-driven journalists use open source to power their newsroom and ensure information is reported fairly and accurately.\\n#\\nDesign essentials\\nThis collection of design libraries are the best on the web, and will complete your toolset for designing stunning products.\\n#\\nMusic\\nDrop the code bass with these musically themed repositories.\\nGovernment apps\\nSites, apps, and tools built by governments across the world to make government work better, together. Read more at https://government.github.com\\n#\\nDevOps tools\\nThese tools help you manage servers and deploy happier and more often with more confidence.\\n#\\nFront-end JavaScript frameworks\\nWhile the number of ways to organize JavaScript is almost infinite, here are some tools that help you build single-page applications.\\n#\\nGitHub Browser Extensions\\nSome useful and fun browser extensions to personalize your GitHub browser experience.\\nGitHub Pages examples\\nFine examples of projects using GitHub Pages (https://pages.github.com).\\nHacking Minecraft\\nMinecraft is a game about building blocks, but it doesn’t end there. Take Minecraft further with some of the projects below, or dive into the code mines and hammer your own!\\n#\\nJavaScript Game Engines\\nLearn or level up your 1337 gamedev skills and build amazing games together for web, desktop, or mobile using these HTML5 / JavaScript game engines.\\nLearn to Code\\nResources to help people learn to code\\n#\\nGetting started with machine learning\\nToday, machine learning—the study of algorithms that make data-based predictions—has found a new audience and a new set of possibilities.\\nMade in Africa\\nDevelopers in Africa use open source technology to solve some of the world's most intractable problems and grow their business ecosystems. Here's a snapshot of local projects across the continent.\\nNet neutrality\\nSoftware, research, and organizations protecting the free and open internet.\\n#\\nOpen data\\nExamples of using GitHub to store, publish, and collaborate on open, machine-readable datasets\\nOpen source organizations\\nA showcase of organizations showcasing their open source projects.\\n#\\nPolicies\\nFrom federal governments to corporations to student clubs, groups of all sizes are using GitHub to share, discuss, and improve laws. *Ask not what the repository can do for you...*\\n#\\nSoftware productivity tools\\nBuild software faster with fewer headaches, using these tools and tricks.\\nLoad more…\\nYou can’t perform that action at this time.\"),\n",
       " Document(metadata={'title': 'GitHub Code Review · GitHub', 'url': 'https://github.com/features/code-review', 'relevance_score': 0.10641869902610779, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content='GitHub Code Review · GitHub\\nSkip to content\\nGitHub Copilot is now available for free.\\nLearn more\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nCode Review\\nWrite better code\\nOn GitHub, lightweight code review tools are built into every pull request. Your team can create review processes that improve the quality of your code and fit neatly into your workflow.\\nGet started\\nContact sales\\nEvery change starts with a pull request.\\nLearn pull request fundamentals\\nStart a new feature or propose a change to existing code with a pull request\\n—a base for your team to coordinate details and refine your changes.\\nPull requests are fundamental to how teams review and improve code on GitHub\\n. Evolve projects, propose new features, and discuss implementation details before changing your source code.\\nDiffs\\nPreview changes in context with your code to see what is being proposed. Side-by-side Diffs highlight added, edited, and deleted code right next to the original file, so you can easily spot changes.\\nLearn more\\nHistory\\nBrowse commits, comments, and references related to your pull request in a timeline-style interface. Your pull request will also highlight what’s changed since you last checked.\\nLearn more\\nBlame\\nSee what a file looked like before a particular change. With blame view, you can see how any portion of your file has evolved over time without viewing the file’s full history.\\nLearn more\\nComments\\nOn GitHub, conversations happen alongside your code. Leave detailed comments on code syntax and ask questions about structure inline.\\nReview requests\\nIf you’re on the other side of the code, requesting peer reviews is easy. Add users to your pull request, and they’ll receive a notification letting them know you need their feedback.\\nReviews\\nSave your teammates a few notifications. Bundle your comments into one cohesive review, then specify whether comments are required changes or just suggestions.\\nResolve simple conflicts\\nYou can’t always avoid conflict. Merge pull requests faster by resolving simple merge conflicts on GitHub—no command line necessary.\\nLearn how to resolve merge conflicts\\nFast, relevant results\\nGive collaborators as much access as they need through your repository settings. You can extend access to a few teams and select which ones can read or write to your files. The options you have for permissions depend on your plan.\\nSee plan options\\nProtected branches\\nProtected Branches help you maintain the integrity of your code. Limit who can push to a branch, and disable force pushes to specific branches. Then scale your policies with the Protected Branches API.\\nLearn more\\nRequired status checks\\nCreate required status checks to add an extra layer of error prevention on branches. Use the Status API to enforce checks and disable the merge button until they pass. To err is human; to automate, divine!\\nStatus API doc\\nEvery change starts with a pull request.\\nGet started\\nContact sales\\nYou can’t perform that action at this time.'),\n",
       " Document(metadata={'title': 'GitHub - nepalprabin/nepalprabin', 'url': 'https://github.com/nepalprabin/nepalprabin', 'relevance_score': 0.10383956879377365, 'prompt': 'Extract all the blog contents based on this prompt', 'source': 'rufus_crawler', 'created_at': '2025-03-05T17:55:28.336760'}, page_content=\"GitHub - nepalprabin/nepalprabin\\nSkip to content\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nnepalprabin\\n/\\nnepalprabin\\nPublic\\nNotifications\\nYou must be signed in to change notification settings\\nFork\\n0\\nStar\\n0\\n0\\nstars\\n0\\nforks\\nBranches\\nTags\\nActivity\\nStar\\nNotifications\\nYou must be signed in to change notification settings\\nnepalprabin/nepalprabin\\nmaster\\nBranches\\nTags\\nGo to file\\nCode\\nFolders and files\\nName\\nName\\nLast commit message\\nLast commit date\\nLatest commit\\nHistory\\n14 Commits\\nREADME.md\\nREADME.md\\nView all files\\nRepository files navigation\\nHi 👋, I'm Prabin Nepal\\nA passionate software developer\\n🌱 I’m currently learning\\nDeep Learning for Computer Vision and NLP\\n💬 Ask me about\\nFull Stack Development, Deep Learning\\n📫 How to reach me\\nprabinnepal1996@gmail.com\\nAbout\\nNo description, website, or topics provided.\\nResources\\nReadme\\nActivity\\nStars\\n0\\nstars\\nWatchers\\n1\\nwatching\\nForks\\n0\\nforks\\nReport repository\\nReleases\\nNo releases published\\nPackages\\n0\\nNo packages published\\nYou can’t perform that action at this time.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rufus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
